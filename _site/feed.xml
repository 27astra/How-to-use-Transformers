<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/How-to-use-Transformers/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/How-to-use-Transformers/" rel="alternate" type="text/html" /><updated>2022-11-09T16:22:29+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/feed.xml</id><title type="html">Transformers快速入门</title><subtitle>How to use HuggingFace Transformers
</subtitle><author><name>xusheng</name></author><entry><title type="html">第十三章：Prompt 情感分析</title><link href="http://localhost:4000/How-to-use-Transformers/nlp/2022-10-10-transformers-note-10.html" rel="alternate" type="text/html" title="第十三章：Prompt 情感分析" /><published>2022-10-10T00:00:00+08:00</published><updated>2022-10-10T00:00:00+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/nlp/transformers-note-10</id><content type="html" xml:base="http://localhost:4000/How-to-use-Transformers/nlp/2022-10-10-transformers-note-10.html"><![CDATA[<p>本文我们将运用 Transformers 库来完成情感分析任务，并且使用目前流行的 Prompt 方法。Prompt 方法的核心想法就是使用模板将问题转换为模型预训练任务类似的形式来处理。</p>

<p>例如要判断标题“American Duo Wins Opening Beach Volleyball Match”的新闻类别，就可以应用模板“This is a $\texttt{[MASK]}$ News: $\textbf{x}$”将其转换为“This is a $\texttt{[MASK]}$ News: American Duo Wins Opening Beach Volleyball Match”，然后送入到经过 MLM (Mask Language Modeling) 任务预训练的模型中预测 $\texttt{[MASK]}$ 对应的词，最后将词映射到新闻类别（比如“Sports”对应“体育”类）。</p>

<blockquote>
  <p>如果你对 Prompt 方法不是很熟悉，建议可以先阅读一下<a href="/2022/09/10/what-is-prompt.html">《Prompt 方法简介》</a></p>
</blockquote>

<p>下面我们以情感分析任务为例，运用 Transformers 库手工构建一个 Prompt 模型来完成任务。</p>

<h2 id="1-准备数据">1. 准备数据</h2>

<p>这里我们选择中文情感分析语料库 ChnSentiCorp 作为数据集，该语料基于爬取的酒店、电脑、书籍网购评论构建，共包含评论接近一万条，可以从百度 ERNIE <a href="https://ernie-github.cdn.bcebos.com/data-chnsenticorp.tar.gz">示例仓库</a>或者<a href="https://pan.baidu.com/s/18UROBO8t1bDGn_spWnXg4w?pwd=xszb">百度云盘</a>下载。</p>

<p>语料库已经划分好了训练集、验证集和测试集，分别包含 9600 / 1200 / 1200 条评论。一行是一个样本，使用 <code class="language-plaintext highlighter-rouge">TAB</code> 分隔评论和对应的标签（0-消极，1-积极）：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般	1
...
</code></pre></div></div>

<h3 id="构建数据集">构建数据集</h3>

<p>与之前一样，我们首先编写继承自 <code class="language-plaintext highlighter-rouge">Dataset</code> 类的自定义数据集用于组织样本和标签。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="k">class</span> <span class="nc">ChnSentiCorp</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'comment'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                    <span class="s">'label'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/train.txt'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/dev.txt'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/test.txt'</span><span class="p">)</span>
</code></pre></div></div>

<p>下面我们输出数据集的尺寸，并且打印出一个训练样本：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train set size: 9600
valid set size: 1200
test set size: 1200
{'comment': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': '1'}
</code></pre></div></div>

<h3 id="数据预处理">数据预处理</h3>

<p>接下来我们就需要通过 <code class="language-plaintext highlighter-rouge">DataLoader</code> 库来按 batch 加载数据，将文本转换为模型可以接受的 token IDs。</p>

<p>大部分 Prompt 方法都是通过模板将问题转换为 MLM 任务的形式来解决，同样地，这里我们定义模板为“总体上来说很 $\texttt{[MASK]}$。$\text{x}$”，并且规定如果 $\texttt{[MASK]}$ 预测为 token “好”就判定情感为“积极”，如果预测为 token “差”就判定为“消极”。</p>

<p>MLM 任务与<a href="/2022/03/18/transformers-note-6.html">序列标注</a>任务很相似，也是对 token 进行分类，并且类别是整个词表，不同之处在于 MLM 任务只对文中特殊的 $\texttt{[MASK]}$ token 进行标注。因此 MLM 任务的标签同样是一个序列，但是只有 $\texttt{[MASK]}$ token 的位置为对应词语的索引，其他位置都应该设为 -100，以便在使用交叉熵计算损失时忽略它们。</p>

<p>下面以处理第一个样本为例。我们通过 <code class="language-plaintext highlighter-rouge">char_to_token()</code> 将 $\texttt{[MASK]}$ 从原文位置映射到切分后的 token 索引，并且根据情感极性将对应的标签设为“好”或“差”的 token ID。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">pos_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s">"好"</span><span class="p">)</span>
<span class="n">neg_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s">"差"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'pos_id:</span><span class="si">{</span><span class="n">pos_id</span><span class="si">}</span><span class="se">\t</span><span class="s">neg_id:</span><span class="si">{</span><span class="n">neg_id</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>

<span class="n">pre_text</span> <span class="o">=</span> <span class="s">'总体上来说很[MASK]。'</span>
<span class="n">comment</span> <span class="o">=</span> <span class="s">'这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'</span>
<span class="n">label</span> <span class="o">=</span> <span class="s">'1'</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="n">pre_text</span> <span class="o">+</span> <span class="n">comment</span>
<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">()</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">full</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
<span class="n">mask_idx</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">'[MASK]'</span><span class="p">))</span>
<span class="n">labels</span><span class="p">[</span><span class="n">mask_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_id</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="s">'1'</span> <span class="k">else</span> <span class="n">neg_id</span>

<span class="k">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['[CLS]', '总', '体', '上', '来', '说', '很', '[MASK]', '。', '这', '个', '宾', '馆', '比', '较', '陈', '旧', '了', '，', '特', '价', '的', '房', '间', '也', '很', '一', '般', '。', '总', '体', '来', '说', '一', '般', '。', '[SEP]']
[-100 -100 -100 -100 -100 -100 -100 1962 -100 -100 -100 -100 -100 -100
 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100
 -100 -100 -100 -100 -100 -100 -100 -100 -100]
</code></pre></div></div>

<p>可以看到，BERT 分词器正确地将“[MASK]”识别为一个 token，并且将 <code class="language-plaintext highlighter-rouge">[MASK]</code> token 对应的标签设置为“好”的 token ID。</p>

<p>在实际编写 DataLoader 的批处理函数 <code class="language-plaintext highlighter-rouge">collate_fn()</code> 时，我们处理的不是一个而是多个样本，因此需要对上面的操作进行扩展。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">pre_text</span> <span class="o">=</span> <span class="s">'总体上来说很[MASK]。'</span>
<span class="n">pos_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s">"好"</span><span class="p">)</span>
<span class="n">neg_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s">"差"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_sentence</span><span class="p">,</span> <span class="n">batch_senti</span>  <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_sentence</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pre_text</span> <span class="o">+</span> <span class="n">sample</span><span class="p">[</span><span class="s">'comment'</span><span class="p">])</span>
        <span class="n">batch_senti</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'label'</span><span class="p">])</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_sentence</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="n">batch_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">full</span><span class="p">(</span><span class="n">batch_inputs</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_sentence</span><span class="p">):</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">mask_idx</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">'[MASK]'</span><span class="p">))</span>
        <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="n">mask_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_id</span> <span class="k">if</span> <span class="n">batch_senti</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">neg_id</span>
    <span class="k">return</span> <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_label</span><span class="p">)</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_X shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch_X</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_y shape:'</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>batch_X shape: {
    'input_ids': torch.Size([4, 96]), 
    'token_type_ids': torch.Size([4, 96]), 
    'attention_mask': torch.Size([4, 96])
}
batch_y shape: torch.Size([4, 96])

{'input_ids': tensor([
        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511, 2523,  671, 5663,
         8024, 6432, 2124, 7410, 1416, 8024, 3300,  763, 1296, 6404, 1348, 2523,
         5042, 1296, 8024,  784,  720,  100,  117,  100,  119, 6432, 2124, 5042,
         1296, 1416, 8024, 2523, 1914, 1296, 6404, 1348, 2523, 7410, 8024,  784,
          720, 3661,  811, 7667, 5401, 2159, 2360, 8024, 5455, 7965, 1590, 4906,
         1278, 4495,  722, 5102, 4638, 8024, 1353, 3633,  679, 2743, 4638, 4385,
         1762,  738, 3766, 6381,  857, 8024, 2743, 4638, 6820, 3221, 2743, 4638,
          511, 2600,  860, 6432, 3341, 8024, 3766,  784,  720, 2692, 2590,  102],
        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511, 2791, 7313, 2397,
         1112, 5653, 3302,  117, 4958, 3698, 3837, 1220,  738, 2523, 1962,  511,
         3766, 3300,  679, 5679, 3698, 1456,  119,  119,  119, 4507,  754, 1905,
          754, 7317, 2356, 1277,  117,  769, 6858, 3683, 6772, 3175,  912, 8024,
          852, 1398, 3198,  738, 3300, 4157, 1648, 3325,  119,  119,  119,  102,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],
        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511, 2791, 7313, 3440,
         3613, 1469, 4384, 1862, 5318, 2190,  126, 3215,  119, 7649, 5831, 6574,
         7030, 2247,  754,  677, 5023,  119, 1372, 3221, 4895, 2458, 2356,  704,
         2552, 6772, 6823,  119,  679, 6814, 6983, 2421, 3300, 4408, 6756,  119,
         1963, 5543, 3022,  677, 4408, 6756,  117, 1156, 1282, 1059, 1282, 5401,
          119,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],
        [ 101, 2600,  860,  677, 3341, 6432, 2523,  103,  511, 2791, 7313, 1377,
          809,  117, 4294, 1166, 4638, 1947, 2791,  117, 7478, 2382,  679, 7231,
          117, 2218, 3221, 7623, 1324, 1922, 5552,  749,  117, 3193, 7623, 3018,
         2533, 3766, 5517, 1366,  117,  102,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]), 
 'token_type_ids': tensor(...), 
 'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}

tensor([[-100, -100, -100, -100, -100, -100, -100, 2345, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100, -100, 1962, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100, -100, 1962, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100],
        [-100, -100, -100, -100, -100, -100, -100, 1962, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])
</code></pre></div></div>

<p>可以看到，DataLoader 按照我们设置的 batch size 每次对 4 个样本进行编码，将 token 序列填充到了相同的长度。标签中 <code class="language-plaintext highlighter-rouge">[MASK]</code> token 对应的索引都转换为了情感极性对应“好”或“差”的 token ID。</p>

<blockquote>
  <p>这里我们对所有样本都应用相同的模板，添加相同的“前缀”，因此 <code class="language-plaintext highlighter-rouge">[MASK]</code> token 的位置其实是固定的，我们不必对每个样本都单独计算 <code class="language-plaintext highlighter-rouge">[MASK]</code>对应的 token 位置。</p>

  <p>在实际操作中，我们既可以对样本应用不同的模板，也可以将 <code class="language-plaintext highlighter-rouge">[MASK]</code> 插入到样本中的任意位置，甚至模板中可以包含多个 <code class="language-plaintext highlighter-rouge">[MASK]</code>，需要根据实际情况对数据预处理进行调整。</p>
</blockquote>

<h2 id="2-训练模型">2. 训练模型</h2>

<h3 id="构建模型">构建模型</h3>

<p>对于 MLM 任务，可以直接使用 Transformers 库封装好的 <code class="language-plaintext highlighter-rouge">AutoModelForMaskedLM</code> 类。由于 BERT 已经在 MLM 任务上进行了预训练，因此借助模板我们甚至可以在不微调的情况下 (Zero-shot) 直接使用模型来预测情感极性。例如对我们的第一个样本：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForMaskedLM</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">text</span> <span class="o">=</span> <span class="s">"总体上来说很[MASK]。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。"</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">token_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">).</span><span class="n">logits</span>
<span class="c1"># Find the location of [MASK] and extract its logits
</span><span class="n">mask_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">mask_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">mask_token_logits</span> <span class="o">=</span> <span class="n">token_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">mask_token_index</span><span class="p">,</span> <span class="p">:]</span>
<span class="c1"># Pick the [MASK] candidates with the highest logits
</span><span class="n">top_5_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">topk</span><span class="p">(</span><span class="n">mask_token_logits</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>

<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">top_5_tokens</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"'&gt;&gt;&gt; </span><span class="si">{</span><span class="n">text</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">mask_token</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token</span><span class="p">]))</span><span class="si">}</span><span class="s">'"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'&gt;&gt;&gt; 总体上来说很好。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'
'&gt;&gt;&gt; 总体上来说很棒。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'
'&gt;&gt;&gt; 总体上来说很差。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'
'&gt;&gt;&gt; 总体上来说很般。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'
'&gt;&gt;&gt; 总体上来说很赞。这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般。'
</code></pre></div></div>

<p>可以看到，BERT 模型成功地将 <code class="language-plaintext highlighter-rouge">[MASK]</code> token 预测成了我们预期的表意词“好”。这里我们还打印出了其他几个大概率的预测词，大部分都具有积极的情感（“好”、“棒”、“赞”）。</p>

<p>当然，这种方式不够灵活，因此像之前章节中一样，本文采用继承 Transformers 库预训练模型的方式来手工构建模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">transformers.activations</span> <span class="kn">import</span> <span class="n">ACT2FN</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertPreTrainedModel</span><span class="p">,</span> <span class="n">BertModel</span>

<span class="k">class</span> <span class="nc">BertPredictionHeadTransform</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_act</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform_act_fn</span> <span class="o">=</span> <span class="n">ACT2FN</span><span class="p">[</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_act</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform_act_fn</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">hidden_act</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform_act_fn</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden_states</span>

<span class="k">class</span> <span class="nc">BertLMPredictionHead</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">BertPredictionHeadTransform</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">):</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden_states</span>

<span class="k">class</span> <span class="nc">BertOnlyMLMHead</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">BertLMPredictionHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction_scores</span>

<span class="k">class</span> <span class="nc">BertForPrompt</span><span class="p">(</span><span class="n">BertPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Initialize weights and apply final processing
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bert_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction_scores</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForPrompt</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cpu device
BertForPrompt(
  (bert): BertModel()
  (cls): BertOnlyMLMHead(
    (predictions): BertLMPredictionHead(
      (transform): BertPredictionHeadTransform(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (transform_act_fn): GELUActivation()
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      )
      (decoder): Linear(in_features=768, out_features=21128, bias=True)
    )
  )
)
</code></pre></div></div>

<p>注意，这里为了能够加载预训练好的 MLM head 参数，我们严格按照 Transformers 库中的模型结构来构建 <code class="language-plaintext highlighter-rouge">BertForPrompt</code> 模型。可以看到，BERT 自带的 MLM head 由两个部分组成：首先对所有 token 进行一个 $768 \times 768$ 的非线性映射（包括激活函数和 LayerNorm），然后使用一个 $768\times 21128$ 的线性映射预测词表中每个 token 的分数。</p>

<p>为了测试模型的操作是否符合预期，我们尝试将一个 batch 的数据送入模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([4, 96, 21128])
</code></pre></div></div>

<p>对于 batch 内 4 个都被填充到长度为 $96$ 的样本，模型对每个 token 都应该输出一个词表大小的向量（对应词表中每个词语的预测 logits 值），因此这里模型的输出尺寸 $4\times 96\times 21128$ 完全符合预期。</p>

<h3 id="训练循环">训练循环</h3>

<p>与之前一样，我们将每一轮 Epoch 分为“训练循环”和“验证/测试循环”，在训练循环中计算损失、优化模型参数，在验证/测试循环中评估模型性能。下面我们首先实现训练循环。</p>

<p>MLM 任务计算损失的方式与序列标注任务几乎完全一致，同样也是在标签序列和预测序列之间计算交叉熵损失，唯一的区别是 MLM 任务只需要计算 <code class="language-plaintext highlighter-rouge">[MASK]</code> token 位置的损失：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predictions</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>
</code></pre></div></div>

<h3 id="后处理">后处理</h3>

<p>因为我们最终需要的是情感标签，所以在编写“验证/测试循环”之前，我们先讨论一下 Prompt 模型的后处理——怎么将模型的输出转换为情感标签。</p>

<p>上面我们介绍过，在 MLM 模型的输出中，我们只关注 <code class="language-plaintext highlighter-rouge">[MASK]</code> token 的预测值，并且只关心其中特定几个表意词的概率值。例如对于情感分析任务，我们只关心预测出的“好”和“坏”两个词的 logit 值的谁更大，如果“好”大于“差”对应的情感标签就是积极，反之就是消极。</p>

<p>因为 Prompt 方法可以在不微调模型的情况下进行预测，这里我们使用 BERT 模型直接对验证集上的前 12 个样本进行预测以展示后处理过程：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">valid_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/dev.txt'</span><span class="p">)</span>
<span class="n">small_eval_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">valid_data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">eval_set</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">small_eval_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>

<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForMaskedLM</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
</code></pre></div></div>

<p>接下来，与之前任务中的验证/测试循环一样，在 <code class="language-plaintext highlighter-rouge">torch.no_grad()</code> 上下文管理器下，我们使用模型对所有样本进行预测，并且汇总预测出的“好”和“差” token 对应的 logits 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pos_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s">"好"</span><span class="p">)</span>
<span class="n">neg_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="s">"差"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">eval_set</span><span class="p">:</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">token_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">).</span><span class="n">logits</span>
    <span class="n">mask_token_indexs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">mask_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mask_token_indexs</span><span class="p">):</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_logits</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span><span class="p">,</span> <span class="p">[</span><span class="n">neg_id</span><span class="p">,</span> <span class="n">pos_id</span><span class="p">]].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div></div>

<p>最后我们遍历数据集中的样本，使用 <code class="language-plaintext highlighter-rouge">softmax</code> 函数将 logits 值转换为概率值，并且同步打印预测和标注结果来进行对比：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">example</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">small_eval_set</span><span class="p">):</span>
    <span class="n">comment</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s">'comment'</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s">'label'</span><span class="p">]</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">comment</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'pred:'</span><span class="p">,</span> <span class="p">{</span><span class="s">'0'</span><span class="p">:</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">item</span><span class="p">(),</span> <span class="s">'1'</span><span class="p">:</span> <span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">item</span><span class="p">()})</span>
    <span class="n">true_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
    <span class="n">true_predictions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span> <span class="k">if</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~ 1
pred: {'0': 0.0033), '1': 0.9967}
&lt;荐书&gt; 推荐所有喜欢&lt;红楼&gt;的红迷们一定要收藏这本书,要知道当年我听说这本书的时候花很长时间去图书馆找和借都没能如愿,所以这次一看到当当有,马上买了,红迷们也要记得备货哦! 1
pred: {'0': 0.0003), '1': 0.9997}
...
</code></pre></div></div>

<p>对于分类任务最常见的就是通过精确率、召回率、F1值 (P / R / F1) 指标来评估每个类别的预测性能，然后再通过宏/微 F1 值 (Macro-F1/Micro-F1) 来评估整体分类性能。这里我们借助机器学习包 <a href="https://scikit-learn.org/stable/#">sklearn</a> 提供的 <code class="language-plaintext highlighter-rouge">classification_report</code> 函数来输出这些指标：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.75      1.00      0.86         9

    accuracy                           0.75        12
   macro avg       0.38      0.50      0.43        12
weighted avg       0.56      0.75      0.64        12
</code></pre></div></div>

<p>可以看到，这里模型将 12 个样本都预测为了“积极”类（标签 1），因此该类别的召回率为 100%，而“消极”类的指标都为 0，代表整体性能的 Macro-F1/Micro-F1 值只有 0.43 和 0.64。</p>

<h3 id="测试循环">测试循环</h3>

<p>熟悉了后处理操作之后，编写验证/测试循环就很简单了，只需对上面的这些步骤稍作整合即可：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">token_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">mask_token_indexs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">mask_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mask_token_indexs</span><span class="p">):</span>
            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_logits</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span><span class="p">,</span> <span class="p">[</span><span class="n">neg_id</span><span class="p">,</span> <span class="n">pos_id</span><span class="p">]].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">'label'</span><span class="p">])</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">results</span><span class="p">).</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">pos_p</span><span class="p">,</span> <span class="n">pos_r</span><span class="p">,</span> <span class="n">pos_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'precision'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'recall'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">neg_p</span><span class="p">,</span> <span class="n">neg_r</span><span class="p">,</span> <span class="n">neg_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'precision'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'recall'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">macro_f1</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"pos: </span><span class="si">{</span><span class="n">pos_p</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">pos_r</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">pos_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">, neg: </span><span class="si">{</span><span class="n">neg_p</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">neg_r</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">neg_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Macro-F1: </span><span class="si">{</span><span class="n">macro_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> Micro-F1: </span><span class="si">{</span><span class="n">micro_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div></div>

<p>为了方便后续保存验证集上最好的模型，这里我们还在验证/测试循环中返回评估结果。</p>

<h3 id="保存模型">保存模型</h3>

<p>与之前一样，我们会根据模型在验证集上的性能来调整超参数以及选出最好的模型权重，然后将选出的模型应用于测试集以评估最终的性能。这里我们继续使用 AdamW 优化器，并且通过 <code class="language-plaintext highlighter-rouge">get_scheduler()</code> 函数定义学习率调度器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_f1_score</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">30</span> <span class="o">*</span> <span class="s">"-"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_scores</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">macro_f1</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">f1_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">macro_f1</span> <span class="o">+</span> <span class="n">micro_f1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">f1_score</span> <span class="o">&gt;</span> <span class="n">best_f1_score</span><span class="p">:</span>
        <span class="n">best_f1_score</span> <span class="o">=</span> <span class="n">f1_score</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span>
            <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> 
            <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_macrof1_</span><span class="si">{</span><span class="p">(</span><span class="n">macro_f1</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_microf1_</span><span class="si">{</span><span class="p">(</span><span class="n">micro_f1</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span>
        <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<p>在开始训练之前，我们先评估一下没有微调的 BERT 模型在测试集上的性能。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/test.txt'</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="n">test_loop</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">test_data</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|█████████████████████████████████| 300/300 [00:06&lt;00:00, 44.78it/s]
pos: 53.05 / 100.00 / 69.33, neg: 100.00 / 9.12 / 16.72
Macro-F1: 43.02 Micro-F1: 43.37
</code></pre></div></div>

<p>可以看到，得益于 Prompt 方法，不经微调的 BERT 模型也已经具有初步的情感分析能力，在测试集上的 Macro-F1 和 Micro-F1 值分别为 43.02 和 43.37。有趣的是，“积极”类别的召回率和“消极”类别的准确率都为 100%，这说明 BERT 对大部分样本都倾向于判断为“积极”类（可能预训练时看到的积极性文本更多吧）。</p>

<p>下面，我们正式开始训练，完整的训练代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertPreTrainedModel</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers.activations</span> <span class="kn">import</span> <span class="n">ACT2FN</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">max_length</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s">'总体上来说很[MASK]。'</span> <span class="o">+</span> <span class="n">x</span>
<span class="n">pos_token</span><span class="p">,</span> <span class="n">neg_token</span> <span class="o">=</span> <span class="s">'好'</span><span class="p">,</span> <span class="s">'差'</span>

<span class="k">def</span> <span class="nf">seed_everything</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1029</span><span class="p">):</span>
    <span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">seed_everything</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">ChnSentiCorp</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'comment'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                    <span class="s">'label'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/train.txt'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/dev.txt'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">ChnSentiCorp</span><span class="p">(</span><span class="s">'data/ChnSentiCorp/test.txt'</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">pos_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">pos_token</span><span class="p">)</span>
<span class="n">neg_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_tokens_to_ids</span><span class="p">(</span><span class="n">neg_token</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_sentence</span><span class="p">,</span> <span class="n">batch_senti</span>  <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_sentence</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">prompt</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'comment'</span><span class="p">]))</span>
        <span class="n">batch_senti</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'label'</span><span class="p">])</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_sentence</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="n">batch_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">full</span><span class="p">(</span><span class="n">batch_inputs</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_sentence</span><span class="p">):</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">mask_idx</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">sentence</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s">'[MASK]'</span><span class="p">))</span>
        <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="n">mask_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">pos_id</span> <span class="k">if</span> <span class="n">batch_senti</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]</span> <span class="o">==</span> <span class="s">'1'</span> <span class="k">else</span> <span class="n">neg_id</span>
    <span class="k">return</span> <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_label</span><span class="p">)</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BertPredictionHeadTransform</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_act</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform_act_fn</span> <span class="o">=</span> <span class="n">ACT2FN</span><span class="p">[</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_act</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">transform_act_fn</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">hidden_act</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">LayerNorm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">layer_norm_eps</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform_act_fn</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden_states</span>

<span class="k">class</span> <span class="nc">BertLMPredictionHead</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">BertPredictionHeadTransform</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bias</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">):</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden_states</span>

<span class="k">class</span> <span class="nc">BertOnlyMLMHead</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">predictions</span> <span class="o">=</span> <span class="n">BertLMPredictionHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sequence_output</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">predictions</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction_scores</span>

<span class="k">class</span> <span class="nc">BertForPrompt</span><span class="p">(</span><span class="n">BertPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cls</span> <span class="o">=</span> <span class="n">BertOnlyMLMHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="c1"># Initialize weights and apply final processing
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bert_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">prediction_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cls</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">prediction_scores</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForPrompt</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predictions</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">token_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">mask_token_indexs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">mask_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mask_token_indexs</span><span class="p">):</span>
            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_logits</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span><span class="p">,</span> <span class="p">[</span><span class="n">neg_id</span><span class="p">,</span> <span class="n">pos_id</span><span class="p">]].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">'label'</span><span class="p">])</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">results</span><span class="p">).</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">pos_p</span><span class="p">,</span> <span class="n">pos_r</span><span class="p">,</span> <span class="n">pos_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'precision'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'recall'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">neg_p</span><span class="p">,</span> <span class="n">neg_r</span><span class="p">,</span> <span class="n">neg_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'precision'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'recall'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">macro_f1</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"pos: </span><span class="si">{</span><span class="n">pos_p</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">pos_r</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">pos_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">, neg: </span><span class="si">{</span><span class="n">neg_p</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">neg_r</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">neg_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Macro-F1: </span><span class="si">{</span><span class="n">macro_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> Micro-F1: </span><span class="si">{</span><span class="n">micro_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metrics</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_f1_score</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">30</span> <span class="o">*</span> <span class="s">"-"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_scores</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">macro_f1</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">f1_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">macro_f1</span> <span class="o">+</span> <span class="n">micro_f1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">f1_score</span> <span class="o">&gt;</span> <span class="n">best_f1_score</span><span class="p">:</span>
        <span class="n">best_f1_score</span> <span class="o">=</span> <span class="n">f1_score</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span>
            <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> 
            <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_macrof1_</span><span class="si">{</span><span class="p">(</span><span class="n">macro_f1</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_microf1_</span><span class="si">{</span><span class="p">(</span><span class="n">micro_f1</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span>
        <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device

Epoch 1/3
------------------------------
loss: 0.258182: 100%|█████████████████| 2400/2400 [03:05&lt;00:00, 12.96it/s]
100%|█████████████████████████████████| 300/300 [00:06&lt;00:00, 44.98it/s]
pos: 90.81 / 94.94 / 92.83, neg: 94.83 / 90.61 / 92.67
Macro-F1: 92.75 Micro-F1: 92.75

saving new weights...

Epoch 2/3
------------------------------
loss: 0.190014: 100%|█████████████████| 2400/2400 [03:04&lt;00:00, 12.98it/s]
100%|█████████████████████████████████| 300/300 [00:06&lt;00:00, 44.79it/s]
pos: 94.88 / 93.76 / 94.32, neg: 93.97 / 95.06 / 94.51
Macro-F1: 94.41 Micro-F1: 94.42

saving new weights...

Epoch 3/3
------------------------------
loss: 0.143803: 100%|█████████████████| 2400/2400 [03:04&lt;00:00, 13.03it/s]
100%|█████████████████████████████████| 300/300 [00:06&lt;00:00, 44.29it/s]
pos: 96.05 / 94.44 / 95.24, neg: 94.65 / 96.21 / 95.42
Macro-F1: 95.33 Micro-F1: 95.33

saving new weights...

Done!
</code></pre></div></div>

<p>可以看到，随着训练的进行，模型在验证集上的 Macro-F1 和 Micro-F1 值都在不断提升。因此 3 轮 Epoch 结束后，会在目录下保存 3 个模型权重：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch_1_valid_macrof1_92.749_microf1_92.748_model_weights.bin
epoch_2_valid_macrof1_94.415_microf1_94.416_model_weights.bin
epoch_3_valid_macrof1_95.331_microf1_95.333_model_weights.bin
</code></pre></div></div>

<p>至此，我们对 Prompt 情感分析模型的训练就完成了。</p>

<h2 id="3-测试模型">3. 测试模型</h2>

<p>训练完成后，我们加载在验证集上性能最优的模型权重，汇报其在测试集上的性能，并且将模型的预测结果保存到文件中。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'epoch_3_valid_macrof1_95.331_microf1_95.333_model_weights.bin'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'evaluating on test set...'</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">token_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">mask_token_indexs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">mask_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mask_token_indexs</span><span class="p">):</span>
            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">token_logits</span><span class="p">[</span><span class="n">s_idx</span><span class="p">,</span> <span class="n">mask_idx</span><span class="p">,</span> <span class="p">[</span><span class="n">neg_id</span><span class="p">,</span> <span class="n">pos_id</span><span class="p">]].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">true_labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">int</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">'label'</span><span class="p">])</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">results</span><span class="p">).</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">save_resluts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">))):</span>
        <span class="n">comment</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">'comment'</span><span class="p">],</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">'label'</span><span class="p">]</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">save_resluts</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s">"comment"</span><span class="p">:</span> <span class="n">comment</span><span class="p">,</span> 
            <span class="s">"label"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span> 
            <span class="s">"pred"</span><span class="p">:</span> <span class="s">'1'</span> <span class="k">if</span> <span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">else</span> <span class="s">'0'</span><span class="p">,</span> 
            <span class="s">"prediction"</span><span class="p">:</span> <span class="p">{</span><span class="s">'0'</span><span class="p">:</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">item</span><span class="p">(),</span> <span class="s">'1'</span><span class="p">:</span> <span class="n">probs</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">item</span><span class="p">()}</span>
        <span class="p">})</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">pos_p</span><span class="p">,</span> <span class="n">pos_r</span><span class="p">,</span> <span class="n">pos_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'precision'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'recall'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'1'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">neg_p</span><span class="p">,</span> <span class="n">neg_r</span><span class="p">,</span> <span class="n">neg_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'precision'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'recall'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'0'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">macro_f1</span><span class="p">,</span> <span class="n">micro_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"pos: </span><span class="si">{</span><span class="n">pos_p</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">pos_r</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">pos_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">, neg: </span><span class="si">{</span><span class="n">neg_p</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">neg_r</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">neg_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Macro-F1: </span><span class="si">{</span><span class="n">macro_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> Micro-F1: </span><span class="si">{</span><span class="n">micro_f1</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'saving predicted results...'</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'test_data_pred.json'</span><span class="p">,</span> <span class="s">'wt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">example_result</span> <span class="ow">in</span> <span class="n">save_resluts</span><span class="p">:</span>
            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">example_result</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>evaluating on test set...
100%|█████████████████████████████████| 300/300 [00:06&lt;00:00, 44.09it/s]
100%|█████████████████████████████████| 1200/1200 [00:00&lt;00:00, 47667.51it/s]
pos: 96.46 / 94.08 / 95.25, neg: 94.07 / 96.45 / 95.25
Macro-F1: 95.25 Micro-F1: 95.25

saving predicted results...
</code></pre></div></div>

<p>可以看到，经过微调，模型在测试集上的 Macro-F1 值从 43.02 提升到 95.25，Micro-F1 值从 43.37 提升到 95.25，证明了我们对模型的微调是成功的。</p>

<p>我们打开保存预测结果的 <em>test_data_pred.json</em>，其中每一行对应一个样本，<code class="language-plaintext highlighter-rouge">comment</code> 对应评论，<code class="language-plaintext highlighter-rouge">label</code> 对应标注标签，<code class="language-plaintext highlighter-rouge">pred</code> 对应预测出的标签，<code class="language-plaintext highlighter-rouge">prediction</code> 对应具体预测出的概率值。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "comment": "交通方便；环境很好；服务态度很好 房间较小", 
    "label": "1", 
    "pred": "1", 
    "prediction": {"0": 0.002953010145574808, "1": 0.9970470070838928}
}
...
</code></pre></div></div>

<p>至此，我们使用 Transformers 库进行 Prompt 情感分析就全部完成了！</p>

<h2 id="代码">代码</h2>

<p>与之前一样，我们按照功能将 Prompt 模型的代码拆分成模块并且存放在不同的文件中，整理后的代码存储在 Github：
<a href="https://github.com/jsksxs360/How-to-use-Transformers/tree/main/src/text_cls_prompt_senti_chnsenticorp">How-to-use-Transformers/src/text_cls_prompt_senti_chnsenticorp/</a></p>

<p>运行 <em>run_prompt_senti_bert.sh</em> 脚本即可进行训练。如果要进行测试或者将模型预测结果保存到文件，只需把脚本中的 <code class="language-plaintext highlighter-rouge">--do_train</code> 改成 <code class="language-plaintext highlighter-rouge">--do_test</code> 或 <code class="language-plaintext highlighter-rouge">--do_predict</code>。</p>

<blockquote>
  <p>经过 3 轮训练，最终 BERT 模型在测试集上的 Macro-F1 值和 Micro-F1 值都达到  95.33%（积极: 96.62 / 94.08 / 95.33, 消极: 94.08 / 96.62 / 95.33） （Nvidia Tesla V100, batch=4）。</p>
</blockquote>]]></content><author><name>SHENG XU</name></author><category term="NLP" /><summary type="html"><![CDATA[本文我们将运用 Transformers 库来完成情感分析任务，并且使用目前流行的 Prompt 方法。Prompt 方法的核心想法就是使用模板将问题转换为模型预训练任务类似的形式来处理。]]></summary></entry><entry><title type="html">第十二章：抽取式问答</title><link href="http://localhost:4000/How-to-use-Transformers/nlp/2022-04-02-transformers-note-9.html" rel="alternate" type="text/html" title="第十二章：抽取式问答" /><published>2022-04-02T00:00:00+08:00</published><updated>2022-04-02T00:00:00+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/nlp/transformers-note-9</id><content type="html" xml:base="http://localhost:4000/How-to-use-Transformers/nlp/2022-04-02-transformers-note-9.html"><![CDATA[<p>本文我们将运用 Transformers 库来完成抽取式问答任务。自动问答 (Question Answering, QA) 是经典的 NLP 任务，需要模型基于给定的上下文回答问题。</p>

<p>根据回答方式的不同可以分为：</p>

<ul>
  <li><strong>抽取式 (extractive) 问答：</strong>从上下文中截取片段作为回答，类似于我们前面介绍的<a href="/2022/03/18/transformers-note-6.html">序列标注</a>任务；</li>
  <li><strong>生成式 (generative) 问答：</strong>生成一个文本片段作为回答，类似于我们前面介绍的<a href="/2022/03/24/transformers-note-7.html">翻译</a>和<a href="/2022/03/29/transformers-note-8.html">摘要</a>任务。</li>
</ul>

<p>抽取式问答模型通常采用纯 Encoder 框架（例如 BERT），它更适用于处理事实性问题，例如“谁发明了 Transformer 架构？”，这些问题的答案通常就包含在上下文中；而生成式问答模型则通常采用 Encoder-Decoder 框架（例如 T5、BART），它更适用于处理开放式问题，例如“天空为什么是蓝色的？”，这些问题的答案通常需要结合上下文语义再进行抽象表达。</p>

<p>本文我们将微调一个 BERT 模型来完成抽取式问答任务：对于给定的问题，从上下文中抽取出概率最大的文本片段作为答案。</p>

<blockquote>
  <p>如果你对生成式问答感兴趣，可以参考 Hugging Face 提供的基于 <a href="https://huggingface.co/datasets/eli5">ELI5</a> 数据库的 <a href="https://yjernite.github.io/lfqa.html">Demo</a>。</p>
</blockquote>

<h2 id="1-准备数据">1. 准备数据</h2>

<p>我们选择由哈工大讯飞联合实验室构建的中文阅读理解语料库 <a href="https://ymcui.com/cmrc2018/">CMRC 2018</a> 作为数据集，该语料是一个类似于 <a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a> 的抽取式数据集，对于每个问题都从原文中截取片段 (span) 作为答案，可以从 <a href="https://github.com/ymcui/cmrc2018/tree/master/squad-style-data">Github</a> 下载。</p>

<p>其中 <em>cmrc2018_train.json</em>、<em>cmrc2018_dev.json</em> 和 <em>cmrc2018_trial.json</em> 分别对应训练集、验证集和测试集。对于每篇文章，CMRC 2018 都标注了一些问题以及对应的答案（包括答案的文本和位置），例如：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
 "context": "《战国无双3》（）是由光荣和ω-force开发的战国无双系列的正统第三续作。本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。...", 
 "qas": [{
     "question": "《战国无双3》是由哪两个公司合作开发的？", 
     "id": "DEV_0_QUERY_0", 
     "answers": [{
         "text": "光荣和ω-force", 
         "answer_start": 11
     }, {
         "text": "光荣和ω-force", 
         "answer_start": 11
     }, {
         "text": "光荣和ω-force", 
         "answer_start": 11
     }]
 }, {
     "question": "男女主角亦有专属声优这一模式是由谁改编的？", 
     "id": "DEV_0_QUERY_1", 
     "answers": [{
         "text": "村雨城", 
         "answer_start": 226
     }, {
         "text": "村雨城", 
         "answer_start": 226
     }, {
         "text": "任天堂游戏谜之村雨城", 
         "answer_start": 219
     }]
 }, ...
 ]
}
</code></pre></div></div>

<p>一个问题可能对应有多个参考答案，在训练时我们任意选择其中一个作为标签，在验证/测试时，我们则将预测答案和所有参考答案都送入打分函数来评估模型的性能。</p>

<h3 id="构建数据集">构建数据集</h3>

<p>与之前一样，我们首先编写继承自 <code class="language-plaintext highlighter-rouge">Dataset</code> 类的自定义数据集用于组织样本和标签。原始数据集中一个样本对应一个上下文，这里我们将它调整为一个问题一个样本，参考答案则处理为包含 <code class="language-plaintext highlighter-rouge">text</code> 和 <code class="language-plaintext highlighter-rouge">answer_start</code> 字段的字典，分别存储答案文本和位置：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">class</span> <span class="nc">CMRC2018</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json_data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">json_data</span><span class="p">[</span><span class="s">'data'</span><span class="p">]:</span>
                <span class="n">title</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span>
                <span class="n">context</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s">'paragraphs'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'context'</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">article</span><span class="p">[</span><span class="s">'paragraphs'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'qas'</span><span class="p">]:</span>
                    <span class="n">q_id</span> <span class="o">=</span> <span class="n">question</span><span class="p">[</span><span class="s">'id'</span><span class="p">]</span>
                    <span class="n">ques</span> <span class="o">=</span> <span class="n">question</span><span class="p">[</span><span class="s">'question'</span><span class="p">]</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">ans</span><span class="p">[</span><span class="s">'text'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ans</span> <span class="ow">in</span> <span class="n">question</span><span class="p">[</span><span class="s">'answers'</span><span class="p">]]</span>
                    <span class="n">answer_start</span> <span class="o">=</span> <span class="p">[</span><span class="n">ans</span><span class="p">[</span><span class="s">'answer_start'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ans</span> <span class="ow">in</span> <span class="n">question</span><span class="p">[</span><span class="s">'answers'</span><span class="p">]]</span>
                    <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s">'id'</span><span class="p">:</span> <span class="n">q_id</span><span class="p">,</span>
                        <span class="s">'title'</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
                        <span class="s">'context'</span><span class="p">:</span> <span class="n">context</span><span class="p">,</span> 
                        <span class="s">'question'</span><span class="p">:</span> <span class="n">ques</span><span class="p">,</span>
                        <span class="s">'answers'</span><span class="p">:</span> <span class="p">{</span>
                            <span class="s">'text'</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
                            <span class="s">'answer_start'</span><span class="p">:</span> <span class="n">answer_start</span>
                        <span class="p">}</span>
                    <span class="p">}</span>
                    <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_train.json'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_dev.json'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_trial.json'</span><span class="p">)</span>
</code></pre></div></div>

<p>下面我们输出数据集的尺寸，并且打印出一个验证样本：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'train set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'valid set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'test set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train set size: 10142
valid set size: 3219
test set size: 1002

{
  'id': 'DEV_0_QUERY_0', 
  'title': '战国无双3', 
  'context': '《战国无双3》（）是由光荣和ω-force开发的战国无双系列的正统第三续作。本作以三大故事为主轴，分别是以武田信玄等人为主的《关东三国志》，织田信长等人为主的《战国三杰》，石田三成等人为主的《关原的年轻武者》，丰富游戏内的剧情。此部份专门介绍角色，欲知武器情报、奥义字或擅长攻击类型等，请至战国无双系列1.由于乡里大辅先生因故去世，不得不寻找其他声优接手。从猛将传 and Z开始。2.战国无双 编年史的原创男女主角亦有专属声优。此模式是任天堂游戏谜之村雨城改编的新增模式。本作中共有20张战场地图（不含村雨城），后来发行的猛将传再新增3张战场地图。但游戏内战役数量繁多，部分地图会有兼用的状况，战役虚实则是以光荣发行的2本「战国无双3 人物真书」内容为主，以下是相关介绍。（注：前方加☆者为猛将传新增关卡及地图。）合并本篇和猛将传的内容，村雨城模式剔除，战国史模式可直接游玩。主打两大模式「战史演武」&amp;「争霸演武」。系列作品外传作品', 
  'question': '《战国无双3》是由哪两个公司合作开发的？', 
  'answers': {
    'text': ['光荣和ω-force', '光荣和ω-force', '光荣和ω-force'], 
    'answer_start': [11, 11, 11]
  }
}
</code></pre></div></div>

<p>可以数据集处理为了我们预期的格式，因为参考答案可以有多个，所以答案文本 <code class="language-plaintext highlighter-rouge">text</code> 和位置 <code class="language-plaintext highlighter-rouge">answer_start</code> 都是列表。</p>

<h3 id="数据预处理">数据预处理</h3>

<p>接下来，我们就需要通过 <code class="language-plaintext highlighter-rouge">DataLoader</code> 库按 batch 加载数据，将文本转换为模型可以接受的 token IDs，并且构建对应的标签，标记答案在上下文中起始和结束位置。本文使用 BERT 模型来完成任务，因此我们首先加载对应的分词器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">'bert-base-chinese'</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
</code></pre></div></div>

<p>正如我们之前在<a href="/2022/03/08/transformers-note-5.html#3-抽取式问答任务">快速分词器</a>中介绍过的那样，对于抽取式问答任务，我们会将问题和上下文编码为下面的形式：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[CLS] question [SEP] context [SEP]
</code></pre></div></div>

<p>标签是答案在上下文中起始/结束 token 的索引，模型的任务就是预测每个 token 为答案片段的起始/结束的概率，即为每个 token 预测一个起始 logit 值和结束 logit 值。例如对于下面的文本，理想标签为：</p>

<p><img src="/img/article/transformers-note-9/qa_labels.svg" alt="qa_labels" /></p>

<p>我们在<a href="/2022/03/08/transformers-note-5.html#处理长文本">问答 pipeline</a> 中就讨论过，由于问题与上下文拼接后的 token 序列可能超过模型的最大输入长度，因此我们可以将上下文切分为短文本块 (chunk) 来处理，同时为了避免答案被截断，我们使用滑窗使得切分出的文本块之间有重叠。</p>

<p><strong>如果对分块操作感到陌生，可以参见快速分词器中的<a href="/2022/03/08/transformers-note-5.html#处理长文本">处理长文本</a>小节，下面只做简单回顾。</strong></p>

<p>下面我们尝试编码第一个训练样本，将拼接后的最大序列长度设为 300，滑窗大小设为 50，只需要给分词器传递以下参数：</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">max_length</code>：设置编码后的最大序列长度（这里设为 300）；</li>
  <li><code class="language-plaintext highlighter-rouge">truncation="only_second"</code>：只截断第二个输入，这里上下文是第二个输入；</li>
  <li><code class="language-plaintext highlighter-rouge">stride</code>：两个相邻文本块之间的重合 token 数量（这里设为 50）；</li>
  <li><code class="language-plaintext highlighter-rouge">return_overflowing_tokens=True</code>：允许分词器返回重叠 token。</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">context</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">"context"</span><span class="p">]</span>
<span class="n">question</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">"question"</span><span class="p">]</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">question</span><span class="p">,</span>
    <span class="n">context</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[CLS] 范 廷 颂 是 什 么 时 候 被 任 为 主 教 的 ？ [SEP] 范 廷 颂 枢 机 （ ， ） ， 圣 名 保 禄 · 若 瑟 （ ） ， 是 越 南 罗 马 天 主 教 枢 机 。 1963 年 被 任 为 主 教 ； 1990 年 被 擢 升 为 天 主 教 河 内 总 教 区 宗 座 署 理 ； 1994 年 被 擢 升 为 总 主 教 ， 同 年 年 底 被 擢 升 为 枢 机 ； 2009 年 2 月 离 世 。 范 廷 颂 于 1919 年 6 月 15 日 在 越 南 宁 平 省 天 主 教 发 艳 教 区 出 生 ； 童 年 时 接 受 良 好 教 育 后 ， 被 一 位 越 南 神 父 带 到 河 内 继 续 其 学 业 。 范 廷 颂 于 1940 年 在 河 内 大 修 道 院 完 成 神 学 学 业 。 范 廷 颂 于 1949 年 6 月 6 日 在 河 内 的 主 教 座 堂 晋 铎 ； 及 后 被 派 到 圣 女 小 德 兰 孤 儿 院 服 务 。 1950 年 代 ， 范 廷 颂 在 河 内 堂 区 创 建 移 民 接 待 中 心 以 收 容 到 河 内 避 战 的 难 民 。 1954 年 ， 法 越 战 争 结 束 ， 越 南 民 主 共 和 国 建 都 河 内 ， 当 时 很 多 天 主 教 神 职 人 员 逃 至 越 南 的 南 方 ， 但 范 廷 颂 仍 然 留 在 河 内 。 翌 年 [SEP]
[CLS] 范 廷 颂 是 什 么 时 候 被 任 为 主 教 的 ？ [SEP] 越 战 争 结 束 ， 越 南 民 主 共 和 国 建 都 河 内 ， 当 时 很 多 天 主 教 神 职 人 员 逃 至 越 南 的 南 方 ， 但 范 廷 颂 仍 然 留 在 河 内 。 翌 年 管 理 圣 若 望 小 修 院 ； 惟 在 1960 年 因 捍 卫 修 院 的 自 由 、 自 治 及 拒 绝 政 府 在 修 院 设 政 治 课 的 要 求 而 被 捕 。 1963 年 4 月 5 日 ， 教 宗 任 命 范 廷 颂 为 天 主 教 北 宁 教 区 主 教 ， 同 年 8 月 15 日 就 任 ； 其 牧 铭 为 「 我 信 天 主 的 爱 」 。 由 于 范 廷 颂 被 越 南 政 府 软 禁 差 不 多 30 年 ， 因 此 他 无 法 到 所 属 堂 区 进 行 牧 灵 工 作 而 专 注 研 读 等 工 作 。 范 廷 颂 除 了 面 对 战 争 、 贫 困 、 被 当 局 迫 害 天 主 教 会 等 问 题 外 ， 也 秘 密 恢 复 修 院 、 创 建 女 修 会 团 体 等 。 1990 年 ， 教 宗 若 望 保 禄 二 世 在 同 年 6 月 18 日 擢 升 范 廷 颂 为 天 主 教 河 内 总 教 区 宗 座 署 理 以 填 补 该 教 区 总 主 教 的 空 缺 。 1994 年 3 月 23 日 [SEP]
[CLS] 范 廷 颂 是 什 么 时 候 被 任 为 主 教 的 ？ [SEP] 若 望 保 禄 二 世 在 同 年 6 月 18 日 擢 升 范 廷 颂 为 天 主 教 河 内 总 教 区 宗 座 署 理 以 填 补 该 教 区 总 主 教 的 空 缺 。 1994 年 3 月 23 日 ， 范 廷 颂 被 教 宗 若 望 保 禄 二 世 擢 升 为 天 主 教 河 内 总 教 区 总 主 教 并 兼 天 主 教 谅 山 教 区 宗 座 署 理 ； 同 年 11 月 26 日 ， 若 望 保 禄 二 世 擢 升 范 廷 颂 为 枢 机 。 范 廷 颂 在 1995 年 至 2001 年 期 间 出 任 天 主 教 越 南 主 教 团 主 席 。 2003 年 4 月 26 日 ， 教 宗 若 望 保 禄 二 世 任 命 天 主 教 谅 山 教 区 兼 天 主 教 高 平 教 区 吴 光 杰 主 教 为 天 主 教 河 内 总 教 区 署 理 主 教 ； 及 至 2005 年 2 月 19 日 ， 范 廷 颂 因 获 批 辞 去 总 主 教 职 务 而 荣 休 ； 吴 光 杰 同 日 真 除 天 主 教 河 内 总 教 区 总 主 教 职 务 。 范 廷 颂 于 2009 年 2 月 22 日 清 晨 在 河 内 离 世 ， 享 年 89 岁 ； 其 葬 礼 于 同 月 26 日 上 午 在 天 主 教 河 内 总 教 区 总 主 教 座 堂 [SEP]
[CLS] 范 廷 颂 是 什 么 时 候 被 任 为 主 教 的 ？ [SEP] 职 务 。 范 廷 颂 于 2009 年 2 月 22 日 清 晨 在 河 内 离 世 ， 享 年 89 岁 ； 其 葬 礼 于 同 月 26 日 上 午 在 天 主 教 河 内 总 教 区 总 主 教 座 堂 举 行 。 [SEP]
</code></pre></div></div>

<p>可以看到，对上下文的分块使得这个样本被切分为了 4 个新样本。</p>

<p>对于包含答案的样本，标签就是起始和结束 token 的索引；对于不包含答案或只有部分答案的样本，对应的标签都为 <code class="language-plaintext highlighter-rouge">start_position = end_position = 0</code>（即 <code class="language-plaintext highlighter-rouge">[CLS]</code>）。因此我们还需要设置分词器参数 <code class="language-plaintext highlighter-rouge">return_offsets_mapping=True</code>，这样就可以运用快速分词器提供的 offset mapping 映射得到对应的 token 索引。</p>

<p>例如我们处理前 4 个训练样本：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">contexts</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"context"</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
<span class="n">questions</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"question"</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">questions</span><span class="p">,</span>
    <span class="n">contexts</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"The 4 examples gave </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">])</span><span class="si">}</span><span class="s"> features."</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Here is where each comes from: </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="s">'overflow_to_sample_mapping'</span><span class="p">]</span><span class="si">}</span><span class="s">."</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dict_keys([
  'input_ids', 
  'token_type_ids', 
  'attention_mask', 
  'offset_mapping', 
  'overflow_to_sample_mapping'
])
The 4 examples gave 14 features.
Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3].
</code></pre></div></div>

<p>由于我们设置 <code class="language-plaintext highlighter-rouge">return_overflowing_tokens</code> 和 <code class="language-plaintext highlighter-rouge">return_offsets_mapping</code>，因此编码结果中除了 input IDs、token type IDs 和 attention mask 以外，还返回了记录 token 到原文映射的 <code class="language-plaintext highlighter-rouge">offset_mapping</code>，以及记录分块样本到原始样本映射的 <code class="language-plaintext highlighter-rouge">overflow_to_sample_mapping</code>。这里 4 个样本共被分块成了 14 个新样本，其中前 4 个新样本来自于原始样本 0，接着 3 个新样本来自于样本 1 …等等。</p>

<p>获得这两个映射之后，我们就可以方便地将答案文本的在原文中的起始/结束位置映射到每个块的 token 索引，以构建答案标签 <code class="language-plaintext highlighter-rouge">start_positions</code> 和 <code class="language-plaintext highlighter-rouge">end_positions</code>。这里我们简单地选择答案列表中的第一个作为参考答案：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">answers</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="s">"answers"</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
<span class="n">start_positions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">end_positions</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"offset_mapping"</span><span class="p">]):</span>
    <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s">"overflow_to_sample_mapping"</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">answers</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span>
    <span class="n">start_char</span> <span class="o">=</span> <span class="n">answer</span><span class="p">[</span><span class="s">"answer_start"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">end_char</span> <span class="o">=</span> <span class="n">answer</span><span class="p">[</span><span class="s">"answer_start"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">answer</span><span class="p">[</span><span class="s">"text"</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="c1"># Find the start and end of the context
</span>    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">context_start</span> <span class="o">=</span> <span class="n">idx</span>
    <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">context_end</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># If the answer is not fully inside the context, label is (0, 0)
</span>    <span class="k">if</span> <span class="n">offset</span><span class="p">[</span><span class="n">context_start</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">start_char</span> <span class="ow">or</span> <span class="n">offset</span><span class="p">[</span><span class="n">context_end</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">end_char</span><span class="p">:</span>
        <span class="n">start_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">end_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># Otherwise it's the start and end token positions
</span>        <span class="n">idx</span> <span class="o">=</span> <span class="n">context_start</span>
        <span class="k">while</span> <span class="n">idx</span> <span class="o">&lt;=</span> <span class="n">context_end</span> <span class="ow">and</span> <span class="n">offset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">start_char</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">start_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">idx</span> <span class="o">=</span> <span class="n">context_end</span>
        <span class="k">while</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">context_start</span> <span class="ow">and</span> <span class="n">offset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">end_char</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">end_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">start_positions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">end_positions</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[47, 0, 0, 0, 53, 0, 0, 100, 0, 0, 0, 0, 61, 0]
[48, 0, 0, 0, 70, 0, 0, 124, 0, 0, 0, 0, 106, 0]
</code></pre></div></div>

<blockquote>
  <p><strong>注意：</strong>为了找到 token 序列中上下文的索引范围，我们可以直接使用 token type IDs，但是一些模型（例如 DistilBERT）的分词器并不会输出该项，因此这里使用快速分词器返回 BatchEncoding 自带的 <code class="language-plaintext highlighter-rouge">sequence_ids()</code> 函数。</p>
</blockquote>

<p>下面我们做个简单的验证，例如对于第一个新样本，可以看到处理后的答案标签为 <code class="language-plaintext highlighter-rouge">(47, 48)</code>，我们将对应的 token 解码并与标注答案进行对比：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">sample_idx</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="s">"overflow_to_sample_mapping"</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
<span class="n">answer</span> <span class="o">=</span> <span class="n">answers</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][</span><span class="s">"text"</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">start_positions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">end_positions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">labeled_answer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="n">start</span> <span class="p">:</span> <span class="n">end</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Theoretical answer: </span><span class="si">{</span><span class="n">answer</span><span class="si">}</span><span class="s">, labels give: </span><span class="si">{</span><span class="n">labeled_answer</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Theoretical answer: 1963年, labels give: 1963 年
</code></pre></div></div>

<blockquote>
  <p><strong>注意：</strong>如果使用 XLNet 等模型，padding 操作会在序列左侧进行，并且问题和上下文也会调换，<code class="language-plaintext highlighter-rouge">[CLS]</code> 也可能不在 0 位置。</p>
</blockquote>

<p><strong>训练批处理函数</strong></p>

<p>最后，我们合并上面的这些操作，编写对应于训练集的批处理函数。由于分块后大部分的样本长度都差不多，因此没必要再进行动态 padding，这里我们简单地将所有新样本都填充到设置的最大长度。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">max_length</span> <span class="o">=</span> <span class="mi">384</span>
<span class="n">stride</span> <span class="o">=</span> <span class="mi">128</span>

<span class="k">def</span> <span class="nf">train_collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_question</span><span class="p">,</span> <span class="n">batch_context</span><span class="p">,</span> <span class="n">batch_answers</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_question</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'question'</span><span class="p">])</span>
        <span class="n">batch_context</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'context'</span><span class="p">])</span>
        <span class="n">batch_answers</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'answers'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_question</span><span class="p">,</span>
        <span class="n">batch_context</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s">'max_length'</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    
    <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'offset_mapping'</span><span class="p">)</span>
    <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'overflow_to_sample_mapping'</span><span class="p">)</span>

    <span class="n">start_positions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">end_positions</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">):</span>
        <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">answer</span> <span class="o">=</span> <span class="n">batch_answers</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span>
        <span class="n">start_char</span> <span class="o">=</span> <span class="n">answer</span><span class="p">[</span><span class="s">'answer_start'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">end_char</span> <span class="o">=</span> <span class="n">answer</span><span class="p">[</span><span class="s">'answer_start'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">answer</span><span class="p">[</span><span class="s">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># Find the start and end of the context
</span>        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">context_start</span> <span class="o">=</span> <span class="n">idx</span>
        <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">context_end</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># If the answer is not fully inside the context, label is (0, 0)
</span>        <span class="k">if</span> <span class="n">offset</span><span class="p">[</span><span class="n">context_start</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">start_char</span> <span class="ow">or</span> <span class="n">offset</span><span class="p">[</span><span class="n">context_end</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">end_char</span><span class="p">:</span>
            <span class="n">start_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">end_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise it's the start and end token positions
</span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">context_start</span>
            <span class="k">while</span> <span class="n">idx</span> <span class="o">&lt;=</span> <span class="n">context_end</span> <span class="ow">and</span> <span class="n">offset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">start_char</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">start_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">idx</span> <span class="o">=</span> <span class="n">context_end</span>
            <span class="k">while</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">context_start</span> <span class="ow">and</span> <span class="n">offset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">end_char</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="n">end_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">start_positions</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">end_positions</span><span class="p">)</span>
 
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">train_collote_fn</span><span class="p">)</span>
</code></pre></div></div>

<p>我们尝试打印出一个 batch 的数据，以验证是否处理正确，并且计算分块后新数据集的大小：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_Start</span><span class="p">,</span> <span class="n">batch_End</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_X shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch_X</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_Start shape:'</span><span class="p">,</span> <span class="n">batch_Start</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_End shape:'</span><span class="p">,</span> <span class="n">batch_End</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_Start</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_End</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'train set size: '</span><span class="p">,</span> <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span> <span class="s">'-&gt;'</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>batch_X shape: {
    'input_ids': torch.Size([8, 384]), 
    'token_type_ids': torch.Size([8, 384]), 
    'attention_mask': torch.Size([8, 384])
}
batch_Start shape: torch.Size([8])
batch_End shape: torch.Size([8])

{'input_ids': tensor([
        [ 101,  100, 6858,  ...,    0,    0,    0],
        [ 101,  784,  720,  ..., 1184, 7481,  102],
        [ 101,  784,  720,  ..., 3341, 8024,  102],
        ...,
        [ 101, 7716, 5335,  ...,    0,    0,    0],
        [ 101, 1367, 7063,  ..., 5638, 1867,  102],
        [ 101, 1367, 7063,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 1, 1, 1],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 1, 1, 1],
        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0]])
}
tensor([ 98,  10,   0,   0,  62,   0, 132,   0])
tensor([100,  35,   0,   0,  65,   0, 140,   0])

train set size: 
10142 -&gt; 18960
</code></pre></div></div>

<p>可以看到，DataLoader 按照我们设置的 <code class="language-plaintext highlighter-rouge">batch_size=4</code> 对样本进行编码，并且成功生成了分别对应答案起始/结束索引的答案标签 <code class="language-plaintext highlighter-rouge">start_positions</code> 和 <code class="language-plaintext highlighter-rouge">end_positions</code> 。经过分块操作后，4 个原始样本被切分成了 8 个新样本，整个训练集的大小从 10142 增长到了 18960。</p>

<blockquote>
  <p>分块操作使得每一个 batch 处理后的大小参差不齐，每次送入模型的样本数并不一致，这虽然可以正常训练，但可能会影响模型最终的精度。更好地方式是为分块后的新样本重新建立一个 Dataset，然后按批加载新的数据集：</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">default_data_collator</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">new_train_dataset</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">default_data_collator</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>  </div>
</blockquote>

<p><strong>验证/测试批处理函数</strong></p>

<p>对于验证/测试集，我们关注的不是预测出的标签序列，而是最终的答案文本，这就需要：</p>

<ol>
  <li>记录每个原始样本被分块成了哪几个新样本，从而合并对应的预测结果；</li>
  <li>在 offset mapping 中标记问题的对应 token，从而在后处理阶段可以区分哪些位置的 token 来自于上下文。</li>
</ol>

<p>因此，对应于验证集/测试集的批处理函数为：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch_question</span><span class="p">,</span> <span class="n">batch_context</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_id</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'id'</span><span class="p">])</span>
        <span class="n">batch_question</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'question'</span><span class="p">])</span>
        <span class="n">batch_context</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'context'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_question</span><span class="p">,</span>
        <span class="n">batch_context</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s">"max_length"</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    
    <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'offset_mapping'</span><span class="p">).</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'overflow_to_sample_mapping'</span><span class="p">)</span>
    <span class="n">example_ids</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">])):</span>
        <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">example_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_id</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">])</span>

        <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">offset_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">offset_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">o</span> <span class="k">if</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">None</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">return</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span>

<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">test_collote_fn</span><span class="p">)</span>
</code></pre></div></div>

<p>同样地，我们打印出一个 batch 编码后的数据，并且计算分块后新数据集的大小：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_X</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_X shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch_X</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="n">example_ids</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'valid set size: '</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">),</span> <span class="s">'-&gt;'</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">valid_dataloader</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>batch_X shape: {
    'input_ids': torch.Size([16, 384]), 
    'token_type_ids': torch.Size([16, 384]), 
    'attention_mask': torch.Size([16, 384])
}

['DEV_0_QUERY_0', 'DEV_0_QUERY_0', 'DEV_0_QUERY_1', 'DEV_0_QUERY_1', 'DEV_0_QUERY_2', 'DEV_0_QUERY_2', 'DEV_1_QUERY_0', 'DEV_1_QUERY_0', 'DEV_1_QUERY_1', 'DEV_1_QUERY_1', 'DEV_1_QUERY_2', 'DEV_1_QUERY_2', 'DEV_1_QUERY_3', 'DEV_1_QUERY_3', 'DEV_2_QUERY_0', 'DEV_2_QUERY_0']

valid set size: 
3219 -&gt; 6254
</code></pre></div></div>

<p>可以看到，我们成功构建了记录每个分块对应样本 ID 的 <code class="language-plaintext highlighter-rouge">example_id</code>。经过分块操作后，整个测试集的样本数量从 3219 增长到了 6254。</p>

<p>至此，数据预处理部分就全部完成了！</p>

<h2 id="2-训练模型">2. 训练模型</h2>

<p>对于抽取式问答任务，可以直接使用 Transformers 库自带的 <code class="language-plaintext highlighter-rouge">AutoModelForQuestionAnswering</code> 函数来构建模型。考虑到这种方式不够灵活，因此与<a href="/2022/03/18/transformers-note-6.html">序列标注任务</a>一样，本文采用继承 Transformers 库预训练模型的方式来手工构建模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertPreTrainedModel</span><span class="p">,</span> <span class="n">BertModel</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BertForExtractiveQA</span><span class="p">(</span><span class="n">BertPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bert_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>

        <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">start_logits</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">end_logits</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span>
    
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForExtractiveQA</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BertForExtractiveQA(
  (bert): BertModel(...)
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
)
</code></pre></div></div>

<p>可以看到，我们构建的模型首先运用 BERT 模型将每一个 token 都编码为语义向量，然后将输出序列送入到一个包含 2 个神经元的线性全连接层中，分别表示每个 token 为答案起始、结束位置的分数，最后我们通过 <code class="language-plaintext highlighter-rouge">tensor.split()</code> 函数把输出拆分为起始、结束位置的预测值。</p>

<p>为了测试模型的操作是否符合预期，我们尝试将一个 batch 的数据送入模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">seed_everything</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">train_collote_fn</span><span class="p">)</span>

<span class="n">batch_X</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="n">start_outputs</span><span class="p">,</span> <span class="n">end_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_X shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch_X</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="s">'start_outputs shape'</span><span class="p">,</span> <span class="n">start_outputs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'end_outputs shape'</span><span class="p">,</span> <span class="n">end_outputs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>batch_X shape: {
    'input_ids': torch.Size([8, 384]), 
    'token_type_ids': torch.Size([8, 384]), 
    'attention_mask': torch.Size([8, 384])
}
start_outputs shape torch.Size([8, 384])
end_outputs shape torch.Size([8, 384])
</code></pre></div></div>

<p>对于 batch 内 8 个都被填充到长度为 384 的文本块，模型对每个 token 都应该输出 1 个 logits 值，对应该 token 为答案起始/结束位置的分数，因此这里模型的起始/结束输出尺寸 $8\times 384$ 完全符合预期。</p>

<h3 id="训练循环">训练循环</h3>

<p>与之前一样，我们将每一轮 Epoch 分为“训练循环”和“验证/测试循环”，在训练循环中计算损失、优化模型参数，在验证/测试循环中评估模型性能。下面我们首先实现训练循环。</p>

<p>如果换一个角度，我们判断每个 token 是否为答案的起始/结束位置，其实就是在整个序列所有的 $L$ 个 token 上选出一个 token 作为答案的起始/结束，相当是在进行一个 $L$ 分类问题。因此这里我们分别在起始和结束的输出上运用交叉熵来计算损失，然后取两个损失的平均值作为模型的整体损失：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">,</span> <span class="n">end_pos</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">,</span> <span class="n">end_pos</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">start_pos</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">end_pos</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">start_pred</span><span class="p">,</span> <span class="n">end_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">start_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">start_pred</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">)</span>
        <span class="n">end_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">end_pred</span><span class="p">,</span> <span class="n">end_pos</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_loss</span> <span class="o">+</span> <span class="n">end_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>
</code></pre></div></div>

<h3 id="后处理">后处理</h3>

<p>因为最终是根据预测出的答案文本来评估模型的性能，所以在编写“验证/测试循环”之前，我们先讨论一下抽取式问答模型的后处理——怎么将模型的输出转换为答案文本。</p>

<p>之前在<a href="/2022/03/08/transformers-note-5.html#3-抽取式问答任务">快速分词器</a>章节中已经介绍过，对每个样本，问答模型都会输出两个张量，分别对应答案起始/结束位置的 logits 值，我们回顾一下之前的后处理过程：</p>

<ol>
  <li>
    <p>遮盖掉除上下文之外的其他 token 的起始/结束 logits 值；</p>
  </li>
  <li>
    <p>通过 softmax 函数将起始/结束 logits 值转换为概率值；</p>
  </li>
  <li>
    <p>通过计算概率值的乘积估计每一对 <code class="language-plaintext highlighter-rouge">(start_token, end_token)</code> 为答案的分数；</p>
  </li>
  <li>
    <p>输出合理的（例如 <code class="language-plaintext highlighter-rouge">start_token</code> 要小于 <code class="language-plaintext highlighter-rouge">end_token</code>）分数最大的对作为答案。</p>
  </li>
</ol>

<p>本文我们会稍微做一些调整：</p>

<ul>
  <li>首先，我们只关心答案文本并不关心其概率，因此这里跳过 softmax 函数，直接基于 logits 值来估计答案分数，这样就从原来计算概率值的乘积变成计算 logits 值的和（因为 $\log(ab) = \log(a) + \log(b)$）；</li>
  <li>其次，为了减少计算量，我们不再为所有可能的 <code class="language-plaintext highlighter-rouge">(start_token, end_token)</code> 对打分，而是只计算 logits 值最高的前 n_best 个 token  组成的对。</li>
</ul>

<p>由于我们的 BERT 模型还没有进行微调，因此这里我们选择一个已经预训练好的问答模型 <a href="https://huggingface.co/uer/roberta-base-chinese-extractive-qa">Chinese RoBERTa-Base Model for QA</a> 进行演示，对验证集上的前 12 个样本进行处理：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">valid_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_dev.json'</span><span class="p">)</span>
<span class="n">small_eval_set</span> <span class="o">=</span> <span class="p">[</span><span class="n">valid_data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]</span>

<span class="n">trained_checkpoint</span> <span class="o">=</span> <span class="s">"uer/roberta-base-chinese-extractive-qa"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">trained_checkpoint</span><span class="p">)</span>
<span class="n">eval_set</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">small_eval_set</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">test_collote_fn</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>

<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForQuestionAnswering</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">trained_checkpoint</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>接下来，与之前任务中的验证/测试循环一样，在 <code class="language-plaintext highlighter-rouge">torch.no_grad()</code> 上下文管理器下，使用模型对所有分块后的新样本进行预测，并且汇总预测出的起始/结束 logits 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start_logits</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">end_logits</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">trained_model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">eval_set</span><span class="p">:</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">trained_model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
    <span class="n">start_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">start_logits</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">end_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">end_logits</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">start_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)</span>
<span class="n">end_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)</span>
</code></pre></div></div>

<p>在将预测结果转换为文本之前，我们还需要知道每个样本被分块为了哪几个新样本，从而汇总对应的预测结果，因此下面先构造一个记录样本 ID 到新样本索引的映射：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">all_example_ids</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_offset_mapping</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span> <span class="ow">in</span> <span class="n">eval_set</span><span class="p">:</span>
    <span class="n">all_example_ids</span> <span class="o">+=</span> <span class="n">example_ids</span>
    <span class="n">all_offset_mapping</span> <span class="o">+=</span> <span class="n">offset_mapping</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="n">example_to_features</span> <span class="o">=</span> <span class="n">collections</span><span class="p">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_example_ids</span><span class="p">):</span>
    <span class="n">example_to_features</span><span class="p">[</span><span class="n">feature_id</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">example_to_features</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>defaultdict(&lt;class 'list'&gt;, {
    'DEV_0_QUERY_0': [0, 1], 'DEV_0_QUERY_1': [2, 3], 'DEV_0_QUERY_2': [4, 5], 'DEV_1_QUERY_0': [6, 7], 
    'DEV_1_QUERY_1': [8, 9], 'DEV_1_QUERY_2': [10, 11], 'DEV_1_QUERY_3': [12, 13], 'DEV_2_QUERY_0': [14, 15], 
    'DEV_2_QUERY_1': [16, 17], 'DEV_2_QUERY_2': [18, 19], 'DEV_3_QUERY_0': [20], 'DEV_3_QUERY_1': [21]
})
</code></pre></div></div>

<p>接下来我们只需要遍历数据集中的样本，首先汇总由其分块出的新样本的预测结果，然后取出每个新样本最高的前 <code class="language-plaintext highlighter-rouge">n_best</code> 个起始/结束 logits 值，最后评估对应的 token 片段为答案的分数（这里我们还通过限制答案的最大长度来进一步减小计算量）：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_best</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">max_answer_length</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">theoretical_answers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s">"id"</span><span class="p">:</span> <span class="n">ex</span><span class="p">[</span><span class="s">"id"</span><span class="p">],</span> <span class="s">"answers"</span><span class="p">:</span> <span class="n">ex</span><span class="p">[</span><span class="s">"answers"</span><span class="p">]}</span> <span class="k">for</span> <span class="n">ex</span> <span class="ow">in</span> <span class="n">small_eval_set</span>
<span class="p">]</span>
<span class="n">predicted_answers</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">small_eval_set</span><span class="p">:</span>
    <span class="n">example_id</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s">"id"</span><span class="p">]</span>
    <span class="n">context</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s">"context"</span><span class="p">]</span>
    <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">feature_index</span> <span class="ow">in</span> <span class="n">example_to_features</span><span class="p">[</span><span class="n">example_id</span><span class="p">]:</span>
        <span class="n">start_logit</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
        <span class="n">end_logit</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="n">all_offset_mapping</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>

        <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">start_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span> <span class="ow">or</span> <span class="n">end_index</span> <span class="o">-</span> <span class="n">start_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;</span> <span class="n">max_answer_length</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="n">answers</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s">"start"</span><span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                        <span class="s">"text"</span><span class="p">:</span> <span class="n">context</span><span class="p">[</span><span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span>
                        <span class="s">"logit_score"</span><span class="p">:</span> <span class="n">start_logit</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logit</span><span class="p">[</span><span class="n">end_index</span><span class="p">],</span>
                    <span class="p">}</span>
                <span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">best_answer</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s">"logit_score"</span><span class="p">])</span>
        <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
            <span class="s">"prediction_text"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> 
            <span class="s">"answer_start"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"start"</span><span class="p">]</span>
        <span class="p">})</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
            <span class="s">"prediction_text"</span><span class="p">:</span> <span class="s">""</span><span class="p">,</span> 
            <span class="s">"answer_start"</span><span class="p">:</span> <span class="mi">0</span>
        <span class="p">})</span>
</code></pre></div></div>

<p>下面我们同步打印出预测和标注的答案来进行对比：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predicted_answers</span><span class="p">,</span> <span class="n">theoretical_answers</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="s">'id'</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'pred:'</span><span class="p">,</span> <span class="n">pred</span><span class="p">[</span><span class="s">'prediction_text'</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'label:'</span><span class="p">,</span> <span class="n">label</span><span class="p">[</span><span class="s">'answers'</span><span class="p">][</span><span class="s">'text'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DEV_0_QUERY_0
pred: 光荣和ω-force
label: ['光荣和ω-force', '光荣和ω-force', '光荣和ω-force']
DEV_0_QUERY_1
pred: 任天堂游戏谜之村雨城
label: ['村雨城', '村雨城', '任天堂游戏谜之村雨城']
...
</code></pre></div></div>

<p>可以看到，由于 <a href="https://huggingface.co/uer/roberta-base-chinese-extractive-qa">Chinese RoBERTa-Base Model for QA</a> 模型本身的预训练数据就包含了 <a href="https://ymcui.com/cmrc2018/">CMRC 2018</a>，因此模型的预测结果非常好。</p>

<p>在成功获取到预测的答案片段之后，就可以对模型的性能进行评估了。这里我们对 CMRC 2018 自带的<a href="https://github.com/ymcui/cmrc2018/blob/master/squad-style-data/cmrc2018_evaluate.py">评估脚本</a>进行修改，使其支持本文模型的输出格式。请将下面的代码存放在 <em>cmrc2018_evaluate.py</em> 文件中，后续直接使用其中的 <code class="language-plaintext highlighter-rouge">evaluate</code> 函数进行评估。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-cased"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">tokenize</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">tokens</span><span class="p">()[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># import nltk
# tokenize = lambda x: nltk.word_tokenize(x)
</span>
<span class="c1"># split Chinese with English
</span><span class="k">def</span> <span class="nf">mixed_segmentation</span><span class="p">(</span><span class="n">in_str</span><span class="p">,</span> <span class="n">rm_punc</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">in_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">in_str</span><span class="p">).</span><span class="n">lower</span><span class="p">().</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">segs_out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">temp_str</span> <span class="o">=</span> <span class="s">""</span>
    <span class="n">sp_char</span> <span class="o">=</span> <span class="p">[</span><span class="s">'-'</span><span class="p">,</span><span class="s">':'</span><span class="p">,</span><span class="s">'_'</span><span class="p">,</span><span class="s">'*'</span><span class="p">,</span><span class="s">'^'</span><span class="p">,</span><span class="s">'/'</span><span class="p">,</span><span class="s">'</span><span class="se">\\</span><span class="s">'</span><span class="p">,</span><span class="s">'~'</span><span class="p">,</span><span class="s">'`'</span><span class="p">,</span><span class="s">'+'</span><span class="p">,</span><span class="s">'='</span><span class="p">,</span>
               <span class="s">'，'</span><span class="p">,</span><span class="s">'。'</span><span class="p">,</span><span class="s">'：'</span><span class="p">,</span><span class="s">'？'</span><span class="p">,</span><span class="s">'！'</span><span class="p">,</span><span class="s">'“'</span><span class="p">,</span><span class="s">'”'</span><span class="p">,</span><span class="s">'；'</span><span class="p">,</span><span class="s">'’'</span><span class="p">,</span><span class="s">'《'</span><span class="p">,</span><span class="s">'》'</span><span class="p">,</span><span class="s">'……'</span><span class="p">,</span><span class="s">'·'</span><span class="p">,</span><span class="s">'、'</span><span class="p">,</span>
               <span class="s">'「'</span><span class="p">,</span><span class="s">'」'</span><span class="p">,</span><span class="s">'（'</span><span class="p">,</span><span class="s">'）'</span><span class="p">,</span><span class="s">'－'</span><span class="p">,</span><span class="s">'～'</span><span class="p">,</span><span class="s">'『'</span><span class="p">,</span><span class="s">'』'</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">in_str</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">rm_punc</span> <span class="ow">and</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">sp_char</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">re</span><span class="p">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s">'[\u4e00-\u9fa5]'</span><span class="p">,</span> <span class="n">char</span><span class="p">)</span> <span class="ow">or</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">sp_char</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">temp_str</span> <span class="o">!=</span> <span class="s">""</span><span class="p">:</span>
                <span class="c1"># ss = nltk.word_tokenize(temp_str)
</span>                <span class="n">ss</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">temp_str</span><span class="p">)</span>
                <span class="n">segs_out</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ss</span><span class="p">)</span>
                <span class="n">temp_str</span> <span class="o">=</span> <span class="s">""</span>
            <span class="n">segs_out</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">temp_str</span> <span class="o">+=</span> <span class="n">char</span>

    <span class="c1">#handling last part
</span>    <span class="k">if</span> <span class="n">temp_str</span> <span class="o">!=</span> <span class="s">""</span><span class="p">:</span>
        <span class="c1"># ss = nltk.word_tokenize(temp_str)
</span>        <span class="n">ss</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">temp_str</span><span class="p">)</span>
        <span class="n">segs_out</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">ss</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">segs_out</span>

<span class="c1"># remove punctuation
</span><span class="k">def</span> <span class="nf">remove_punctuation</span><span class="p">(</span><span class="n">in_str</span><span class="p">):</span>
    <span class="n">in_str</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">in_str</span><span class="p">).</span><span class="n">lower</span><span class="p">().</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">sp_char</span> <span class="o">=</span> <span class="p">[</span><span class="s">'-'</span><span class="p">,</span><span class="s">':'</span><span class="p">,</span><span class="s">'_'</span><span class="p">,</span><span class="s">'*'</span><span class="p">,</span><span class="s">'^'</span><span class="p">,</span><span class="s">'/'</span><span class="p">,</span><span class="s">'</span><span class="se">\\</span><span class="s">'</span><span class="p">,</span><span class="s">'~'</span><span class="p">,</span><span class="s">'`'</span><span class="p">,</span><span class="s">'+'</span><span class="p">,</span><span class="s">'='</span><span class="p">,</span>
               <span class="s">'，'</span><span class="p">,</span><span class="s">'。'</span><span class="p">,</span><span class="s">'：'</span><span class="p">,</span><span class="s">'？'</span><span class="p">,</span><span class="s">'！'</span><span class="p">,</span><span class="s">'“'</span><span class="p">,</span><span class="s">'”'</span><span class="p">,</span><span class="s">'；'</span><span class="p">,</span><span class="s">'’'</span><span class="p">,</span><span class="s">'《'</span><span class="p">,</span><span class="s">'》'</span><span class="p">,</span><span class="s">'……'</span><span class="p">,</span><span class="s">'·'</span><span class="p">,</span><span class="s">'、'</span><span class="p">,</span>
               <span class="s">'「'</span><span class="p">,</span><span class="s">'」'</span><span class="p">,</span><span class="s">'（'</span><span class="p">,</span><span class="s">'）'</span><span class="p">,</span><span class="s">'－'</span><span class="p">,</span><span class="s">'～'</span><span class="p">,</span><span class="s">'『'</span><span class="p">,</span><span class="s">'』'</span><span class="p">]</span>
    <span class="n">out_segs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">in_str</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">sp_char</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">out_segs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
    <span class="k">return</span> <span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_segs</span><span class="p">)</span>

<span class="c1"># find longest common string
</span><span class="k">def</span> <span class="nf">find_lcs</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
    <span class="n">mmax</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">s1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">s2</span><span class="p">[</span><span class="n">j</span><span class="p">]:</span>
                <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span>
                <span class="k">if</span> <span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">mmax</span><span class="p">:</span>
                    <span class="n">mmax</span><span class="o">=</span><span class="n">m</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">p</span><span class="o">=</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span>
    <span class="k">return</span> <span class="n">s1</span><span class="p">[</span><span class="n">p</span><span class="o">-</span><span class="n">mmax</span><span class="p">:</span><span class="n">p</span><span class="p">],</span> <span class="n">mmax</span>

<span class="k">def</span> <span class="nf">calc_f1_score</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
    <span class="n">f1_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ans</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">:</span>
        <span class="n">ans_segs</span> <span class="o">=</span> <span class="n">mixed_segmentation</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">rm_punc</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">prediction_segs</span> <span class="o">=</span> <span class="n">mixed_segmentation</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">rm_punc</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">lcs</span><span class="p">,</span> <span class="n">lcs_len</span> <span class="o">=</span> <span class="n">find_lcs</span><span class="p">(</span><span class="n">ans_segs</span><span class="p">,</span> <span class="n">prediction_segs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lcs_len</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">f1_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">continue</span>
        <span class="n">precision</span>     <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">lcs_len</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">prediction_segs</span><span class="p">)</span>
        <span class="n">recall</span>         <span class="o">=</span> <span class="mf">1.0</span><span class="o">*</span><span class="n">lcs_len</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">ans_segs</span><span class="p">)</span>
        <span class="n">f1</span>             <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">precision</span><span class="o">*</span><span class="n">recall</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">precision</span><span class="o">+</span><span class="n">recall</span><span class="p">)</span>
        <span class="n">f1_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">f1_scores</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">calc_em_score</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">prediction</span><span class="p">):</span>
    <span class="n">em</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">ans</span> <span class="ow">in</span> <span class="n">answers</span><span class="p">:</span>
        <span class="n">ans_</span> <span class="o">=</span> <span class="n">remove_punctuation</span><span class="p">(</span><span class="n">ans</span><span class="p">)</span>
        <span class="n">prediction_</span> <span class="o">=</span> <span class="n">remove_punctuation</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ans_</span> <span class="o">==</span> <span class="n">prediction_</span><span class="p">:</span>
            <span class="n">em</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">em</span>

<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">):</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">em</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">skip_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">data</span><span class="p">[</span><span class="s">'id'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'prediction_text'</span><span class="p">])</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">])</span>
    <span class="n">ref</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">data</span><span class="p">[</span><span class="s">'id'</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s">'answers'</span><span class="p">][</span><span class="s">'text'</span><span class="p">])</span> <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">references</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">query_id</span><span class="p">,</span> <span class="n">answers</span> <span class="ow">in</span> <span class="n">ref</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">total_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">query_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span>
            <span class="n">sys</span><span class="p">.</span><span class="n">stderr</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="s">'Unanswered question: {}</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">query_id</span><span class="p">))</span>
            <span class="n">skip_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">continue</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">query_id</span><span class="p">]</span>
        <span class="n">f1</span> <span class="o">+=</span> <span class="n">calc_f1_score</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
        <span class="n">em</span> <span class="o">+=</span> <span class="n">calc_em_score</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
    <span class="n">f1_score</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">f1</span> <span class="o">/</span> <span class="n">total_count</span>
    <span class="n">em_score</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">em</span> <span class="o">/</span> <span class="n">total_count</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s">'avg'</span><span class="p">:</span> <span class="p">(</span><span class="n">em_score</span> <span class="o">+</span> <span class="n">f1_score</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.5</span><span class="p">,</span> 
        <span class="s">'f1'</span><span class="p">:</span> <span class="n">f1_score</span><span class="p">,</span> 
        <span class="s">'em'</span><span class="p">:</span> <span class="n">em_score</span><span class="p">,</span> 
        <span class="s">'total'</span><span class="p">:</span> <span class="n">total_count</span><span class="p">,</span> 
        <span class="s">'skip'</span><span class="p">:</span> <span class="n">skip_count</span>
    <span class="p">}</span>
</code></pre></div></div>

<p>最后，我们将上面的预测结果送入 <code class="language-plaintext highlighter-rouge">evaluate</code> 函数进行评估：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">cmrc2018_evaluate</span> <span class="kn">import</span> <span class="n">evaluate</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">predicted_answers</span><span class="p">,</span> <span class="n">theoretical_answers</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"F1: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'f1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> EM: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'em'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> AVG: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>F1: 92.63 EM: 75.00 AVG: 83.81
</code></pre></div></div>

<h3 id="测试循环">测试循环</h3>

<p>熟悉了后处理操作之后，编写验证/测试循环就很简单了，只需对上面的这些步骤稍作整合即可：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">from</span> <span class="nn">cmrc2018_evaluate</span> <span class="kn">import</span> <span class="n">evaluate</span>

<span class="n">n_best</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">max_answer_length</span> <span class="o">=</span> <span class="mi">30</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">all_example_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_offset_mapping</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">all_example_ids</span> <span class="o">+=</span> <span class="n">example_ids</span>
        <span class="n">all_offset_mapping</span> <span class="o">+=</span> <span class="n">offset_mapping</span>
    <span class="n">example_to_features</span> <span class="o">=</span> <span class="n">collections</span><span class="p">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_example_ids</span><span class="p">):</span>
        <span class="n">example_to_features</span><span class="p">[</span><span class="n">feature_id</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="n">start_logits</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">start_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">start_logits</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">end_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">end_logits</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">start_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)</span>
    
    <span class="n">theoretical_answers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s">"id"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"id"</span><span class="p">],</span> <span class="s">"answers"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"answers"</span><span class="p">]}</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">predicted_answers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))):</span>
        <span class="n">example_id</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"id"</span><span class="p">]</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"context"</span><span class="p">]</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Loop through all features associated with that example
</span>        <span class="k">for</span> <span class="n">feature_index</span> <span class="ow">in</span> <span class="n">example_to_features</span><span class="p">[</span><span class="n">example_id</span><span class="p">]:</span>
            <span class="n">start_logit</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">end_logit</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">all_offset_mapping</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>

            <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">start_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span> <span class="ow">or</span> <span class="n">end_index</span><span class="o">-</span><span class="n">start_index</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;</span> <span class="n">max_answer_length</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="n">answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s">"start"</span><span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s">"text"</span><span class="p">:</span> <span class="n">context</span><span class="p">[</span><span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> 
                        <span class="s">"logit_score"</span><span class="p">:</span> <span class="n">start_logit</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logit</span><span class="p">[</span><span class="n">end_index</span><span class="p">],</span>
                    <span class="p">})</span>
        <span class="c1"># Select the answer with the best score
</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_answer</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s">"logit_score"</span><span class="p">])</span>
            <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"start"</span><span class="p">]</span>
            <span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="s">""</span><span class="p">,</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">})</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">predicted_answers</span><span class="p">,</span> <span class="n">theoretical_answers</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"F1: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'f1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> EM: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'em'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> AVG: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>为了方便后续保存验证集上最好的模型，这里我们还在验证/测试循环中返回对模型预测的评估结果。</p>

<h3 id="保存模型">保存模型</h3>

<p>与之前一样，我们会根据模型在验证集上的性能来调整超参数以及选出最好的模型权重，然后将选出的模型应用于测试集以评估最终的性能。这里我们继续使用 AdamW 优化器，并且通过 <code class="language-plaintext highlighter-rouge">get_scheduler()</code> 函数定义学习率调度器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_avg_score</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_scores</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'Valid'</span><span class="p">)</span>
    <span class="n">avg_score</span> <span class="o">=</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">avg_score</span> <span class="o">&gt;</span> <span class="n">best_avg_score</span><span class="p">:</span>
        <span class="n">best_avg_score</span> <span class="o">=</span> <span class="n">avg_score</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_avg_</span><span class="si">{</span><span class="n">avg_score</span><span class="si">:</span><span class="mf">0.4</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<p>下面，我们正式开始训练，完整的训练代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertPreTrainedModel</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="n">sys</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">'./'</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">cmrc2018_evaluate</span> <span class="kn">import</span> <span class="n">evaluate</span>

<span class="n">max_length</span> <span class="o">=</span> <span class="mi">384</span>
<span class="n">stride</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">n_best</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">max_answer_length</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">seed_everything</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1029</span><span class="p">):</span>
    <span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">seed_everything</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">CMRC2018</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json_data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">json_data</span><span class="p">[</span><span class="s">'data'</span><span class="p">]:</span>
                <span class="n">title</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span>
                <span class="n">context</span> <span class="o">=</span> <span class="n">article</span><span class="p">[</span><span class="s">'paragraphs'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'context'</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">article</span><span class="p">[</span><span class="s">'paragraphs'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s">'qas'</span><span class="p">]:</span>
                    <span class="n">q_id</span> <span class="o">=</span> <span class="n">question</span><span class="p">[</span><span class="s">'id'</span><span class="p">]</span>
                    <span class="n">ques</span> <span class="o">=</span> <span class="n">question</span><span class="p">[</span><span class="s">'question'</span><span class="p">]</span>
                    <span class="n">text</span> <span class="o">=</span> <span class="p">[</span><span class="n">ans</span><span class="p">[</span><span class="s">'text'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ans</span> <span class="ow">in</span> <span class="n">question</span><span class="p">[</span><span class="s">'answers'</span><span class="p">]]</span>
                    <span class="n">answer_start</span> <span class="o">=</span> <span class="p">[</span><span class="n">ans</span><span class="p">[</span><span class="s">'answer_start'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ans</span> <span class="ow">in</span> <span class="n">question</span><span class="p">[</span><span class="s">'answers'</span><span class="p">]]</span>
                    <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                        <span class="s">'id'</span><span class="p">:</span> <span class="n">q_id</span><span class="p">,</span>
                        <span class="s">'title'</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span>
                        <span class="s">'context'</span><span class="p">:</span> <span class="n">context</span><span class="p">,</span> 
                        <span class="s">'question'</span><span class="p">:</span> <span class="n">ques</span><span class="p">,</span>
                        <span class="s">'answers'</span><span class="p">:</span> <span class="p">{</span>
                            <span class="s">'text'</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
                            <span class="s">'answer_start'</span><span class="p">:</span> <span class="n">answer_start</span>
                        <span class="p">}</span>
                    <span class="p">}</span>
                    <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_train.json'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_dev.json'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">CMRC2018</span><span class="p">(</span><span class="s">'data/cmrc2018/cmrc2018_trial.json'</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">'bert-base-chinese'</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_question</span><span class="p">,</span> <span class="n">batch_context</span><span class="p">,</span> <span class="n">batch_answers</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_question</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'question'</span><span class="p">])</span>
        <span class="n">batch_context</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'context'</span><span class="p">])</span>
        <span class="n">batch_answers</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'answers'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_question</span><span class="p">,</span>
        <span class="n">batch_context</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s">'max_length'</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    
    <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'offset_mapping'</span><span class="p">)</span>
    <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'overflow_to_sample_mapping'</span><span class="p">)</span>

    <span class="n">start_positions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">end_positions</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">):</span>
        <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">answer</span> <span class="o">=</span> <span class="n">batch_answers</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span>
        <span class="n">start_char</span> <span class="o">=</span> <span class="n">answer</span><span class="p">[</span><span class="s">'answer_start'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">end_char</span> <span class="o">=</span> <span class="n">answer</span><span class="p">[</span><span class="s">'answer_start'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">answer</span><span class="p">[</span><span class="s">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="c1"># Find the start and end of the context
</span>        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">context_start</span> <span class="o">=</span> <span class="n">idx</span>
        <span class="k">while</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">context_end</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="c1"># If the answer is not fully inside the context, label is (0, 0)
</span>        <span class="k">if</span> <span class="n">offset</span><span class="p">[</span><span class="n">context_start</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">start_char</span> <span class="ow">or</span> <span class="n">offset</span><span class="p">[</span><span class="n">context_end</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">end_char</span><span class="p">:</span>
            <span class="n">start_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">end_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Otherwise it's the start and end token positions
</span>            <span class="n">idx</span> <span class="o">=</span> <span class="n">context_start</span>
            <span class="k">while</span> <span class="n">idx</span> <span class="o">&lt;=</span> <span class="n">context_end</span> <span class="ow">and</span> <span class="n">offset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">start_char</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">start_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

            <span class="n">idx</span> <span class="o">=</span> <span class="n">context_end</span>
            <span class="k">while</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">context_start</span> <span class="ow">and</span> <span class="n">offset</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">end_char</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">-=</span> <span class="mi">1</span>
            <span class="n">end_positions</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">start_positions</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">end_positions</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">test_collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch_question</span><span class="p">,</span> <span class="n">batch_context</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_id</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'id'</span><span class="p">])</span>
        <span class="n">batch_question</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'question'</span><span class="p">])</span>
        <span class="n">batch_context</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'context'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_question</span><span class="p">,</span>
        <span class="n">batch_context</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="s">"max_length"</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    
    <span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'offset_mapping'</span><span class="p">).</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">sample_mapping</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'overflow_to_sample_mapping'</span><span class="p">)</span>
    <span class="n">example_ids</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">])):</span>
        <span class="n">sample_idx</span> <span class="o">=</span> <span class="n">sample_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">example_ids</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_id</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">])</span>

        <span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">offset_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">offset_mapping</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">o</span> <span class="k">if</span> <span class="n">sequence_ids</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">None</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">o</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">return</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">train_collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">test_collote_fn</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">test_collote_fn</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'train set size: '</span><span class="p">,</span> <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">),</span> <span class="s">'-&gt;'</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'valid set size: '</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">),</span> <span class="s">'-&gt;'</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">valid_dataloader</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'test set size: '</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">),</span> <span class="s">'-&gt;'</span><span class="p">,</span> <span class="nb">sum</span><span class="p">([</span><span class="n">batch_data</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">]))</span>

<span class="k">class</span> <span class="nc">BertForExtractiveQA</span><span class="p">(</span><span class="n">BertPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">num_labels</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bert_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>

        <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">start_logits</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">end_logits</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">contiguous</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">config</span><span class="p">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForExtractiveQA</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">,</span> <span class="n">end_pos</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">,</span> <span class="n">end_pos</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">start_pos</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">end_pos</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">start_pred</span><span class="p">,</span> <span class="n">end_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">start_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">start_pred</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">)</span>
        <span class="n">end_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">end_pred</span><span class="p">,</span> <span class="n">end_pos</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_loss</span> <span class="o">+</span> <span class="n">end_loss</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">all_example_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_offset_mapping</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="n">all_example_ids</span> <span class="o">+=</span> <span class="n">example_ids</span>
        <span class="n">all_offset_mapping</span> <span class="o">+=</span> <span class="n">offset_mapping</span>
    <span class="n">example_to_features</span> <span class="o">=</span> <span class="n">collections</span><span class="p">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_example_ids</span><span class="p">):</span>
        <span class="n">example_to_features</span><span class="p">[</span><span class="n">feature_id</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="n">start_logits</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">pred_start_logits</span><span class="p">,</span> <span class="n">pred_end_logit</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">start_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_start_logits</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">end_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_end_logit</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">start_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)</span>
    
    <span class="n">theoretical_answers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s">"id"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"id"</span><span class="p">],</span> <span class="s">"answers"</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"answers"</span><span class="p">]}</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">predicted_answers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))):</span>
        <span class="n">example_id</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"id"</span><span class="p">]</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"context"</span><span class="p">]</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Loop through all features associated with that example
</span>        <span class="k">for</span> <span class="n">feature_index</span> <span class="ow">in</span> <span class="n">example_to_features</span><span class="p">[</span><span class="n">example_id</span><span class="p">]:</span>
            <span class="n">start_logit</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">end_logit</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">all_offset_mapping</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>

            <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">start_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span> <span class="ow">or</span> <span class="n">end_index</span><span class="o">-</span><span class="n">start_index</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;</span> <span class="n">max_answer_length</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="n">answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s">"start"</span><span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s">"text"</span><span class="p">:</span> <span class="n">context</span><span class="p">[</span><span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> 
                        <span class="s">"logit_score"</span><span class="p">:</span> <span class="n">start_logit</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logit</span><span class="p">[</span><span class="n">end_index</span><span class="p">],</span>
                    <span class="p">})</span>
        <span class="c1"># Select the answer with the best score
</span>        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_answer</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s">"logit_score"</span><span class="p">])</span>
            <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"start"</span><span class="p">]</span>
            <span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="s">""</span><span class="p">,</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">})</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">predicted_answers</span><span class="p">,</span> <span class="n">theoretical_answers</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"F1: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'f1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> EM: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'em'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> AVG: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_avg_score</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_scores</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">valid_data</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">avg_score</span> <span class="o">=</span> <span class="n">valid_scores</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">avg_score</span> <span class="o">&gt;</span> <span class="n">best_avg_score</span><span class="p">:</span>
        <span class="n">best_avg_score</span> <span class="o">=</span> <span class="n">avg_score</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_avg_</span><span class="si">{</span><span class="n">avg_score</span><span class="si">:</span><span class="mf">0.4</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device

train set size: 
10142 -&gt; 18960
valid set size: 
3219 -&gt; 6254
test set size: 
1002 -&gt; 1961

Epoch 1/3
-------------------------------
loss: 1.473110: 100%|█████████████| 2536/2536 [08:13&lt;00:00,  5.14it/s]
100%|█████████████████████████████| 805/805 [00:50&lt;00:00, 15.86it/s]
100%|█████████████████████████████| 3219/3219 [00:00&lt;00:00, 4216.22it/s]
F1: 82.96 EM: 63.84 AVG: 73.40

saving new weights...

Epoch 2/3
-------------------------------
loss: 1.178375: 100%|█████████████| 2536/2536 [08:13&lt;00:00,  5.14it/s]
100%|█████████████████████████████| 805/805 [00:51&lt;00:00, 15.78it/s]
100%|█████████████████████████████| 3219/3219 [00:00&lt;00:00, 4375.79it/s]
F1: 84.97 EM: 65.52 AVG: 75.24

saving new weights...

Epoch 3/3
-------------------------------
loss: 1.010483: 100%|█████████████| 2536/2536 [08:13&lt;00:00,  5.14it/s]
100%|█████████████████████████████| 805/805 [00:51&lt;00:00, 15.77it/s]
100%|█████████████████████████████| 3219/3219 [00:00&lt;00:00, 4254.01it/s]
F1: 83.84 EM: 63.40 AVG: 73.62

Done!
</code></pre></div></div>

<p>可以看到，随着训练的进行，模型在验证集上的性能先升后降。因此，3 轮训练结束后，目录下只保存了前两轮训练后的模型权重：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch_1_valid_avg_73.3993_model_weights.bin
epoch_2_valid_avg_75.2441_model_weights.bin
</code></pre></div></div>

<p>至此，我们对 BERT 摘要模型的训练就完成了。</p>

<h2 id="3-测试模型">3. 测试模型</h2>

<p>训练完成后，我们加载在验证集上性能最优的模型权重，汇报其在测试集上的性能，并且将模型的预测结果保存到文件中。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'epoch_2_valid_avg_75.2441_model_weights.bin'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'evaluating on test set...'</span><span class="p">)</span>
    <span class="n">all_example_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_offset_mapping</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">offset_mapping</span><span class="p">,</span> <span class="n">example_ids</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
        <span class="n">all_example_ids</span> <span class="o">+=</span> <span class="n">example_ids</span>
        <span class="n">all_offset_mapping</span> <span class="o">+=</span> <span class="n">offset_mapping</span>
    <span class="n">example_to_features</span> <span class="o">=</span> <span class="n">collections</span><span class="p">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_example_ids</span><span class="p">):</span>
        <span class="n">example_to_features</span><span class="p">[</span><span class="n">feature_id</span><span class="p">].</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>

    <span class="n">start_logits</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pred_start_logits</span><span class="p">,</span> <span class="n">pred_end_logit</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">start_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_start_logits</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">end_logits</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_end_logit</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">start_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">start_logits</span><span class="p">)</span>
    <span class="n">end_logits</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">end_logits</span><span class="p">)</span>
    
    <span class="n">theoretical_answers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s">"id"</span><span class="p">:</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"id"</span><span class="p">],</span> <span class="s">"answers"</span><span class="p">:</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"answers"</span><span class="p">]}</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">))</span>
    <span class="p">]</span>
    <span class="n">predicted_answers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">save_resluts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">))):</span>
        <span class="n">example_id</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"id"</span><span class="p">]</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"context"</span><span class="p">]</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"title"</span><span class="p">]</span>
        <span class="n">question</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"question"</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"answers"</span><span class="p">]</span>
        <span class="n">answers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">feature_index</span> <span class="ow">in</span> <span class="n">example_to_features</span><span class="p">[</span><span class="n">example_id</span><span class="p">]:</span>
            <span class="n">start_logit</span> <span class="o">=</span> <span class="n">start_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">end_logit</span> <span class="o">=</span> <span class="n">end_logits</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>
            <span class="n">offsets</span> <span class="o">=</span> <span class="n">all_offset_mapping</span><span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>

            <span class="n">start_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">start_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">end_indexes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">end_logit</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="n">n_best</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">start_index</span> <span class="ow">in</span> <span class="n">start_indexes</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">end_index</span> <span class="ow">in</span> <span class="n">end_indexes</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">end_index</span> <span class="o">&lt;</span> <span class="n">start_index</span> <span class="ow">or</span> <span class="n">end_index</span><span class="o">-</span><span class="n">start_index</span><span class="o">+</span><span class="mi">1</span> <span class="o">&gt;</span> <span class="n">max_answer_length</span><span class="p">):</span>
                        <span class="k">continue</span>
                    <span class="n">answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s">"start"</span><span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> 
                        <span class="s">"text"</span><span class="p">:</span> <span class="n">context</span><span class="p">[</span><span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="p">:</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">][</span><span class="mi">1</span><span class="p">]],</span> 
                        <span class="s">"logit_score"</span><span class="p">:</span> <span class="n">start_logit</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span> <span class="o">+</span> <span class="n">end_logit</span><span class="p">[</span><span class="n">end_index</span><span class="p">],</span>
                    <span class="p">})</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">answers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">best_answer</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">answers</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s">"logit_score"</span><span class="p">])</span>
            <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"start"</span><span class="p">]</span>
            <span class="p">})</span>
            <span class="n">save_resluts</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"title"</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span> 
                <span class="s">"context"</span><span class="p">:</span> <span class="n">context</span><span class="p">,</span> 
                <span class="s">"question"</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> 
                <span class="s">"answers"</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"text"</span><span class="p">],</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="n">best_answer</span><span class="p">[</span><span class="s">"start"</span><span class="p">]</span>
            <span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predicted_answers</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="s">""</span><span class="p">,</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">})</span>
            <span class="n">save_resluts</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">example_id</span><span class="p">,</span> 
                <span class="s">"title"</span><span class="p">:</span> <span class="n">title</span><span class="p">,</span> 
                <span class="s">"context"</span><span class="p">:</span> <span class="n">context</span><span class="p">,</span> 
                <span class="s">"question"</span><span class="p">:</span> <span class="n">question</span><span class="p">,</span> 
                <span class="s">"answers"</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span> 
                <span class="s">"prediction_text"</span><span class="p">:</span> <span class="s">""</span><span class="p">,</span> 
                <span class="s">"answer_start"</span><span class="p">:</span> <span class="mi">0</span>
            <span class="p">})</span>
    <span class="n">eval_result</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">predicted_answers</span><span class="p">,</span> <span class="n">theoretical_answers</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"F1: </span><span class="si">{</span><span class="n">eval_result</span><span class="p">[</span><span class="s">'f1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> EM: </span><span class="si">{</span><span class="n">eval_result</span><span class="p">[</span><span class="s">'em'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> AVG: </span><span class="si">{</span><span class="n">eval_result</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'saving predicted results...'</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'test_data_pred.json'</span><span class="p">,</span> <span class="s">'wt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">example_result</span> <span class="ow">in</span> <span class="n">save_resluts</span><span class="p">:</span>
            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">example_result</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>evaluating on test set...
100%|█████████████████████████████| 251/251 [00:15&lt;00:00, 15.95it/s]
100%|█████████████████████████████| 1002/1002 [00:00&lt;00:00, 3243.72it/s]
F1: 69.10 EM: 31.47 AVG: 50.29

saving predicted results...
</code></pre></div></div>

<p>可以看到，最终问答模型在测试集上取得了 F1 值 69.10、EM 值 31.47 的结果。考虑到我们只使用了基础版本的 BERT 模型，并且只训练了 3 轮，这已经是一个不错的结果了。</p>

<p>我们打开保存预测结果的 <em>test_data_pred.json</em>，其中每一行对应一个样本，<code class="language-plaintext highlighter-rouge">sentence</code> 对应原文，<code class="language-plaintext highlighter-rouge">pred_label</code> 对应预测出的实体，<code class="language-plaintext highlighter-rouge">true_label</code> 对应标注实体信息。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  "id": "TRIAL_800_QUERY_0", 
  "title": "泡泡战士", 
  "context": "基于《跑跑卡丁车》与《泡泡堂》上所开发的游戏，由韩国Nexon开发与发行。中国大陆由盛大游戏运营，这是Nexon时隔6年再次授予盛大网络其游戏运营权。台湾由游戏橘子运营。玩家以水枪、小枪、锤子或是水炸弹泡封敌人(玩家或NPC)，即为一泡封，将水泡击破为一踢爆。若水泡未在时间内踢爆，则会从水泡中释放或被队友救援(即为一救援)。每次泡封会减少生命数，生命数耗完即算为踢爆。重生者在一定时间内为无敌状态，以踢爆数计分较多者获胜，规则因模式而有差异。以2V2、4V4随机配对的方式，玩家可依胜场数爬牌位(依序为原石、铜牌、银牌、金牌、白金、钻石、大师) ，可选择经典、热血、狙击等模式进行游戏。若游戏中离，则4分钟内不得进行配对(每次中离+4分钟)。开放时间为暑假或寒假期间内不定期开放，8人经典模式随机配对，采计分方式，活动时间内分数越多，终了时可依该名次获得奖励。", 
  "question": "生命数耗完即算为什么？", 
  "answers": {
    "text": ["踢爆"], 
    "answer_start": [127]
  }, 
  "prediction_text": "踢爆", 
  "answer_start": 182
}
...
</code></pre></div></div>

<p>至此，我们使用 Transformers 库进行抽取式问答任务就全部完成了！</p>

<h2 id="代码">代码</h2>

<p>与之前一样，我们按照功能将代码拆分成模块并且存放在不同的文件中，整理后的代码存储在 Github：
<a href="https://github.com/jsksxs360/How-to-use-Transformers/tree/main/src/sequence_labeling_extractiveQA_cmrc">How-to-use-Transformers/src/sequence_labeling_extractiveQA_cmrc/</a></p>

<p>与 Transformers 库类似，我们将模型损失的计算也包含进模型本身，这样在训练循环中我们就可以直接使用模型返回的损失进行反向传播。</p>

<p>运行 <em>run_extractiveQA.sh</em> 脚本即可进行训练。如果要进行测试或者将模型输出的翻译结果保存到文件，只需把脚本中的 <code class="language-plaintext highlighter-rouge">--do_train</code> 改成 <code class="language-plaintext highlighter-rouge">--do_test</code> 或 <code class="language-plaintext highlighter-rouge">--do_predict</code>。</p>

<blockquote>
  <p>经过 3 轮训练，最终 BERT 模型在测试集上的 F1 和 EM 值分别为  67.96 和 31.84 （Nvidia Tesla V100, batch=4）。</p>
</blockquote>

<h2 id="参考">参考</h2>

<p><a href="https://huggingface.co/course/chapter1/1">[1]</a> HuggingFace 在线教程<br />
<a href="https://pytorch.org/docs/stable/">[2]</a> Pytorch 官方文档<br />
<a href="https://huggingface.co/docs/transformers/index">[3]</a> Transformers 官方文档</p>]]></content><author><name>SHENG XU</name></author><category term="NLP" /><summary type="html"><![CDATA[本文我们将运用 Transformers 库来完成抽取式问答任务。自动问答 (Question Answering, QA) 是经典的 NLP 任务，需要模型基于给定的上下文回答问题。]]></summary></entry><entry><title type="html">第十一章：文本摘要任务</title><link href="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-29-transformers-note-8.html" rel="alternate" type="text/html" title="第十一章：文本摘要任务" /><published>2022-03-29T00:00:00+08:00</published><updated>2022-03-29T00:00:00+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/nlp/transformers-note-8</id><content type="html" xml:base="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-29-transformers-note-8.html"><![CDATA[<p>本文我们将运用 Transformers 库来完成文本摘要任务。与我们上一章进行的翻译任务一样，文本摘要同样是一个 Seq2Seq 任务，旨在尽可能保留文本语义的情况下将长文本压缩为短文本。</p>

<p>虽然 Hugging Face 已经提供了很多<a href="https://huggingface.co/models?pipeline_tag=summarization&amp;sort=downloads">文本摘要模型</a>，但是它们大部分只能处理英文，因此本文将微调一个多语言文本摘要模型用于完成中文摘要：为新浪微博短新闻生成摘要。</p>

<p>文本摘要可以看作是将长文本“翻译”为捕获关键信息的短文本，因此大部分文本摘要模型同样采用 Encoder-Decoder 框架。当然，也有一些非  Encoder-Decoder 框架的摘要模型，例如 GPT 家族也可以通过小样本学习 (few-shot) 进行文本摘要。</p>

<p>下面是一些目前流行的可用于文本摘要的模型：</p>

<ul>
  <li><strong><a href="https://huggingface.co/gpt2-xl">GPT-2</a>：</strong>虽然是自回归 (auto-regressive) 语言模型，但是可以通过在输入文本的末尾添加 <code class="language-plaintext highlighter-rouge">TL;DR</code> 来使 GPT-2 生成摘要；</li>
  <li><strong><a href="https://huggingface.co/google/pegasus-large">PEGASUS</a>：</strong>与大部分语言模型通过预测被遮掩掉的词语来进行训练不同，PEGASUS 通过预测被遮掩掉的句子来进行训练。由于预训练目标与摘要任务接近，因此 PEGASUS 在摘要任务上的表现很好；</li>
  <li><strong><a href="https://huggingface.co/t5-base">T5</a>：</strong>将各种 NLP 任务都转换到 text-to-text 框架来完成的通用 Transformer 架构，要进行摘要任务只需在输入文本前添加 <code class="language-plaintext highlighter-rouge">summarize:</code> 前缀；</li>
  <li><strong><a href="https://huggingface.co/google/mt5-base">mT5</a>：</strong>T5 的多语言版本，在多语言通用爬虫语料库 mC4 上预训练，覆盖 101 种语言；</li>
  <li><strong><a href="https://huggingface.co/facebook/bart-base">BART</a>：</strong>包含一个 Encoder 和一个 Decoder stack 的 Transformer 架构，训练目标是重构损坏的输入，同时还结合了 BERT 和 GPT-2 的预训练方案；</li>
  <li><strong><a href="https://huggingface.co/facebook/mbart-large-50">mBART-50</a>：</strong>BART 的多语言版本，在 50 种语言上进行了预训练。</li>
</ul>

<p>T5 模型通过模板前缀 (prompt prefix) 将各种 NLP 任务都转换到 text-to-text 框架进行预训练，例如摘要任务的前缀就是 <code class="language-plaintext highlighter-rouge">summarize:</code>，模型以前缀作为条件生成符合模板的文本，这使得一个模型就可以完成多种 NLP 任务：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-8/t5.png" alt="t5.png" style="display: block; margin: auto; width: 700px" /></p>

<p>在本文中，我们将专注于微调多语言 mT5 模型用于中文摘要任务，mT5 模型不使用前缀，但是具备 T5 模型大部分的多功能性。</p>

<h2 id="1-准备数据">1. 准备数据</h2>

<p>我们选择大规模中文短文本摘要语料库 <a href="http://icrc.hitsz.edu.cn/Article/show/139.html">LCSTS</a> 作为数据集，该语料基于新浪微博短新闻构建，规模超过 200 万。这里我们直接从<a href="https://www.heywhale.com/mw/dataset/5f05ae9c3af6a6002d0f0997">和鲸社区</a>或<a href="https://pan.baidu.com/s/10zbcluvILlL8J-KnX56Fgw?pwd=xszb">百度云盘</a>下载用户处理好的 LCSTS 语料。</p>

<p>我们简单地将新闻的标题作为摘要来微调 mT5 模型以完成文本摘要任务。</p>

<p>该语料已经划分好了训练集、验证集和测试集，分别包含 2400591 / 10666 / 1106 个样本，一行是一个“标题!=!正文”的组合：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>媒体融合关键是以人为本!=!受众在哪里，媒体就应该在哪里，媒体的体制、内容、技术就应该向哪里转变。媒体融合关键是以人为本，即满足大众的信息需求，为受众提供更优质的服务。这就要求媒体在融合发展的过程中，既注重技术创新，又注重用户体验。
</code></pre></div></div>

<h3 id="构建数据集">构建数据集</h3>

<p>与之前一样，我们首先编写继承自 <code class="language-plaintext highlighter-rouge">Dataset</code> 类的自定义数据集用于组织样本和标签。考虑到使用 LCSTS 两百多万条样本进行训练耗时过长，这里我们只抽取训练集中的前 20 万条数据：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">max_dataset_size</span> <span class="o">=</span> <span class="mi">200000</span>

<span class="k">class</span> <span class="nc">LCSTS</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">max_dataset_size</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'!=!'</span><span class="p">)</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'title'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="s">'content'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'data/lcsts_tsv/data1.tsv'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'data/lcsts_tsv/data2.tsv'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'data/lcsts_tsv/data3.tsv'</span><span class="p">)</span>
</code></pre></div></div>

<p>下面我们输出数据集的尺寸，并且打印出一个训练样本：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'train set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'valid set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'test set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_data</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train set size: 200000
valid set size: 10666
test set size: 1106
{'title': '修改后的立法法全文公布', 'content': '新华社受权于18日全文播发修改后的《中华人民共和国立法法》，修改后的立法法分为“总则”“法律”“行政法规”“地方性法规、自治条例和单行条例、规章”“适用与备案审查”“附则”等6章，共计105条。'}
</code></pre></div></div>

<h3 id="数据预处理">数据预处理</h3>

<p>接下来，我们就需要通过 <code class="language-plaintext highlighter-rouge">DataLoader</code> 库按 batch 加载数据，将文本转换为模型可以接受的 token IDs。与<a href="/2022/03/24/transformers-note-7.html">翻译</a>任务类似，我们需要运用分词器对原文和摘要都进行编码，这里我们选择 <a href="https://csebuetnlp.github.io/">BUET CSE NLP Group</a> 提供的 <a href="https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum">mT5 摘要模型</a>：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"csebuetnlp/mT5_multilingual_XLSum"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
</code></pre></div></div>

<p>我们先尝试使用 mT5 tokenizer 对文本进行分词：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s">"我叫张三，在苏州大学学习计算机。"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">input_ids</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'input_ids': [259, 3003, 27333, 8922, 2092, 261, 1083, 117707, 9792, 24920, 123553, 306, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
['▁', '我', '叫', '张', '三', ',', '在', '苏州', '大学', '学习', '计算机', '。', '&lt;/s&gt;']
</code></pre></div></div>

<p>特殊的 Unicode 字符 <code class="language-plaintext highlighter-rouge">▁</code> 以及序列结束 token <code class="language-plaintext highlighter-rouge">&lt;/s&gt;</code> 表明 mT5 模型采用的是基于 Unigram 切分算法的 SentencePiece 分词器。Unigram 对于处理多语言语料库特别有用，它使得 SentencePiece 可以在不知道重音、标点符号以及没有空格分隔字符（例如中文）的情况下对文本进行分词。</p>

<p>与翻译任务类似，摘要任务的输入和标签都是文本，这里我们同样使用分词器提供的 <code class="language-plaintext highlighter-rouge">as_target_tokenizer()</code> 函数来并行地对输入和标签进行分词，并且同样将标签序列中填充的 pad 字符设置为 -100 以便在计算交叉熵损失时忽略它们，以及通过模型自带的 <code class="language-plaintext highlighter-rouge">prepare_decoder_input_ids_from_labels</code> 函数对标签进行移位操作以准备好 decoder input IDs：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="n">max_input_length</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'content'</span><span class="p">])</span>
        <span class="n">batch_targets</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'title'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_inputs</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_input_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">as_target_tokenizer</span><span class="p">():</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">batch_targets</span><span class="p">,</span> 
            <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
        <span class="p">)[</span><span class="s">"input_ids"</span><span class="p">]</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'decoder_input_ids'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">prepare_decoder_input_ids_from_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">end_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">end_token_index</span><span class="p">):</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">end_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">batch_data</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
</code></pre></div></div>

<p>由于本文直接使用 Transformers 库自带的 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 函数来构建模型，因此我们将每一个 batch 中的数据都处理为该模型可接受的格式：一个包含 <code class="language-plaintext highlighter-rouge">'attention_mask'</code>、<code class="language-plaintext highlighter-rouge">'input_ids'</code>、<code class="language-plaintext highlighter-rouge">'labels'</code> 和 <code class="language-plaintext highlighter-rouge">'decoder_input_ids'</code> 键的字典。</p>

<p>下面我们尝试打印出一个 batch 的数据，以验证是否处理正确：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])
batch shape: {
    'input_ids': torch.Size([4, 78]), 
    'attention_mask': torch.Size([4, 78]), 
    'decoder_input_ids': torch.Size([4, 23]), 
    'labels': torch.Size([4, 23])
}
{'input_ids': tensor([
        [   259,  46420,   1083,  73451,    493,   3582,  14219,  98660, 111234,
           9455,  10139,    261,  11688,  56462,   7031,  71079,  31324,  94274,
           2037, 203743,   9911,  16834,   1107,   6929,  31063,    306,   2372,
            891,    261, 221805,   1455,  31571, 118447,    493,  56462,   7031,
          71079, 124732,   3937,  23224,   2037, 203743,   9911, 199662,  22064,
          31063,    261,   7609,   5705,  18988, 160700, 154547,  43803,  40678,
           3519,    306,      1,      0,      0,      0,      0,      0,      0,
              0,      0,      0,      0,      0,      0,      0,      0,      0,
              0,      0,      0,      0,      0,      0],
        [   259, 101737,  36059,    261, 157186,  47685,   8854, 124583, 218664,
           5705,   8363,   7216,  30921,  27032,  59754, 127646,  62558,  98901,
            261,   8868,   4110,   5705,  73334,  25265,  26553,   4153,    261,
           7274,  58402,   5435,  12914,    591,   2991, 162028,  22151,   4925,
         157186,  34499, 101737,  36059,  14520,  11201,  89746,  11017,    261,
           3763,   8868, 157186,  47685,   8854, 150259,  90707,   4417,  35388,
           3751,   2037,   3763, 194391,  81024,    261, 124025, 239583,  72939,
            306,   4925,  28216,  11242,  51563,   3094,    261, 157186, 142783,
           8868,  51191,  43239,   3763,    306,      1],
        [   259,  13732,   5705, 165437,  36814,  29650,    261, 120834, 201540,
          64493,  36814,  69169,    306,  13381,   5859,  14456,  21562,  16408,
         201540,   9692,   1374, 116772,  35988,   2188,  36079, 214133,    261,
          13505,   9127,   2542, 161781, 101017,    261, 101737,  36059,   7321,
          14219,   7519,  21929,    460, 100987,    261,   9903,   5848,  72308,
         101017,    261,   2123,  19394, 164872,   5162, 125883,  21562,  43138,
          37575,  15937,  66211,   5162,   3377,    848,  27349,   2446, 198562,
         154832,    261,  11883,  65386,    353, 106219,    261,  27674,    939,
          76364,   5507,  31568,   9809,  54172,      1],
        [   259,  77554,   1193,  74380,    493,    590,    487,    538,    495,
         198437,   8041,   6907, 219169, 122000,  10220,  28426,   6994,  36236,
          74380,  30733,    306,  40921, 218505,   1083,   5685,  14469,   2884,
           1637, 198437,  17723,  94708,  22695,    306,  12267,   1374,  13733,
           1543, 224495, 164497,  17286, 143553,  30464, 198437,  17723, 113940,
         176540, 143553,    306,  36017,   1374,  13733,  13342,  88397,  94708,
          22695,    261,   1083,   5685,  14469,  10458,   9692,   4070,  13342,
         115813,  27385,    306,      1,      0,      0,      0,      0,      0,
              0,      0,      0,      0,      0,      0]]), 
 'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0]]), 
 'decoder_input_ids': tensor([
        [     0,    259,  11688,  56462,   7031,  71079,  73451,   3592,   3751,
           9911,  17938,  16834,   1107,   6929,  31063,  63095,    291,      1,
              0,      0,      0,      0,      0],
        [     0,    259, 157186,  47685,   8854, 107850,  14520,  11201,  89746,
          11017,  10973,   2219, 239583,  72939, 108358,    267,   1597,  43239,
          11242,  51563,   3094,      1,      0],
        [     0,    259,  13732,   2123,  19394,  94689,   2029,  26544,  17684,
           4074,  33119,  62428,  76364,      1,      0,      0,      0,      0,
              0,      0,      0,      0,      0],
        [     0,    447,    487,    538,    495, 198437,   8041,   6907,  86248,
          74380, 100644,  12267,    338, 225859,    261,  40921,    353,   3094,
          53737,   1083,  16311,  58407,  23616]]), 
 'labels': tensor([
        [   259,  11688,  56462,   7031,  71079,  73451,   3592,   3751,   9911,
          17938,  16834,   1107,   6929,  31063,  63095,    291,      1,   -100,
           -100,   -100,   -100,   -100,   -100],
        [   259, 157186,  47685,   8854, 107850,  14520,  11201,  89746,  11017,
          10973,   2219, 239583,  72939, 108358,    267,   1597,  43239,  11242,
          51563,   3094,      1,   -100,   -100],
        [   259,  13732,   2123,  19394,  94689,   2029,  26544,  17684,   4074,
          33119,  62428,  76364,      1,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100],
        [   447,    487,    538,    495, 198437,   8041,   6907,  86248,  74380,
         100644,  12267,    338, 225859,    261,  40921,    353,   3094,  53737,
           1083,  16311,  58407,  23616,      1]])}
</code></pre></div></div>

<p>可以看到，DataLoader 按照我们设置的 <code class="language-plaintext highlighter-rouge">batch_size=4</code> 对样本进行编码，并且填充 pad token 对应的标签都被设置为 -100。我们构建的 Decoder 的输入 decoder input IDs 尺寸与标签序列完全相同，且通过向后移位在序列头部添加了特殊的“序列起始符”，例如第一个样本：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'labels': 
        [   259,  11688,  56462,   7031,  71079,  73451,   3592,   3751,   9911,
          17938,  16834,   1107,   6929,  31063,  63095,    291,      1,   -100,
           -100,   -100,   -100,   -100,   -100]
'decoder_input_ids': 
        [     0,    259,  11688,  56462,   7031,  71079,  73451,   3592,   3751,
           9911,  17938,  16834,   1107,   6929,  31063,  63095,    291,      1,
              0,      0,      0,      0,      0]
</code></pre></div></div>

<p>至此，数据预处理部分就全部完成了！</p>

<blockquote>
  <p>在大部分情况下，即使我们在 batch 数据中没有包含 decoder input IDs，模型也能正常训练，它会自动调用模型的 <code class="language-plaintext highlighter-rouge">prepare_decoder_input_ids_from_labels</code> 函数来构造 <code class="language-plaintext highlighter-rouge">decoder_input_ids</code>。</p>
</blockquote>

<h2 id="2-训练模型">2. 训练模型</h2>

<p>本文直接使用 Transformers 库自带的 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 函数来构建模型，因此下面只需要实现 Epoch 中的”训练循环”和”验证/测试循环”。</p>

<blockquote>
  <p>这里我们同样没有自己编写模型，因为 Seq2Seq 模型的结构都较为复杂（包含编码解码以及彼此交互的各种操作），如果自己实现需要编写大量的辅助函数。</p>
</blockquote>

<h3 id="优化模型参数">优化模型参数</h3>

<p>使用 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 构造的模型已经封装好了对应的损失函数，并且计算出的损失会直接包含在模型的输出 <code class="language-plaintext highlighter-rouge">outputs</code> 中，可以直接通过 <code class="language-plaintext highlighter-rouge">outputs.loss</code> 获得，因此训练循环为：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>
</code></pre></div></div>

<p>验证/测试循环负责评估模型的性能。对于文本摘要任务，常用评估指标是 <a href="https://en.wikipedia.org/wiki/ROUGE_(metric)">ROUGE 值</a> (short for Recall-Oriented Understudy for Gisting Evaluation)，它可以度量两个词语序列之间的词语重合率。ROUGE 值的召回率表示参考摘要在多大程度上被生成摘要覆盖，如果我们只比较词语，那么召回率就是：</p>

\[\text{Recall} = \frac{\text{Number of overlapping words}}{\text{Total number of words in reference summary}}\]

<p>准确率则表示生成的摘要中有多少词语与参考摘要相关：</p>

\[\text{Precision}=\frac{\text{Number of overlapping words}}{\text{Total number of words in generated summary}}\]

<p>最后再基于准确率和召回率来计算 F1 值。实际操作中，我们可以通过 <a href="https://github.com/pltrdy/rouge">rouge 库</a>来方便地计算这些 ROUGE 值，例如 ROUGE-1 度量 uni-grams 的重合情况，ROUGE-2 度量 bi-grams 的重合情况，而 ROUGE-L 则通过在生成摘要和参考摘要中寻找最长公共子串来度量最长的单词匹配序列，例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">rouge</span> <span class="kn">import</span> <span class="n">Rouge</span>

<span class="n">generated_summary</span> <span class="o">=</span> <span class="s">"I absolutely loved reading the Hunger Games"</span>
<span class="n">reference_summary</span> <span class="o">=</span> <span class="s">"I loved reading the Hunger Games"</span>

<span class="n">rouge</span> <span class="o">=</span> <span class="n">Rouge</span><span class="p">()</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="p">.</span><span class="n">get_scores</span><span class="p">(</span>
    <span class="n">hyps</span><span class="o">=</span><span class="p">[</span><span class="n">generated_summary</span><span class="p">],</span> <span class="n">refs</span><span class="o">=</span><span class="p">[</span><span class="n">reference_summary</span><span class="p">]</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
 'rouge-1': {'r': 1.0, 'p': 0.8571428571428571, 'f': 0.9230769181065088}, 
 'rouge-2': {'r': 0.8, 'p': 0.6666666666666666, 'f': 0.7272727223140496}, 
 'rouge-l': {'r': 1.0, 'p': 0.8571428571428571, 'f': 0.9230769181065088}
}
</code></pre></div></div>

<p>rouge 库默认使用空格进行分词，因此无法处理中文、日文等语言，最简单的办法是按字进行切分，当然也可以使用分词器分词后再进行计算，否则会计算出不正确的 ROUGE 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">rouge</span> <span class="kn">import</span> <span class="n">Rouge</span>

<span class="n">generated_summary</span> <span class="o">=</span> <span class="s">"我在苏州大学学习计算机，苏州大学很美丽。"</span>
<span class="n">reference_summary</span> <span class="o">=</span> <span class="s">"我在环境优美的苏州大学学习计算机。"</span>

<span class="n">rouge</span> <span class="o">=</span> <span class="n">Rouge</span><span class="p">()</span>

<span class="n">TOKENIZE_CHINESE</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># from transformers import AutoTokenizer
# model_checkpoint = "csebuetnlp/mT5_multilingual_XLSum"
# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
</span>
<span class="c1"># TOKENIZE_CHINESE = lambda x: ' '.join(
#     tokenizer.convert_ids_to_tokens(tokenizer(x).input_ids, skip_special_tokens=True)
# )
</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="p">.</span><span class="n">get_scores</span><span class="p">(</span>
    <span class="n">hyps</span><span class="o">=</span><span class="p">[</span><span class="n">TOKENIZE_CHINESE</span><span class="p">(</span><span class="n">generated_summary</span><span class="p">)],</span> 
    <span class="n">refs</span><span class="o">=</span><span class="p">[</span><span class="n">TOKENIZE_CHINESE</span><span class="p">(</span><span class="n">reference_summary</span><span class="p">)]</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'ROUGE:'</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="p">.</span><span class="n">get_scores</span><span class="p">(</span>
    <span class="n">hyps</span><span class="o">=</span><span class="p">[</span><span class="n">generated_summary</span><span class="p">],</span> 
    <span class="n">refs</span><span class="o">=</span><span class="p">[</span><span class="n">reference_summary</span><span class="p">]</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">'wrong ROUGE:'</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ROUGE: {
 'rouge-1': {'r': 0.75, 'p': 0.8, 'f': 0.7741935433922998}, 
 'rouge-2': {'r': 0.5625, 'p': 0.5625, 'f': 0.562499995}, 
 'rouge-l': {'r': 0.6875, 'p': 0.7333333333333333, 'f': 0.7096774143600416}
}
wrong ROUGE: {
 'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 
 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 
 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}
}
</code></pre></div></div>

<p>在上一章中我们说过，<code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 模型对 Decoder 的解码过程也进行了封装，我们只需要调用模型的 <code class="language-plaintext highlighter-rouge">generate()</code> 函数就可以自动地逐个生成预测 token。例如，我们可以直接调用预训练好的 mT5 摘要模型生成摘要（使用柱搜索解码，num_beams=4，并且不允许出现 2-gram 重复）：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"csebuetnlp/mT5_multilingual_XLSum"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">article_text</span> <span class="o">=</span> <span class="s">"""
受众在哪里，媒体就应该在哪里，媒体的体制、内容、技术就应该向哪里转变。
媒体融合关键是以人为本，即满足大众的信息需求，为受众提供更优质的服务。
这就要求媒体在融合发展的过程中，既注重技术创新，又注重用户体验。
"""</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">article_text</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span>
<span class="p">)</span>
<span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_ids</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">4</span>
<span class="p">)</span>
<span class="n">summary</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span>
    <span class="n">generated_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cpu device
媒体融合发展是当下中国面临的一大难题。
</code></pre></div></div>

<p>当然了，摘要多个句子也没有问题：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">article_texts</span> <span class="o">=</span> <span class="p">[</span>
<span class="s">"""
受众在哪里，媒体就应该在哪里，媒体的体制、内容、技术就应该向哪里转变。
媒体融合关键是以人为本，即满足大众的信息需求，为受众提供更优质的服务。
这就要求媒体在融合发展的过程中，既注重技术创新，又注重用户体验。
"""</span><span class="p">,</span>
<span class="s">"""
新华社受权于18日全文播发修改后的《中华人民共和国立法法》，
修改后的立法法分为“总则”“法律”“行政法规”“地方性法规、
自治条例和单行条例、规章”“适用与备案审查”“附则”等6章，共计105条。
"""</span>
<span class="p">]</span>

<span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">article_texts</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span>
<span class="p">)</span>
<span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">input_ids</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">4</span>
<span class="p">)</span>
<span class="n">summarys</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span>
    <span class="n">generated_tokens</span><span class="p">,</span>
    <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">summarys</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
 '媒体融合发展是当下中国面临的一大难题。', 
 '中国官方新华社周一(18日)全文播发修改后的《中华人民共和国立法法》。'
]
</code></pre></div></div>

<p>在验证/测试循环中，我们首先通过 <code class="language-plaintext highlighter-rouge">model.generate()</code> 函数获取预测结果，然后将预测结果和正确标签都处理为 rouge 库接受的文本列表格式（这里我们将标签序列中的 -100 替换为 pad token ID 以便于分词器解码），最后送入到 rouge 库计算各项 ROUGE 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">rouge</span> <span class="kn">import</span> <span class="n">Rouge</span>

<span class="n">rouge</span> <span class="o">=</span> <span class="n">Rouge</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
                <span class="n">num_beams</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">generated_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">[</span><span class="s">"labels"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">label_tokens</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">label_tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
        <span class="n">decoded_labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">preds</span> <span class="o">+=</span> <span class="p">[</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">decoded_preds</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">decoded_labels</span><span class="p">]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="p">.</span><span class="n">get_scores</span><span class="p">(</span><span class="n">hyps</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">refs</span><span class="o">=</span><span class="n">labels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="s">'f'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">result</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Rouge1: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'rouge-1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> Rouge2: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'rouge-2'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> RougeL: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'rouge-l'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>为了方便后续保存验证集上最好的模型，我们还在验证/测试循环中返回评估出的 ROUGE 值。</p>

<h3 id="保存模型">保存模型</h3>

<p>与之前一样，我们会根据模型在验证集上的性能来调整超参数以及选出最好的模型，然后将选出的模型应用于测试集以评估最终的性能。这里我们继续使用 AdamW 优化器，并且通过 <code class="language-plaintext highlighter-rouge">get_scheduler()</code> 函数定义学习率调度器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_avg_rouge</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_rouge</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">valid_rouge</span><span class="p">)</span>
    <span class="n">rouge_avg</span> <span class="o">=</span> <span class="n">valid_rouge</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">rouge_avg</span> <span class="o">&gt;</span> <span class="n">best_avg_rouge</span><span class="p">:</span>
        <span class="n">best_avg_rouge</span> <span class="o">=</span> <span class="n">rouge_avg</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_rouge_</span><span class="si">{</span><span class="n">rouge_avg</span><span class="si">:</span><span class="mf">0.4</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<p>在开始训练之前，我们先评估一下没有经过微调的模型在 LCSTS 测试集上的性能。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'lcsts_tsv/data3.tsv'</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="n">test_loop</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device
100%|███████████| 35/35 [01:07&lt;00:00,  1.92s/it]
Rouge1: 20.00 Rouge2: 14.29 RougeL: 20.00
</code></pre></div></div>

<p>可以看到预训练模型在我们测试集上的 ROUGE-1、ROUGE-2、ROUGE-L 值分别为 20.00、14.29 和 20.00，说明该模型具备文本摘要的能力，但是在“短文本新闻摘要”任务上表现不佳。然后，我们正式开始训练，完整代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">rouge</span> <span class="kn">import</span> <span class="n">Rouge</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">max_dataset_size</span> <span class="o">=</span> <span class="mi">200000</span>
<span class="n">max_input_length</span> <span class="o">=</span> <span class="mi">512</span>
<span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_batch_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">test_batch_size</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">beam_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">no_repeat_ngram_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">LCSTS</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">max_dataset_size</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">items</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'!=!'</span><span class="p">)</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">items</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'title'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                    <span class="s">'content'</span><span class="p">:</span> <span class="n">items</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'lcsts_tsv/data1.tsv'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'lcsts_tsv/data2.tsv'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'lcsts_tsv/data3.tsv'</span><span class="p">)</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"csebuetnlp/mT5_multilingual_XLSum"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'content'</span><span class="p">])</span>
        <span class="n">batch_targets</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'title'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_inputs</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_input_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">as_target_tokenizer</span><span class="p">():</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">batch_targets</span><span class="p">,</span> 
            <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
        <span class="p">)[</span><span class="s">"input_ids"</span><span class="p">]</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'decoder_input_ids'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">prepare_decoder_input_ids_from_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">end_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">end_token_index</span><span class="p">):</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">end_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">batch_data</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">test_batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>

<span class="n">rouge</span> <span class="o">=</span> <span class="n">Rouge</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'Test'</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'Valid'</span><span class="p">,</span> <span class="s">'Test'</span><span class="p">]</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
                <span class="n">num_beams</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
                <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="n">no_repeat_ngram_size</span><span class="p">,</span>
            <span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">generated_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">[</span><span class="s">"labels"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">label_tokens</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">label_tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
        <span class="n">decoded_labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">preds</span> <span class="o">+=</span> <span class="p">[</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">decoded_preds</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">label</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">decoded_labels</span><span class="p">]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="p">.</span><span class="n">get_scores</span><span class="p">(</span><span class="n">hyps</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">refs</span><span class="o">=</span><span class="n">labels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="s">'f'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">result</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">result</span><span class="p">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s"> Rouge1: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'rouge-1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> Rouge2: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'rouge-2'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> RougeL: </span><span class="si">{</span><span class="n">result</span><span class="p">[</span><span class="s">'rouge-l'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_avg_rouge</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_rouge</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'Valid'</span><span class="p">)</span>
    <span class="n">rouge_avg</span> <span class="o">=</span> <span class="n">valid_rouge</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">rouge_avg</span> <span class="o">&gt;</span> <span class="n">best_avg_rouge</span><span class="p">:</span>
        <span class="n">best_avg_rouge</span> <span class="o">=</span> <span class="n">rouge_avg</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_rouge_</span><span class="si">{</span><span class="n">rouge_avg</span><span class="si">:</span><span class="mf">0.4</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/3
-------------------------------
loss: 3.544795: 100%|██████████| 6250/6250 [42:02&lt;00:00,  2.48it/s]
100%|██████████████████████████| 334/334 [06:38&lt;00:00,  1.19s/it]
Rouge1: 13.33 Rouge2: 0.00 RougeL: 6.67

saving new weights...

Epoch 2/3
-------------------------------
loss: 3.448048: 100%|██████████| 6250/6250 [42:01&lt;00:00,  2.48it/s]
100%|██████████████████████████| 334/334 [06:33&lt;00:00,  1.18s/it]
Rouge1: 13.33 Rouge2: 0.00 RougeL: 6.67

Epoch 3/3
-------------------------------
loss: 3.398337: 100%|██████████| 6250/6250 [42:01&lt;00:00,  2.48it/s]
100%|██████████████████████████| 334/334 [06:28&lt;00:00,  1.16s/it]
Rouge1: 13.33 Rouge2: 0.00 RougeL: 6.67

Done!
</code></pre></div></div>

<p>可以看到，3 轮训练中，模型在验证集上的 ROUGE 值没有发生变化，首轮训练后模型参数就已经收敛，达到了最好的性能。因此，3 轮训练结束后，目录下只保存了首轮训练后的模型权重：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch_1_valid_rouge_6.6667_model_weights.bin
</code></pre></div></div>

<p>至此，我们对 mT5 摘要模型的训练（微调）过程就完成了。</p>

<h2 id="3-测试模型">3. 测试模型</h2>

<p>训练完成后，我们加载在验证集上性能最优的模型权重，汇报其在测试集上的性能，并且将模型的预测结果保存到文件中。</p>

<p>由于 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 对整个解码过程进行了封装，我们只需要调用 <code class="language-plaintext highlighter-rouge">generate()</code> 函数就可以自动通过 beam search 找到最佳的 token ID 序列，因此最后只需要再使用分词器将 token ID 序列转换为文本就可以获得生成的摘要：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_data</span> <span class="o">=</span> <span class="n">LCSTS</span><span class="p">(</span><span class="s">'data/lcsts_tsv/data3.tsv'</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">json</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'epoch_1_valid_rouge_6.6667_model_weights.bin'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'evaluating on test set...'</span><span class="p">)</span>
    <span class="n">sources</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="n">num_beams</span><span class="o">=</span><span class="n">beam_size</span><span class="p">,</span>
            <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="n">no_repeat_ngram_size</span><span class="p">,</span>
        <span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">generated_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">[</span><span class="s">"labels"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">decoded_sources</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span>
            <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> 
            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">use_source_tokenizer</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">label_tokens</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">label_tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
        <span class="n">decoded_labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">sources</span> <span class="o">+=</span> <span class="p">[</span><span class="n">source</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">decoded_sources</span><span class="p">]</span>
        <span class="n">preds</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pred</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">decoded_preds</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[</span><span class="n">label</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">decoded_labels</span><span class="p">]</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="p">.</span><span class="n">get_scores</span><span class="p">(</span>
        <span class="n">hyps</span><span class="o">=</span><span class="p">[</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">],</span> 
        <span class="n">refs</span><span class="o">=</span><span class="p">[</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">rouges</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="p">[</span><span class="s">'f'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">rouges</span><span class="p">[</span><span class="s">'avg'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">rouges</span><span class="p">.</span><span class="n">values</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Test Rouge1: </span><span class="si">{</span><span class="n">rouges</span><span class="p">[</span><span class="s">'rouge-1'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> Rouge2: </span><span class="si">{</span><span class="n">rouges</span><span class="p">[</span><span class="s">'rouge-2'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s"> RougeL: </span><span class="si">{</span><span class="n">rouges</span><span class="p">[</span><span class="s">'rouge-l'</span><span class="p">]</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'saving predicted results...'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">source</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s">"document"</span><span class="p">:</span> <span class="n">source</span><span class="p">,</span> 
            <span class="s">"prediction"</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span> 
            <span class="s">"summarization"</span><span class="p">:</span> <span class="n">label</span>
        <span class="p">})</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'test_data_pred.json'</span><span class="p">,</span> <span class="s">'wt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">exapmle_result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">exapmle_result</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device
evaluating on test set...
100%|██████████████████████████| 35/35 [00:42&lt;00:00,  1.22s/it]
Test Rouge1: 70.00 Rouge2: 55.56 RougeL: 70.00

saving predicted results...
</code></pre></div></div>

<p>可以看到，经过我们的微调，模型在测试集上的 ROUGE-1、ROUGE-2 和 ROUGE-L 值分别从 20.00、14.29、20.00 提升到了 70.00、55.56、70.00，证明了我们对模型的微调是成功的。</p>

<p>我们打开保存预测结果的 <em>test_data_pred.json</em>，其中每一行对应一个样本，<code class="language-plaintext highlighter-rouge">document</code> 对应原文，<code class="language-plaintext highlighter-rouge">prediction</code> 对应模型生成的摘要，<code class="language-plaintext highlighter-rouge">summarization</code> 对应参考摘要。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  "document": "本文总结了十个可穿戴产品的设计原则,而这些原则,同样也是笔者认为是这个行业最吸引人的地方:1.为人们解决重复性问题;2.从人开始,而不是从机器开始;3.要引起注意,但不要刻意;4.提升用户能力,而不是取代人", 
  "prediction": "可穿戴产品设计原则", 
  "summarization": "可穿戴技术十大设计原则"
}
...
</code></pre></div></div>

<p>至此，我们使用 Transformers 库进行文本摘要任务就全部完成了！</p>

<h2 id="代码">代码</h2>

<p>与之前一样，我们按照功能将文本摘要模型的代码拆分成模块并且存放在不同的文件中，整理后的代码存储在 Github：
<a href="https://github.com/jsksxs360/How-to-use-Transformers/tree/main/src/seq2seq_summarization">How-to-use-Transformers/src/seq2seq_summarization/</a></p>

<p>运行 <em>run_summarization_mt5.sh</em> 脚本即可进行训练。如果要进行测试或者将模型输出的翻译结果保存到文件，只需把脚本中的 <code class="language-plaintext highlighter-rouge">--do_train</code> 改成 <code class="language-plaintext highlighter-rouge">--do_test</code> 或 <code class="language-plaintext highlighter-rouge">--do_predict</code>。</p>

<blockquote>
  <p>经过 3 轮训练，最终 mT5 模型在测试集上的 ROUGE-1、ROUGE-2 和 ROUGE-L 值分别为 70.00、55.56 和 70.00（Nvidia Tesla V100, batch=32）。</p>
</blockquote>

<h2 id="参考">参考</h2>

<p><a href="https://huggingface.co/course/chapter1/1">[1]</a> HuggingFace 在线教程<br />
<a href="https://pytorch.org/docs/stable/">[2]</a> Pytorch 官方文档<br />
<a href="https://huggingface.co/docs/transformers/index">[3]</a> Transformers 官方文档</p>]]></content><author><name>SHENG XU</name></author><category term="NLP" /><summary type="html"><![CDATA[本文我们将运用 Transformers 库来完成文本摘要任务。与我们上一章进行的翻译任务一样，文本摘要同样是一个 Seq2Seq 任务，旨在尽可能保留文本语义的情况下将长文本压缩为短文本。]]></summary></entry><entry><title type="html">第十章：翻译任务</title><link href="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-24-transformers-note-7.html" rel="alternate" type="text/html" title="第十章：翻译任务" /><published>2022-03-24T00:00:00+08:00</published><updated>2022-03-24T00:00:00+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/nlp/transformers-note-7</id><content type="html" xml:base="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-24-transformers-note-7.html"><![CDATA[<p>本章我们将运用 Transformers 库来完成翻译任务。翻译是典型的序列到序列 (sequence-to-sequence, Seq2Seq) 任务，即对于每一个输入序列都会输出一个对应的序列。翻译在任务形式上与许多其他任务很接近，例如：</p>

<ul>
  <li>
    <p><strong>文本摘要 (Summarization)：</strong>将长文本压缩为短文本，并且还要尽可能保留核心内容。</p>
  </li>
  <li><strong>风格转换 (Style transfer)：</strong>将文本转换为另一种书写风格，例如将文言文转换为白话文、将古典英语转换为现代英语；</li>
  <li><strong>生成式问答 (Generative question answering)：</strong>对于给定的问题，基于上下文生成对应的答案。</li>
</ul>

<p>理论上我们也可以将本章的操作应用于完成这些 Seq2Seq 任务。</p>

<p>翻译任务通常需要大量的对照语料用于训练，如果我们有足够多的训练数据就可以从头训练一个翻译模型，但是微调预训练好的模型会更快，例如将 mT5、mBART 等多语言模型微调到特定的语言对。</p>

<p>本章我们将微调一个 Marian 翻译模型进行汉英翻译，该模型已经基于 <a href="https://opus.nlpl.eu/">Opus</a> 语料对汉英翻译任务进行了预训练，因此可以直接用于翻译。而通过我们的微调，可以进一步提升该模型在特定语料上的性能。</p>

<h2 id="1-准备数据">1. 准备数据</h2>

<p>我们选择 <a href="https://github.com/brightmart/nlp_chinese_corpus#5%E7%BF%BB%E8%AF%91%E8%AF%AD%E6%96%99translation2019zh">translation2019zh</a> 语料作为数据集，它共包含中英文平行语料 520 万对，可以用于训练中英翻译模型。Github 仓库中只提供了 <a href="https://drive.google.com/open?id=1EX8eE5YWBxCaohBO8Fh4e2j3b9C2bTVQ">Google Drive</a> 链接，我们也可以通过<a href="https://www.heywhale.com/mw/dataset/5de5fcafca27f8002c4ca993/content">和鲸社区</a>或者<a href="https://pan.baidu.com/s/14VkrHo3ExUSQskHHBK_I8w?pwd=xszb">百度云盘</a>下载。</p>

<p>本文我们将基于该语料，微调一个预训练好的汉英翻译模型。</p>

<p>该语料已经划分好了训练集和验证集，分别包含 516 万和 3.9 万个样本，语料以 json 格式提供，一行是一个中英文对照句子对：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{"english": "In Italy, there is no real public pressure for a new, fairer tax system.", "chinese": "在意大利，公众不会真的向政府施压，要求实行新的、更公平的税收制度。"}
</code></pre></div></div>

<h3 id="构建数据集">构建数据集</h3>

<p>与之前一样，我们首先编写继承自 <code class="language-plaintext highlighter-rouge">Dataset</code> 类的自定义数据集类用于组织样本和标签。考虑到 translation2019zh 并没有提供测试集，而且使用五百多万条样本进行训练耗时过长，这里我们只抽取训练集中的前 22 万条数据，并从中划分出 2 万条数据作为验证集，然后将 translation2019zh 中的验证集作为测试集：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="n">max_dataset_size</span> <span class="o">=</span> <span class="mi">220000</span>
<span class="n">train_set_size</span> <span class="o">=</span> <span class="mi">200000</span>
<span class="n">valid_set_size</span> <span class="o">=</span> <span class="mi">20000</span>

<span class="k">class</span> <span class="nc">TRANS</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">max_dataset_size</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">TRANS</span><span class="p">(</span><span class="s">'data/translation2019zh/translation2019zh_train.json'</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="n">train_set_size</span><span class="p">,</span> <span class="n">valid_set_size</span><span class="p">])</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">TRANS</span><span class="p">(</span><span class="s">'data/translation2019zh/translation2019zh_valid.json'</span><span class="p">)</span>
</code></pre></div></div>

<p>下面我们输出数据集的大小并且打印出一个训练样本：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'train set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'valid set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'test set size: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_data</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>train set size: 200000
valid set size: 20000
test set size: 39323
{'english': "We're going to order some chicks for the kids and to replan the shop stock, and we chose to go with the colored ones that look cute.", 'chinese': '我们打算为儿童们定购一些小鸡，来补充商店存货，我们选择了这些被染了色的小鸡，它们看起来真的很可爱。'}
</code></pre></div></div>

<h3 id="数据预处理">数据预处理</h3>

<p>接下来我们就需要通过 <code class="language-plaintext highlighter-rouge">DataLoader</code> 库来按 batch 加载数据，将文本转换为模型可以接受的 token IDs。对于翻译任务，我们需要运用分词器同时对源文本和目标文本进行编码，这里我们选择 <a href="https://huggingface.co/Helsinki-NLP">Helsinki-NLP</a> 提供的汉英翻译模型 opus-mt-zh-en 对应的分词器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"Helsinki-NLP/opus-mt-zh-en"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
</code></pre></div></div>

<p>你也可以尝试别的语言，<a href="https://huggingface.co/Helsinki-NLP">Helsinki-NLP</a> 提供了超过了一千种模型用于在不同语言之间进行翻译，只需要将 <code class="language-plaintext highlighter-rouge">model_checkpoint</code> 设置为对应的语言即可。如果你想使用多语言模型的分词器，例如 mBART、mBART-50、M2M100，就需要通过设置 <code class="language-plaintext highlighter-rouge">tokenizer.src_lang</code> 和 <code class="language-plaintext highlighter-rouge">tokenizer.tgt_lang</code> 来手工设定源/目标语言。</p>

<p>默认情况下分词器会采用源语言的设定来编码文本，要编码目标语言则需要通过上下文管理器 <code class="language-plaintext highlighter-rouge">as_target_tokenizer()</code>：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">zh_sentence</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">"chinese"</span><span class="p">]</span>
<span class="n">en_sentence</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">"english"</span><span class="p">]</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">zh_sentence</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">as_target_tokenizer</span><span class="p">():</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">en_sentence</span><span class="p">)</span>
</code></pre></div></div>

<p>如果你忘记添加上下文管理器，就会使用源语言分词器对目标语言进行编码，产生糟糕的分词结果：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">wrong_targets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">en_sentence</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">targets</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">convert_ids_to_tokens</span><span class="p">(</span><span class="n">wrong_targets</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['▁我们', '打算', '为儿童', '们', '定', '购', '一些', '小', '鸡', ',', '来', '补充', '商店', '存货', ',', '我们', '选择', '了', '这些', '被', '染', '了', '色', '的小', '鸡', ',', '它们', '看起来', '真的很', '可爱', '。', '&lt;/s&gt;']

['▁We', "'", 're', '▁going', '▁to', '▁order', '▁some', '▁chicks', '▁for', '▁the', '▁kids', '▁and', '▁to', '▁re', 'plan', '▁the', '▁shop', '▁stock', ',', '▁and', '▁we', '▁chose', '▁to', '▁go', '▁with', '▁the', '▁color', 'ed', '▁ones', '▁that', '▁look', '▁cute', '.', '&lt;/s&gt;']

['▁We', "'", 're', '▁going', '▁to', '▁', 'or', 'der', '▁some', '▁ch', 'ick', 's', '▁for', '▁the', '▁k', 'id', 's', '▁and', '▁to', '▁re', 'p', 'lan', '▁the', '▁', 'sh', 'op', '▁', 'st', 'ock', ',', '▁and', '▁we', '▁', 'cho', 'se', '▁to', '▁go', '▁with', '▁the', '▁c', 'olo', 'red', '▁', 'ones', '▁that', '▁look', '▁', 'cu', 'te', '.', '&lt;/s&gt;']
</code></pre></div></div>

<p>可以看到，由于中文分词器无法识别大部分的英文单词，用它编码英文会生成更多的 token，例如这里将“order”切分为了“or”和“der”，将“chicks”切分为了“ch”、“ick”、“s”等等。</p>

<p>对于翻译任务，标签序列就是目标语言的 token ID 序列。与<a href="/2022/03/18/transformers-note-6.html">序列标注任务</a>类似，我们会在模型预测出的标签序列与答案标签序列之间计算损失来调整模型参数，因此我们同样需要将填充的 pad 字符设置为 -100，以便在使用交叉熵计算序列损失时将它们忽略：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">max_input_length</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"chinese"</span><span class="p">]</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
<span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">train_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="s">"english"</span><span class="p">]</span> <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>

<span class="n">model_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span> 
    <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="n">max_input_length</span><span class="p">,</span> 
    <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
<span class="p">)</span>
<span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">as_target_tokenizer</span><span class="p">():</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">targets</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span> 
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)[</span><span class="s">"input_ids"</span><span class="p">]</span>

<span class="n">end_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">end_token_index</span><span class="p">):</span>
    <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">end_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>

<span class="k">print</span><span class="p">(</span><span class="s">'batch_X shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">model_inputs</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_y shape:'</span><span class="p">,</span> <span class="n">labels</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>batch_X shape: {
    'input_ids': torch.Size([4, 36]), 
    'attention_mask': torch.Size([4, 36])
}
batch_y shape: torch.Size([4, 43])

{'input_ids': tensor([
        [  335,  3321, 20836,  2505,  3410, 13425,   617,  1049, 12245,     2,
           272,  2369, 25067, 28865,     2,   230,  1507,    55,   288,   266,
         19981,    55,  5144,  9554, 12245,     2,   896, 13699, 15710, 15249,
             9,     0, 65000, 65000, 65000, 65000],
        [ 5786, 23552,    36,  8380, 16532,   378,   675,  2878,   272,   702,
         22092,    11, 20819,  4085,   309,  3428, 43488,     9,     0, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000],
        [  103, 27772, 32598,   241,   930,     2,  8714,  4349,  9460,    69,
         10866,   272,  2733,  1499, 18852,  8390,    11,    25,   384,  5520,
         35761,  1924,  1251,  1499,     9,     0, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000],
        [    7,   706,  5634, 24065, 16505, 13502,   176, 10252, 53105,     2,
          3021,  5980, 31854,  2509,     9,    91,   646,  3976, 40408,  6305,
            11,  7440,  1020,  7471, 56880,  5980, 31854,    34, 46037, 17267,
           514, 43792,  6455, 20889,    17,     0]]), 
 'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}

tensor([[  140,    21,   129,   717,     8,   278,   239, 53363,    14,     3,
          6801,     6,     8,  1296, 38776,     3, 18850,  7985,     2,     6,
           107, 21883,     8,   374,    27,     3, 20969,   250,  6048,    19,
          1217, 20511,     5,     0,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100],
        [ 3822, 28838,   847,   115,    12, 17059,     8,   603,   649,     4,
         33030,    46,     3,   315,   557,     3, 21347,     5,     0,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100],
        [  379, 41237,   480,    26,  2127,    10,   158,  1963,    19,     3,
         24463,  2564,    18,  1509,     8, 41272,   158, 28930,    25,    58,
            43, 32192, 10532,    42,   172,   105,     5,     0,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100],
        [48532,     3, 42162,    22,    29,    95,  1568, 15398,     7, 41830,
            59, 14375,  2104,   168,  5101,  6347,  3708,  7497, 36852,     6,
         29594,   199,    27,    12,  1960, 32215, 18162, 27015,     4,  8706,
          1029,    20,  4098,    54,  8273,     8,  8996,     3, 41372,   102,
         50348,   243,     0]])
</code></pre></div></div>

<p>我们使用的 Marian 模型会在分词结果的结尾加上特殊 token <code class="language-plaintext highlighter-rouge">'&lt;/s&gt;'</code>，因此这里通过 <code class="language-plaintext highlighter-rouge">tokenizer.eos_token_id</code> 定位其在 token ID 序列中的索引，然后将其之后的 pad 字符设置为 -100。</p>

<blockquote>
  <p>标签序列的格式需要依据模型而定，例如如果你使用的是 T5 模型，模型的输入还需要包含指明任务类型的前缀 (prefix)，对于翻译任务就需要在输入前添加 <code class="language-plaintext highlighter-rouge">Chinese to English:</code>。</p>
</blockquote>

<p>与我们之前任务中使用的纯 Encoder 模型不同，Seq2Seq 任务对应的模型采用的是 Encoder-Decoder 框架：Encoder 负责编码输入序列，Decoder 负责循环地逐个生成输出 token。因此，对于每一个样本，我们还需要额外准备 decoder input IDs 作为 Decoder 的输入。decoder input IDs 是标签序列的移位，在序列的开始位置增加了一个特殊的“序列起始符”。</p>

<p>在训练过程中，模型会基于 decoder input IDs 和 attention mask 来确保在预测某个 token 时不会使用到该 token 及其之后的 token 的信息。即 Decoder 在预测某个目标 token 时，只能基于“整个输入序列”和“当前已经预测出的 token”信息来进行预测，如果提前看到要预测的 token（甚至更后面的 token），就相当于是“作弊”了。因此在训练时，会通过特殊的“三角形” Mask 来遮掩掉预测 token 及其之后的 token 的信息。</p>

<blockquote>
  <p>如果对这一块感到困惑，可以参考苏剑林的博文<a href="https://kexue.fm/archives/6933">《从语言模型到Seq2Seq：Transformer如戏，全靠Mask》</a>。</p>
</blockquote>

<p>考虑到不同模型的移位操作可能存在差异，我们通过模型自带的 <code class="language-plaintext highlighter-rouge">prepare_decoder_input_ids_from_labels</code> 函数来完成。完整的批处理函数为：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="n">max_input_length</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'chinese'</span><span class="p">])</span>
        <span class="n">batch_targets</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'english'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_inputs</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_input_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">as_target_tokenizer</span><span class="p">():</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">batch_targets</span><span class="p">,</span> 
            <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
        <span class="p">)[</span><span class="s">"input_ids"</span><span class="p">]</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'decoder_input_ids'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">prepare_decoder_input_ids_from_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">end_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">end_token_index</span><span class="p">):</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">end_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">batch_data</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
</code></pre></div></div>

<p>注意，由于本文直接使用 Transformers 库自带的 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 函数来构建模型，因此我们将每一个 batch 中的数据处理为该模型可接受的格式：一个包含 <code class="language-plaintext highlighter-rouge">'attention_mask'</code>、<code class="language-plaintext highlighter-rouge">'input_ids'</code>、<code class="language-plaintext highlighter-rouge">'labels'</code> 和 <code class="language-plaintext highlighter-rouge">'decoder_input_ids'</code> 键的字典。</p>

<p>下面我们尝试打印出一个 batch 的数据，以验证是否处理正确：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dict_keys(['input_ids', 'attention_mask', 'decoder_input_ids', 'labels'])

batch shape: {
    'input_ids': torch.Size([4, 57]), 
    'attention_mask': torch.Size([4, 57]), 
    'decoder_input_ids': torch.Size([4, 37]), 
    'labels': torch.Size([4, 37])
}

{'input_ids': tensor([
        [ 4385,   257,  6095, 11065,  4028,   142,     2, 14025, 16036,  2059,
          2677,     9,     0, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000],
        [  335,   675,  6072,   160,  2353, 12746,  6875, 10851,    13,  3067,
         49431,    13, 21639, 11180,   188, 23811,  3127, 59374, 12746,    16,
         10801, 10459,     2,  2754,   101, 62987,  3975,  6875, 10851,  2326,
            13, 16106, 39781,  6875, 10851,  2326,    13, 41743,  3975,  6875,
         10851,  2326,    13,  3067, 49431,  2326,    13,  4011, 21639,  2326,
            13, 23811,  3127, 59374,   408,     9,     0],
        [    7, 10900,  2702,  2997,  5257,  4145,  3277,  9239,  2437,     2,
          1222, 11929,     2,    36,  4776,  4998,  2992,  2061,    16,  5029,
          2061, 27060,  1297,     2, 10900,  2702, 28874,  5029,  4205,    16,
         11959,  4205, 29858,     9,     0, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000],
        [    7,   690,   840,    31,    11,  2847,     2, 61232,  1862,  2989,
          4870,  1548, 55902,  1058,   348,  4316,  1371, 14036,     9,     0,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000]]), 
 'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0]]), 
 'decoder_input_ids': tensor([
        [65000,  1738,   209,    30,  1294,    30,    54, 43574,    22,     2,
           183,     3,  1483,     4,  1540,  7418,     5,     0, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000],
        [65000,   140,   281,   520,  2293,     4, 37984,   102,     7,     2,
         26398,  1632,     2, 32215,   102,     2, 22188,  1403,     6,  3825,
             7,     2,   286,  1282,  2687,   586, 55450, 37984,   501,     2,
          7684,   177, 37984,   501,     2,   825,  1181],
        [65000, 50295, 53923, 54326,    22,  4471,     2,   513, 26103,     4,
          3275,  2707,  2907,     6,    10,    12,  4405,   625,    10, 10813,
             4, 50295, 53923,  1906, 15486, 10813,  5032,     6, 13962,  5032,
         12620,     5,     0, 65000, 65000, 65000, 65000],
        [65000,  1008,   840,    28, 41223,  4688,    30, 37855,   250, 10204,
             4,  2407,     5,     0, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000]]), 
 'labels': tensor([
        [ 1738,   209,    30,  1294,    30,    54, 43574,    22,     2,   183,
             3,  1483,     4,  1540,  7418,     5,     0,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100],
        [  140,   281,   520,  2293,     4, 37984,   102,     7,     2, 26398,
          1632,     2, 32215,   102,     2, 22188,  1403,     6,  3825,     7,
             2,   286,  1282,  2687,   586, 55450, 37984,   501,     2,  7684,
           177, 37984,   501,     2,   825,  1181,     0],
        [50295, 53923, 54326,    22,  4471,     2,   513, 26103,     4,  3275,
          2707,  2907,     6,    10,    12,  4405,   625,    10, 10813,     4,
         50295, 53923,  1906, 15486, 10813,  5032,     6, 13962,  5032, 12620,
             5,     0,  -100,  -100,  -100,  -100,  -100],
        [ 1008,   840,    28, 41223,  4688,    30, 37855,   250, 10204,     4,
          2407,     5,     0,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100]])}
</code></pre></div></div>

<p>可以看到，DataLoader 按照我们设置的 batch size，每次对 4 个样本进行编码，并且填充 token 对应的标签都被设置为 -100。我们构建的 Decoder 的输入 decoder input IDs 尺寸与标签序列完全相同，且通过向后移位在序列头部添加了特殊的“序列起始符”，例如第一个样本：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'labels': 
        [ 1738,   209,    30,  1294,    30,    54, 43574,    22,     2,   183,
             3,  1483,     4,  1540,  7418,     5,     0,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,
          -100,  -100,  -100,  -100,  -100,  -100,  -100]
'decoder_input_ids': 
        [65000,  1738,   209,    30,  1294,    30,    54, 43574,    22,     2,
           183,     3,  1483,     4,  1540,  7418,     5,     0, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000, 65000,
         65000, 65000, 65000, 65000, 65000, 65000, 65000]
</code></pre></div></div>

<p>至此，数据预处理部分就全部完成了！</p>

<blockquote>
  <p>在大部分情况下，即使我们在 batch 数据中没有包含 decoder input IDs，模型也能正常训练，它会自动调用模型的 <code class="language-plaintext highlighter-rouge">prepare_decoder_input_ids_from_labels</code> 函数来构造 <code class="language-plaintext highlighter-rouge">decoder_input_ids</code>。</p>
</blockquote>

<h2 id="2-训练模型">2. 训练模型</h2>

<p>本文直接使用 Transformers 库自带的 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 类来构建模型，并且在批处理函数中还调用了模型自带的 <code class="language-plaintext highlighter-rouge">prepare_decoder_input_ids_from_labels</code> 函数，因此下面只需要实现 Epoch 中的”训练循环”和”验证/测试循环”。</p>

<blockquote>
  <p>这里之所以没有像前面章节中那样自己编写模型，是因为翻译模型的结构较为复杂，要完整地完成编码、解码过程需要借助许多辅助函数。我们可以想象，如果我们同样通过继承 <code class="language-plaintext highlighter-rouge">PreTrainedModel</code> 类来实现翻译模型，那么其结构大致为：</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers.models.marian</span> <span class="kn">import</span> <span class="n">MarianPreTrainedModel</span><span class="p">,</span> <span class="n">MarianModel</span>

<span class="k">class</span> <span class="nc">MarianForMT</span><span class="p">(</span><span class="n">MarianPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">MarianModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="n">target_vocab_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">.</span><span class="n">decoder_vocab_size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s">"final_logits_bias"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">)))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">d_model</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">lm_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">final_logits_bias</span>
        <span class="k">return</span> <span class="n">lm_logits</span>
      
    <span class="k">def</span> <span class="nf">other_func</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MarianForMT</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div>  </div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cpu device
MarianForMT(
  (model): MarianModel(
    (shared): Embedding(65001, 512, padding_idx=65000)
    (encoder): MarianEncoder(...)
    (decoder): MarianDecoder(...)
  )
  (lm_head): Linear(in_features=512, out_features=65001, bias=False)
)
</code></pre></div>  </div>

  <p>即模型会首先运用 Marian 模型的 Encoder 对输入 token 序列进行编码，然后通过 Decoder 基于我们构建的 Decoder 输入解码出对应的目标向量序列，最后将输出序列送入到一个包含 65001 个神经元的线性全连接层中进行分类，预测每个向量对应的是词表中的哪个词。</p>

  <p>为了测试模型的操作是否符合预期，我们尝试将一个 batch 的数据送入模型：</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>  </div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([4, 37, 65001])
</code></pre></div>  </div>

  <p>可以看到，模型的输出尺寸 $4\times 37\times 65001$ 与我们构造的 Decoder 输入 <code class="language-plaintext highlighter-rouge">decoder_input_ids</code> 尺寸完全一致。</p>
</blockquote>

<h3 id="优化模型参数">优化模型参数</h3>

<p>使用 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 构造的模型已经封装好了对应的损失函数，并且计算出的损失会直接包含在模型的输出 <code class="language-plaintext highlighter-rouge">outputs</code> 中，可以直接通过 <code class="language-plaintext highlighter-rouge">outputs.loss</code> 获得，因此训练循环为：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>
</code></pre></div></div>

<blockquote>
  <p>与<a href="/2022/03/18/transformers-note-6.html">序列标注</a>任务类似，翻译任务的输出同样是一个预测向量序列，因此在使用交叉熵计算模型损失时，要么对维度进行调整，要么通过 <code class="language-plaintext highlighter-rouge">view()</code> 将 batch 中的多个向量序列连接为一个序列。因为我们已经将填充 token 对应的标签设为了 -100，所以模型实际上是借助 <code class="language-plaintext highlighter-rouge">view()</code> 调整输出张量的尺寸来计算损失的：</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">lm_logits</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">decoder_vocab_size</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div>  </div>
</blockquote>

<p>验证/测试循环负责评估模型的性能。对于翻译任务，经典的评估指标是 Kishore Papineni 等人在<a href="https://aclanthology.org/P02-1040.pdf">《BLEU: a Method for Automatic Evaluation of Machine Translation》</a>中提出的 <a href="https://en.wikipedia.org/wiki/BLEU">BLEU 值</a>，用于度量两个词语序列之间的一致性，但是其并不会衡量语义连贯性或者语法正确性。</p>

<p>由于计算 BLEU 值需要输入分好词的文本，而不同的分词方式会对结果造成影响，因此现在更常用的评估指标是 <a href="https://github.com/mjpost/sacrebleu">SacreBLEU</a>，它对分词的过程进行了标准化。SacreBLEU 直接以未分词的文本作为输入，并且对于同一个输入可以接受多个目标作为参考。虽然我们使用的 translation2019zh 语料对于每一个句子只有一个参考，也需要将其包装为一个句子列表，例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sacrebleu.metrics</span> <span class="kn">import</span> <span class="n">BLEU</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"This plugin lets you translate web pages between several languages automatically."</span>
<span class="p">]</span>
<span class="n">bad_predictions_1</span> <span class="o">=</span> <span class="p">[</span><span class="s">"This This This This"</span><span class="p">]</span>
<span class="n">bad_predictions_2</span> <span class="o">=</span> <span class="p">[</span><span class="s">"This plugin"</span><span class="p">]</span>
<span class="n">references</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span>
        <span class="s">"This plugin allows you to automatically translate web pages between several languages."</span>
    <span class="p">]</span>
<span class="p">]</span>

<span class="n">bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">).</span><span class="n">score</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">bad_predictions_1</span><span class="p">,</span> <span class="n">references</span><span class="p">).</span><span class="n">score</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">bad_predictions_2</span><span class="p">,</span> <span class="n">references</span><span class="p">).</span><span class="n">score</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>46.750469682990165
1.683602693167689
0.0
</code></pre></div></div>

<p>BLEU 值的范围从 0 到 100，越高越高。可以看到，对于一些槽糕的翻译结果，例如包含大量重复词语或者长度过短的预测结果，会计算出非常低的 BLEU 值。</p>

<p>SacreBLEU 默认会采用 mteval-v13a.pl 分词器对文本进行分词，但是它无法处理中文、日文等非拉丁系语言。对于中文就需要设置参数 <code class="language-plaintext highlighter-rouge">tokenize='zh'</code> 手动使用中文分词器，否则会计算出不正确的 BLEU 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sacrebleu.metrics</span> <span class="kn">import</span> <span class="n">BLEU</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"我在苏州大学学习计算机，苏州大学很美丽。"</span>
<span class="p">]</span>

<span class="n">references</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span>
        <span class="s">"我在环境优美的苏州大学学习计算机。"</span>
    <span class="p">]</span>
<span class="p">]</span>

<span class="n">bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">(</span><span class="n">tokenize</span><span class="o">=</span><span class="s">'zh'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'BLEU: </span><span class="si">{</span><span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">).</span><span class="n">score</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
<span class="n">bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'wrong BLEU: </span><span class="si">{</span><span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="p">).</span><span class="n">score</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>BLEU: 45.340106118883256
wrong BLEU: 0.0
</code></pre></div></div>

<p>使用 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 构造的模型同样对 Decoder 的解码过程进行了封装，我们只需要调用模型的 <code class="language-plaintext highlighter-rouge">generate()</code> 函数就可以自动地逐个生成预测 token。例如，我们可以直接调用预训练好的 Marian 模型进行翻译：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSeq2SeqLM</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"Helsinki-NLP/opus-mt-zh-en"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="s">'我叫张三，我住在苏州。'</span>

<span class="n">sentence_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">sentence_generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">sentence_inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">sentence_inputs</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span>
<span class="p">)</span>
<span class="n">sentence_decoded_pred</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sentence_generated_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sentence_decoded_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cpu device
My name is Zhang San, and I live in Suzhou.
</code></pre></div></div>

<p>在 <code class="language-plaintext highlighter-rouge">generate()</code> 生成 token ID 之后，我们通过分词器自带的 <code class="language-plaintext highlighter-rouge">tokenizer.batch_decode()</code> 函数将 batch 中所有的 token ID 序列都转换为文本，因此翻译多个句子也没有问题：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s">'我叫张三，我住在苏州。'</span><span class="p">,</span> <span class="s">'我在环境优美的苏州大学学习计算机。'</span><span class="p">]</span>

<span class="n">sentences_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">sentences</span><span class="p">,</span> 
    <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
<span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">sentences_generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">sentences_inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">sentences_inputs</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">128</span>
<span class="p">)</span>
<span class="n">sentences_decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">sentences_generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">sentences_decoded_preds</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
    'My name is Zhang San, and I live in Suzhou.', 
    "I'm studying computers at Suzhou University in a beautiful environment."
]
</code></pre></div></div>

<p>在“验证/测试循环”中，我们首先通过 <code class="language-plaintext highlighter-rouge">model.generate()</code> 函数获取预测结果，然后将预测结果和正确标签都处理为 SacreBLEU 接受的文本列表形式（这里我们将标签序列中的 -100 替换为 pad token ID 以便于分词器解码），最后送入到 SacreBLEU 中计算 BLEU 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sacrebleu.metrics</span> <span class="kn">import</span> <span class="n">BLEU</span>
<span class="n">bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">[</span><span class="s">"labels"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">label_tokens</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">label_tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
        <span class="n">decoded_labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">preds</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pred</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">decoded_preds</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">label</span><span class="p">.</span><span class="n">strip</span><span class="p">()]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">decoded_labels</span><span class="p">]</span>
    <span class="n">bleu_score</span> <span class="o">=</span> <span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">).</span><span class="n">score</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"BLEU: </span><span class="si">{</span><span class="n">bleu_score</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bleu_score</span>
</code></pre></div></div>

<p>为了方便后续保存验证集上最好的模型，这里我们还在验证/测试循环中返回模型计算出的 BLEU 值。</p>

<h3 id="保存模型">保存模型</h3>

<p>与之前一样，我们会根据模型在验证集上的性能来调整超参数以及选出最好的模型权重，然后将选出的模型应用于测试集以评估最终的性能。这里我们继续使用 AdamW 优化器，并且通过 <code class="language-plaintext highlighter-rouge">get_scheduler()</code> 函数定义学习率调度器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_bleu</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_bleu</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'Valid'</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">valid_bleu</span> <span class="o">&gt;</span> <span class="n">best_bleu</span><span class="p">:</span>
        <span class="n">best_bleu</span> <span class="o">=</span> <span class="n">valid_bleu</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_bleu_</span><span class="si">{</span><span class="n">valid_bleu</span><span class="si">:</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<p>在开始训练之前，我们先评估一下没有微调的模型在测试集上的性能。这个过程比较耗时，你可以在它执行的时候喝杯咖啡:)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_data</span> <span class="o">=</span> <span class="n">TRANS</span><span class="p">(</span><span class="s">'data/translation2019zh/translation2019zh_valid.json'</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="n">test_loop</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device
100%|█████████████████████████|  615/615 [19:08&lt;00:00,  1.87s/it]
Test BLEU: 42.61
</code></pre></div></div>

<p>可以看到预训练模型在测试集上的 BLEU 值为 42.61，即使不进行微调，也已经具有不错的汉英翻译能力。</p>

<p>下面我们正式开始训练（微调）模型，完整的训练代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSeq2SeqLM</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>
<span class="kn">from</span> <span class="nn">sacrebleu.metrics</span> <span class="kn">import</span> <span class="n">BLEU</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="k">def</span> <span class="nf">seed_everything</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">1029</span><span class="p">):</span>
    <span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">cudnn</span><span class="p">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>
<span class="n">seed_everything</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">max_dataset_size</span> <span class="o">=</span> <span class="mi">220000</span>
<span class="n">train_set_size</span> <span class="o">=</span> <span class="mi">200000</span>
<span class="n">valid_set_size</span> <span class="o">=</span> <span class="mi">20000</span>

<span class="n">max_input_length</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">max_target_length</span> <span class="o">=</span> <span class="mi">128</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">class</span> <span class="nc">TRANS</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">max_dataset_size</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">sample</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">loads</span><span class="p">(</span><span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">())</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span>
        <span class="k">return</span> <span class="n">Data</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">TRANS</span><span class="p">(</span><span class="s">'data/translation2019zh/translation2019zh_train.json'</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="p">[</span><span class="n">train_set_size</span><span class="p">,</span> <span class="n">valid_set_size</span><span class="p">])</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">TRANS</span><span class="p">(</span><span class="s">'data/translation2019zh/translation2019zh_valid.json'</span><span class="p">)</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"Helsinki-NLP/opus-mt-zh-en"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSeq2SeqLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_targets</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_inputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'chinese'</span><span class="p">])</span>
        <span class="n">batch_targets</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'english'</span><span class="p">])</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_inputs</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_input_length</span><span class="p">,</span>
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="k">with</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">as_target_tokenizer</span><span class="p">():</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">batch_targets</span><span class="p">,</span> 
            <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
        <span class="p">)[</span><span class="s">"input_ids"</span><span class="p">]</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'decoder_input_ids'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">prepare_decoder_input_ids_from_labels</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        <span class="n">end_token_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">end_idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">end_token_index</span><span class="p">):</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">end_idx</span><span class="o">+</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch_data</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
    <span class="k">return</span> <span class="n">batch_data</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch_data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">loss</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>

<span class="n">bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    
    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
            <span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">[</span><span class="s">"labels"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">label_tokens</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">label_tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
        <span class="n">decoded_labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">preds</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pred</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">decoded_preds</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">label</span><span class="p">.</span><span class="n">strip</span><span class="p">()]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">decoded_labels</span><span class="p">]</span>
    <span class="n">bleu_score</span> <span class="o">=</span> <span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">).</span><span class="n">score</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"BLEU: </span><span class="si">{</span><span class="n">bleu_score</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">bleu_score</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_bleu</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">valid_bleu</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">valid_bleu</span> <span class="o">&gt;</span> <span class="n">best_bleu</span><span class="p">:</span>
        <span class="n">best_bleu</span> <span class="o">=</span> <span class="n">valid_bleu</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span>
            <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> 
            <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_bleu_</span><span class="si">{</span><span class="n">valid_bleu</span><span class="si">:</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="s">_model_weights.bin'</span>
        <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device
Epoch 1/3
-------------------------------
loss: 2.570799: 100%|██████████| 6250/6250 [11:19&lt;00:00,  9.20it/s]
100%|██████████| 625/625 [10:51&lt;00:00,  1.04s/it]
BLEU: 53.38

saving new weights...

Epoch 2/3
-------------------------------
loss: 2.498721: 100%|██████████| 6250/6250 [11:21&lt;00:00,  9.17it/s]
100%|██████████| 625/625 [11:08&lt;00:00,  1.07s/it]
BLEU: 53.38

Epoch 3/3
-------------------------------
loss: 2.454356: 100%|██████████| 6250/6250 [11:21&lt;00:00,  9.17it/s]
100%|██████████| 625/625 [10:51&lt;00:00,  1.04s/it]
BLEU: 53.38

Done!
</code></pre></div></div>

<p>可以看到，随着训练的进行，模型在训练集上的损失一直在下降，但是在验证集上的 BLEU 值却并没有提升，在第一轮后就稳定在 53.38。因此，3 轮训练结束后，目录下只保存了第一轮训练后的模型权重：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch_1_valid_bleu_53.38_model_weights.bin
</code></pre></div></div>

<p>至此，我们对中英翻译 Marian 模型的训练（微调）过程就完成了。</p>

<h2 id="3-测试模型">3. 测试模型</h2>

<p>训练完成后，我们加载在验证集上性能最优的模型权重，汇报其在测试集上的性能，并且将模型的预测结果保存到文件中。</p>

<p>由于 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 对整个解码过程进行了封装，我们只需要调用 <code class="language-plaintext highlighter-rouge">generate()</code> 函数就可以自动通过 beam search 找到最佳的 token ID 序列，因此我们只需要再使用分词器将 token ID 序列转换为文本就可以获得翻译结果：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_data</span> <span class="o">=</span> <span class="n">TRANS</span><span class="p">(</span><span class="s">'translation2019zh/translation2019zh_valid.json'</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">json</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'epoch_1_valid_bleu_53.38_model_weights.bin'</span><span class="p">))</span>

<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'evaluating on test set...'</span><span class="p">)</span>
    <span class="n">sources</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">batch_data</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">generated_tokens</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
            <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">],</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">batch_data</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">],</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_target_length</span><span class="p">,</span>
        <span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">batch_data</span><span class="p">[</span><span class="s">"labels"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">decoded_sources</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span>
            <span class="n">batch_data</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">(),</span> 
            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
            <span class="n">use_source_tokenizer</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="n">decoded_preds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">label_tokens</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">label_tokens</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="n">label_tokens</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span><span class="p">)</span>
        <span class="n">decoded_labels</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">label_tokens</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">sources</span> <span class="o">+=</span> <span class="p">[</span><span class="n">source</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">decoded_sources</span><span class="p">]</span>
        <span class="n">preds</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pred</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">decoded_preds</span><span class="p">]</span>
        <span class="n">labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">label</span><span class="p">.</span><span class="n">strip</span><span class="p">()]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">decoded_labels</span><span class="p">]</span>
    <span class="n">bleu_score</span> <span class="o">=</span> <span class="n">bleu</span><span class="p">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">).</span><span class="n">score</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Test BLEU: </span><span class="si">{</span><span class="n">bleu_score</span><span class="si">:</span><span class="o">&gt;</span><span class="mf">0.2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'saving predicted results...'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">source</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s">"sentence"</span><span class="p">:</span> <span class="n">source</span><span class="p">,</span> 
            <span class="s">"prediction"</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span> 
            <span class="s">"translation"</span><span class="p">:</span> <span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">})</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'test_data_pred.json'</span><span class="p">,</span> <span class="s">'wt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">exapmle_result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">exapmle_result</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device
evaluating on test set...
100%|██████████| 1229/1229 [21:18&lt;00:00,  1.04s/it]
Test BLEU: 54.87
</code></pre></div></div>

<p>可以看到，经过微调，模型在测试集上的 BLEU 值从 42.61 上升到 54.87，证明了我们对模型的微调是成功的。</p>

<p>我们打开保存预测结果的 <em>test_data_pred.json</em>，其中每一行对应一个样本，<code class="language-plaintext highlighter-rouge">sentence</code> 对应原文，<code class="language-plaintext highlighter-rouge">prediction</code> 对应模型的翻译结果，<code class="language-plaintext highlighter-rouge">translation</code> 对应标注的翻译文本。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  "sentence": "▁大连是中国最美丽的城市之一。", 
  "prediction": "Dalian is one of China's most beautiful cities.", 
  "translation": "E. g. Dalian is one of the most beautiful cities in China."
}
...
</code></pre></div></div>

<p>至此，我们使用 Transformers 库进行翻译任务就全部完成了！</p>

<h2 id="4-关于解码">4. 关于解码</h2>

<p>在本文中，我们使用 <code class="language-plaintext highlighter-rouge">AutoModelForSeq2SeqLM</code> 模型自带的 <code class="language-plaintext highlighter-rouge">generate()</code> 函数，通过柱搜索 (Beam search) 解码出翻译结果（使用模型默认解码参数）。实际上所有 Transformers 库中的生成模型都可以通过 <code class="language-plaintext highlighter-rouge">generate()</code> 函数来完成解码，只需要向其传递不同的参数。</p>

<p>下面我们将简单介绍目前常用的几种解码策略。</p>

<h3 id="自回归语言生成">自回归语言生成</h3>

<p>我们先回顾一下自回归 (auto-regressive) 语言生成的过程。自回归语言生成假设每个词语序列的概率都可以分解为一系列条件词语概率的乘积：</p>

\[P(w_{1:T}\mid W_0) = \prod_{t=1}^T P(w_t\mid w_{1:t-1}, W_0), \quad w_{1:0} = \varnothing\]

<p>这样就可以迭代地基于上下文 $W_0$ 以及已经生成的词语序列 $w_{1:t-1}$ 来预测序列中的下一个词 $w_t$，因此被称为自回归 (auto-regressive)。生成序列的长度 $T$ 通常不是预先确定的，而是当生成出休止符（EOS token）时结束迭代。</p>

<p>Transformers 库中所有的生成模型都提供了用于自回归生成的 <code class="language-plaintext highlighter-rouge">generate()</code> 函数，例如 GPT2、XLNet、OpenAi-GPT、CTRL、TransfoXL、XLM、Bart、T5 等等。</p>

<p>下面我们将介绍目前常用的四种解码方式：</p>

<ul>
  <li>贪心搜索 (Greedy Search)</li>
  <li>柱搜索 (Beam search)</li>
  <li><em>Top-K</em> 采样 (<em>Top-K</em> sampling)</li>
  <li><em>Top-p</em> 采样 (<em>Top-p</em> sampling)。</li>
</ul>

<p>为了方便，我们将统一使用 GPT-2 模型来进行展示。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"gpt2"</span><span class="p">)</span>

<span class="c1"># add the EOS token as PAD token to avoid warnings
</span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"gpt2"</span><span class="p">,</span> <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token_id</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="贪心搜索">贪心搜索</h3>

<p>贪心搜索 (Greedy Search) 在每轮迭代时，即在时间步 $t$，简单地选择概率最高的下一个词作为当前词，即 $w_t = \text{argmax}_w P(w\mid w_{1:t-1})$。下图展示了一个贪心搜索的例子：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/greedy_search.png" width="450px" style="display: block; margin: auto;" /></p>

<p>可以看到，从起始词语“The”开始，贪心算法不断地选择概率最高的下一个词直至结束，最后生成词语序列 (“The” “nice” “woman”)，其整体概率为 $0.5 \times 0.4 = 0.2$。</p>

<p>下面我们使用 GPT-2 模型结合贪心算法来为上下文 (“I”, “enjoy”, “walking”, “with”, “my”, “cute”, “dog”) 生成后续序列：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># encode context the generation is conditioned on
</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'I enjoy walking with my cute dog'</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">'pt'</span><span class="p">)</span>

<span class="c1"># generate text until the output length (which includes the context length) reaches 50
</span><span class="n">greedy_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">greedy_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.

I'm not sure if I'll
</code></pre></div></div>

<p>模型成功地生成了一个短文本，但是它似乎开始不停地重复。这是一个语言生成中常见的问题，特别是在贪心搜索和柱搜索中经常会出现。</p>

<p>贪心搜索最大的问题是由于每次都只选择当前概率最大的词，相当于是区部最优解，因此生成的序列往往并不是全局最优的。例如在上图中，词语序列 (“The”, “dog”, “has”) 的概率是 $0.4 \times 0.9 = 0.36$，而这个序列无法通过贪心算法得到。</p>

<h3 id="柱搜索">柱搜索</h3>

<p>柱搜索 (Beam search) 在每个时间步都保留 num_beams 个最可能的词，最终选择整体概率最大的序列作为结果。下图展示了一个 <code class="language-plaintext highlighter-rouge">num_beams=2</code> 的例子：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/beam_search.png" width="450px" style="display: block; margin: auto;" /></p>

<p>可以看到，在第一个时间步，柱搜索同时保留了概率最大的前 2 个序列：概率为 $0.4$ 的 (”The“, ”dog“) 和概率为 $0.5$ 的 (”The“, ”nice“)；在第二个时间步，柱搜索通过计算继续保留概率最大的前 2 个序列：概率为 $0.4 \times 0.9=0.36$ 的 (”The“, ”dog“, ”has“) 和概率为 $0.5 \times 0.4=0.2$ 的 (”The“, ”nice“, ”woman“)；最终选择概率最大的序列 (”The“, ”dog“, ”has“) 作为结果。</p>

<blockquote>
  <p>柱搜索虽然通过在每个时间步保留多个分支来缓解贪心算法局部最优解的问题，但是它依然不能保证找到全局最优解。</p>
</blockquote>

<p>下面我们同样运用 GPT-2 模型结合柱搜索来生成文本，只需要设置参数 <code class="language-plaintext highlighter-rouge">num_beams &gt; 1</code> 以及 <code class="language-plaintext highlighter-rouge">early_stopping=True</code>，这样只要所有柱搜索保留的分支都到达休止符 EOS token，生成过程就结束。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># activate beam search and early_stopping
</span><span class="n">beam_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">beam_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll
</code></pre></div></div>

<p>虽然柱搜索得到的序列更加流畅，但是输出中依然出现了重复片段。最简单的解决方法是引入 n-grams 惩罚，其在每个时间步都手工将那些会产生重复 n-gram 片段的词的概率设为 0。例如，我们额外设置参数 <code class="language-plaintext highlighter-rouge">no_repeat_ngram_size=2</code> 就能使生成序列中不会出现重复的 2-gram 片段：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set no_repeat_ngram_size to 2
</span><span class="n">beam_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">beam_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's time for me to take a break
</code></pre></div></div>

<p>不过 n-grams 惩罚虽然能够缓解“重复”问题，却也要谨慎使用。例如对于一篇关于”New York“文章就不能使用 2-gram 惩罚，否则”New York“在全文中就只能出现一次了。</p>

<p>柱搜索会在每个时间步都保留当前概率最高的前 num_beams 个序列，因此我们还可以通过设置参数 <code class="language-plaintext highlighter-rouge">num_return_sequences</code>（&lt;= num_beams）来返回概率靠前的多个序列：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set return_num_sequences &gt; 1
</span><span class="n">beam_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">num_beams</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
    <span class="n">no_repeat_ngram_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
    <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
    <span class="n">early_stopping</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="c1"># now we have 3 output sequences
</span><span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">beam_output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">beam_outputs</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"{}: {}</span><span class="se">\n\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">beam_output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's time for me to take a break


1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.

I've been thinking about this for a while now, and I think it's time for me to get back to


2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.

I've been thinking about this for a while now, and I think it's time for me to take a break
</code></pre></div></div>

<p>由于柱大小只被设为 5，因此最终获得的 3 个序列看上去非常接近。</p>

<p>有趣的是，人类语言似乎并不遵循下一个词是最高概率的分布，换句话说，真实的人类语言具有高度的随机性，是不可预测的。下图展示了人类语言与柱搜索在每个时间步词语概率的对比：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/human_text_vs_beam_search.png" width="450px" style="display: block; margin: auto;" /></p>

<p>因此，柱搜索更适用于机器翻译或摘要等生成序列长度大致可预测的任务，而在对话生成、故事生成等开放式文本生成任务 (open-ended generation) 上表现不佳。虽然通过 n-gram 或者其他惩罚项可以缓解“重复”问题，但是如何控制”不重复”和“重复”之间的平衡又非常困难。</p>

<p>所以，对于开放式文本生成任务，我们需要引入更多的随机性——这就是采样方法。</p>

<h3 id="随机采样">随机采样</h3>

<p>采样 (sampling) 最基本的形式就是从当前上下文的条件概率分布中随机地选择一个词作为下一个词，即：</p>

\[w_t \sim P(w\mid w_{1:t-1})\]

<p>对于前面图中的例子，一个基于采样的生成过程可能为（采样生成的结果不是唯一的）：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/sampling_search.png" width="600px" style="display: block; margin: auto;" /></p>

<p>这里“car”是从条件概率分布 $P(w\mid \text{“The”})$ 中采样得到，而“drives”是从分布 $P(w\mid \text{“The”, “car”})$ 中采样得到。</p>

<p>在 Transformers 库中，我们只需要在 <code class="language-plaintext highlighter-rouge">generate()</code> 中设置 <code class="language-plaintext highlighter-rouge">do_sample=True</code> 并且令 <code class="language-plaintext highlighter-rouge">top_k=0</code> 禁用 <em>Top-K</em> 采样就可以实现随机采样：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set seed to reproduce results. Feel free to change the seed though to get different results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># activate sampling and deactivate top_k by setting top_k sampling to 0
</span><span class="n">sample_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog along the seven mile loop along Green Bay's Skagit River. In the central part of Monroe County about 100 miles east of sheboygan, it is almost deserted. But along the way there are often carefully
</code></pre></div></div>

<p>看上去还不错，但是细读的话会发现不是很连贯，这也是采样生成文本的通病：模型经常会生成前后不连贯的片段。一种解决方式是通过降低 softmax 的温度 (temperature) 使得分布 $P(w\mid w_{1:t-1})$ 更尖锐，即进一步增加高概率词出现的可能性和降低低概率词出现的可能性。例如对上面的例子应用降温：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/sampling_search_with_temp.png" width="600px" style="display: block; margin: auto;" /></p>

<p>这样在第一个时间步，条件概率变得更加尖锐，几乎不可能会选择到“car”。我们只需要在 <code class="language-plaintext highlighter-rouge">generate()</code> 中设置 <code class="language-plaintext highlighter-rouge">temperature</code> 来就可以实现对分布的降温：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set seed to reproduce results. Feel free to change the seed though to get different results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># use temperature to decrease the sensitivity to low probability candidates
</span><span class="n">sample_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> 
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.6</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog, but it's pretty much impossible to get the best out of my dog.

Pinky is a bit of a big she-wolf, but she is pretty much the most adorable of all the wolves.
</code></pre></div></div>

<p>可以看到生成的文本更加连贯了。降温操作实际上是在减少分布的随机性，当我们把 temperature 设为 0 时就等同于贪心解码。</p>

<h3 id="top-k-采样">Top-K 采样</h3>

<p>类似于柱搜索，<em>Top-K</em> 采样在每个时间步都保留最可能的 K 个词，然后在这 K 个词上重新分配概率质量。例如我们对上面的示例进行 <em>Top-K</em> 采样，这里设置 $K=6$ 在每个时间步都将采样池控制在 6 个词。：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/top_k_sampling.png" width="700px" style="display: block; margin: auto;" /></p>

<p>可以看到，6 个最可能的词（记为 $V_{\text{top-K}}$）虽然仅包含第一个时间步中整体概率质量的大约 $\frac{2}{3}$，但是几乎包含了第二个时间步中所有的概率质量。尽管如此，它还是成功地消除了第二步中那些奇怪的候选词（例如“not”、“the”、“small”、“told”）。</p>

<p>下面我们通过在 <code class="language-plaintext highlighter-rouge">generate()</code> 中设置 <code class="language-plaintext highlighter-rouge">top_k=10</code> 来进行 <em>Top-K</em> 采样：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set seed to reproduce results. Feel free to change the seed though to get different results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># set top_k to 10
</span><span class="n">sample_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">top_k</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog, but it's a bit of a pain in the ass to see that the dog does not get to walk with me.

I think my dog is just fine. But he needs some time to get used
</code></pre></div></div>

<p><em>Top-K</em> 采样的一个问题是它无法动态调整每个时间步从概率分布 $P$ 中过滤出来的单词数量，这会导致有些词可能是从非常尖锐的分布（上图中右侧）中采样的，而其他单词则可能是从平坦的分布（上图中左侧）中采样的，从而无法保证生成序列整体的质量。</p>

<h3 id="top-p-nucleus-采样">Top-p (nucleus) 采样</h3>

<p><em>Top-p</em> 对 <em>Top-K</em> 进行了改进，每次只从累积概率超过 $p$ 的最小的可能词集中进行选择，然后在这组词语中重新分配概率质量。这样，每个时间步的词语集合的大小就可以根据下一个词的条件概率分布动态增加和减少。下图展示了一个 Top-p 采样的例子：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-7/top_p_sampling.png" width="700px" style="display: block; margin: auto;" /></p>

<p>这里我们设置 $p=0.92$，<em>Top-p</em> 采样在每个时间步会在整体概率质量超过 92% 的最小单词集合（定义为 $V_{\text{top-p}}$）中进行选择。上图左边的例子中，<em>Top-p</em> 采样出了 9 个最可能的词语，而在右边的例子中，只选了 3 个最可能的词，整体概率质量就已经超过了 92%。可以看到，当下一个词难以预测时（例如 $P(w\mid \text{“The”})$），<em>Top-p</em> 采样会保留很多可能的词，而当下一个词相对容易预测时（例如 $P(w\mid \text{“The”, “car”})$），<em>Top-p</em> 就只会保留很少的词。</p>

<p>我们只需要在 <code class="language-plaintext highlighter-rouge">generate()</code> 中设置 <code class="language-plaintext highlighter-rouge">0 &lt; top_p &lt; 1</code> 就可以激活 Top-p 采样了：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set seed to reproduce results. Feel free to change the seed though to get different results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># deactivate top_k sampling and sample only from 92% most likely words
</span><span class="n">sample_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span> 
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.92</span><span class="p">,</span> 
    <span class="n">top_k</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
I enjoy walking with my cute dog along the Tokyo highway," said Beranito, 47, the man who moved to the new apartment in 2013 with his wife. "I liked to sit next to him on the roof when I was doing programming.
</code></pre></div></div>

<p>虽然理论上 <em>Top-p</em> 采样比 <em>Top-K</em> 采样更灵活，但是两者在实际应用中都被广泛采用，<em>Top-p</em> 甚至可以与 <em>Top-K</em> 共同工作，这可以在排除低概率词的同时还允许进行一些动态选择。</p>

<p>最后，与贪心搜索类似，为了获得多个独立采样的结果，我们设置 <code class="language-plaintext highlighter-rouge">num_return_sequences &gt; 1</code>，并且同时结合 <em>Top-p</em> 和 <em>Top-K</em> 采样：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set seed to reproduce results. Feel free to change the seed though to get different results
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3
</span><span class="n">sample_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">input_ids</span><span class="p">,</span>
    <span class="n">do_sample</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
    <span class="n">max_length</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">top_k</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
    <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> 
    <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Output:</span><span class="se">\n</span><span class="s">"</span> <span class="o">+</span> <span class="mi">100</span> <span class="o">*</span> <span class="s">'-'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sample_output</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sample_outputs</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"{}: {}</span><span class="se">\n\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">sample_output</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Output:
----------------------------------------------------------------------------------------------------
0: I enjoy walking with my cute dog, and she is the perfect animal companion to me. She helps me get on my feet as often as possible. I love sharing my love and care with all of my dogs. I have the highest respect for them


1: I enjoy walking with my cute dog when he is around my neck," she said. "I'm just doing it. It's not something that's easy for me to do when I'm the leader."

The family is just beginning to see


2: I enjoy walking with my cute dog, and we are both very pleased by his behavior. He seems to be extremely curious about the world around him, and just as he is searching for his place of origin he is able to spot and find it easily
</code></pre></div></div>

<h2 id="代码">代码</h2>

<p>与之前一样，我们按照功能将翻译模型的代码拆分成模块并且存放在不同的文件中，整理后的代码存储在 Github：<br />
<a href="https://github.com/jsksxs360/How-to-use-Transformers/tree/main/src/seq2seq_translation">How-to-use-Transformers/src/seq2seq_translation/</a></p>

<p>运行 <em>run_translation_marian.sh</em> 脚本即可进行训练。如果要进行测试或者将模型输出的翻译结果保存到文件，只需把脚本中的 <code class="language-plaintext highlighter-rouge">--do_train</code> 改成 <code class="language-plaintext highlighter-rouge">--do_test</code> 或 <code class="language-plaintext highlighter-rouge">--do_predict</code>。</p>

<blockquote>
  <p>经过 3 轮训练，最终 Marian 模型在测试集上的 BLEU 值为 54.87%（Nvidia Tesla V100, batch=32）。</p>
</blockquote>

<h2 id="参考">参考</h2>

<p><a href="https://huggingface.co/course/chapter1/1">[1]</a> HuggingFace 在线教程<br />
<a href="https://pytorch.org/docs/stable/">[2]</a> Pytorch 官方文档<br />
<a href="https://huggingface.co/docs/transformers/index">[3]</a> Transformers 官方文档<br />
<a href="https://huggingface.co/blog/how-to-generate">[4]</a> HuggingFace 博文《How to generate text》</p>]]></content><author><name>SHENG XU</name></author><category term="NLP" /><summary type="html"><![CDATA[本章我们将运用 Transformers 库来完成翻译任务。翻译是典型的序列到序列 (sequence-to-sequence, Seq2Seq) 任务，即对于每一个输入序列都会输出一个对应的序列。翻译在任务形式上与许多其他任务很接近，例如：]]></summary></entry><entry><title type="html">第九章：序列标注任务</title><link href="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-18-transformers-note-6.html" rel="alternate" type="text/html" title="第九章：序列标注任务" /><published>2022-03-18T00:00:00+08:00</published><updated>2022-03-18T00:00:00+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/nlp/transformers-note-6</id><content type="html" xml:base="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-18-transformers-note-6.html"><![CDATA[<p>我们的第一个实战任务是序列标注 (Sequence Labeling/Tagging)，其目标是为文本中的每一个 token 分配一个标签，因此 Transformers 库也将其称为 token 分类任务。常见的序列标注任务有<strong>命名实体识别 NER</strong> (Named Entity Recognition) 和<strong>词性标注 POS</strong> (Part-Of-Speech tagging)。</p>

<blockquote>
  <p>命名实体识别 NER 旨在识别出文本中诸如人物、地点、组织等实体，即为所有的 token 都打上实体标签（包含“非实体”）。词性标注 POS 旨在为文本中的每一个词语标注上对应的词性，例如名词、动词、形容词等。</p>
</blockquote>

<p>下面我们以 NER 为例，运用 Transformers 库手工构建一个基于 BERT 的模型来完成任务。</p>

<h2 id="1-准备数据">1. 准备数据</h2>

<p>我们选择 <a href="https://opendata.pku.edu.cn/dataset.xhtml?persistentId=doi:10.18170/DVN/SEYRX5">1998 年人民日报语料库</a>作为数据集，该语料库标注了大量的语言学信息，可以同时<a href="https://github.com/howl-anderson/tools_for_corpus_of_people_daily">用于</a>分词、NER 等任务。这里我们直接使用处理好的 NER 语料 <a href="http://s3.bmio.net/kashgari/china-people-daily-ner-corpus.tar.gz">china-people-daily-ner-corpus.tar.gz</a>。</p>

<p>该语料已经划分好了训练集、验证集和测试集，分别对应 example.train、example.dev 和 example.test 文件，包含 20864 / 2318 / 4636 个句子。语料采用我们在<a href="/2022/03/08/transformers-note-5.html">《快速分词器》</a>中介绍过的 IOB2 格式进行标注，一行对应一个字：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>海 O
钓 O
比 O
赛 O
地 O
点 O
在 O
厦 B-LOC
门 I-LOC
与 O
金 B-LOC
门 I-LOC
之 O
间 O
的 O
海 O
域 O
。 O
</code></pre></div></div>

<p>回顾一下，在 IOB2 格式中，”B-XXX”表示某一类标签的开始，”I-XXX”表示某一类标签的中间，”O”表示非标签。人民日报语料中标注有人物 (PER)、地点 (LOC) 和组织 (ORG) 三种实体类型，因此共有 7 种标签：</p>

<ul>
  <li>“O”：非实体；</li>
  <li>“B-PER/I-PER”：人物实体的起始/中间；</li>
  <li>“B-LOC/I-LOC”：地点实体的起始/中间；</li>
  <li>“B-ORG/I-ORG”：组织实体的起始/中间。</li>
</ul>

<h3 id="构建数据集">构建数据集</h3>

<p>与之前一样，我们首先编写继承自 <code class="language-plaintext highlighter-rouge">Dataset</code> 类的自定义数据集用于组织样本和标签。数据集中句子之间采用空行分隔，因此我们首先通过 <code class="language-plaintext highlighter-rouge">'\n\n'</code> 切分出句子，然后按行读取句子中每一个字和对应的标签，如果标签以 <code class="language-plaintext highlighter-rouge">B</code> 或者 <code class="language-plaintext highlighter-rouge">I</code> 开头，就表示出现了实体。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="n">categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">PeopleDaily</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">.</span><span class="n">read</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n\n</span><span class="s">'</span><span class="p">)):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">sentence</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="s">''</span><span class="p">,</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)):</span>
                    <span class="n">char</span><span class="p">,</span> <span class="n">tag</span> <span class="o">=</span> <span class="n">item</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
                    <span class="n">sentence</span> <span class="o">+=</span> <span class="n">char</span>
                    <span class="k">if</span> <span class="n">tag</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'B'</span><span class="p">):</span>
                        <span class="n">labels</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span><span class="p">,</span> <span class="n">tag</span><span class="p">[</span><span class="mi">2</span><span class="p">:]])</span> <span class="c1"># Remove the B- or I-
</span>                        <span class="n">categories</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
                    <span class="k">elif</span> <span class="n">tag</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'I'</span><span class="p">):</span>
                        <span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">char</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'sentence'</span><span class="p">:</span> <span class="n">sentence</span><span class="p">,</span> 
                    <span class="s">'labels'</span><span class="p">:</span> <span class="n">labels</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">Data</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</code></pre></div></div>

<p>下面我们通过读取文件构造数据集，并打印出一个训练样本：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">PeopleDaily</span><span class="p">(</span><span class="s">'data/china-people-daily-ner-corpus/example.train'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">PeopleDaily</span><span class="p">(</span><span class="s">'data/china-people-daily-ner-corpus/example.dev'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">PeopleDaily</span><span class="p">(</span><span class="s">'data/china-people-daily-ner-corpus/example.test'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'sentence': '海钓比赛地点在厦门与金门之间的海域。', 'labels': [[7, 8, '厦门', 'LOC'], [10, 11, '金门', 'LOC']]}
</code></pre></div></div>

<p>可以看到我们的自定义数据集成功地抽取出了句子中的实体标签（包括实体在原文中的位置以及标签）。</p>

<h3 id="数据预处理">数据预处理</h3>

<p>接着，我们就需要通过 <code class="language-plaintext highlighter-rouge">DataLoader</code> 库来按 batch 加载数据，并且将文本以及标签都转换为模型可以接受的输入形式。前面我们已经通过 <code class="language-plaintext highlighter-rouge">categories</code> 搜集了数据集中的所有实体标签，因此很容易建立标签映射字典：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">id2label</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s">'O'</span><span class="p">}</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">categories</span><span class="p">)):</span>
    <span class="n">id2label</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">id2label</span><span class="p">)]</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"B-</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s">"</span>
    <span class="n">id2label</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">id2label</span><span class="p">)]</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s">"</span>
<span class="n">label2id</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">id2label</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

<span class="k">print</span><span class="p">(</span><span class="n">id2label</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">label2id</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{0: 'O', 1: 'B-LOC', 2: 'I-LOC', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-PER', 6: 'I-PER'}
{'O': 0, 'B-LOC': 1, 'I-LOC': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-PER': 5, 'I-PER': 6}
</code></pre></div></div>

<p>与<a href="/2022/03/08/transformers-note-5.html">《快速分词器》</a>中的操作类似，我们需要通过快速分词器提供的映射函数，将实体标签从原文映射到切分出的 token 上。</p>

<p>下面以处理第一个样本为例。我们首先通过 <code class="language-plaintext highlighter-rouge">char_to_token()</code> 函数将实体标签从原文位置映射到切分后的 token 索引，并且通过上面构建好的映射字典将实体标签转换为实体编号。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="s">'海钓比赛地点在厦门与金门之间的海域。'</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s">'厦门'</span><span class="p">,</span> <span class="s">'LOC'</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="s">'金门'</span><span class="p">,</span> <span class="s">'LOC'</span><span class="p">]]</span>

<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">()</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="k">for</span> <span class="n">char_start</span><span class="p">,</span> <span class="n">char_end</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
    <span class="n">token_start</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">char_start</span><span class="p">)</span>
    <span class="n">token_end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">char_end</span><span class="p">)</span>
    <span class="n">label</span><span class="p">[</span><span class="n">token_start</span><span class="p">]</span> <span class="o">=</span> <span class="n">label2id</span><span class="p">[</span><span class="sa">f</span><span class="s">"B-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>
    <span class="n">label</span><span class="p">[</span><span class="n">token_start</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">token_end</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">label2id</span><span class="p">[</span><span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
<span class="k">print</span><span class="p">([</span><span class="n">id2label</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">label</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['[CLS]', '海', '钓', '比', '赛', '地', '点', '在', '厦', '门', '与', '金', '门', '之', '间', '的', '海', '域', '。', '[SEP]']
[0 0 0 0 0 0 0 0 1 2 0 1 2 0 0 0 0 0 0 0]
['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']
</code></pre></div></div>

<p>不过在实际编写 DataLoader 的批处理函数 <code class="language-plaintext highlighter-rouge">collate_fn()</code> 时，我们处理的就不再是一个而是多个样本，因此需要对上面的操作进行扩展。而且由于最终会通过交叉熵损失来优化模型参数，我们还需要将 <code class="language-plaintext highlighter-rouge">[CLS]</code>、<code class="language-plaintext highlighter-rouge">[SEP]</code>、<code class="language-plaintext highlighter-rouge">[PAD]</code> 等特殊 token 对应的标签设为 -100，以便在计算损失时忽略它们：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_sentence</span><span class="p">,</span> <span class="n">batch_tags</span>  <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_sentence</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'sentence'</span><span class="p">])</span>
        <span class="n">batch_tags</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'labels'</span><span class="p">])</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_sentence</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="n">batch_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_inputs</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_sentence</span><span class="p">):</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">())</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="k">for</span> <span class="n">char_start</span><span class="p">,</span> <span class="n">char_end</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">batch_tags</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]:</span>
            <span class="n">token_start</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">char_start</span><span class="p">)</span>
            <span class="n">token_end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">char_end</span><span class="p">)</span>
            <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="n">token_start</span><span class="p">]</span> <span class="o">=</span> <span class="n">label2id</span><span class="p">[</span><span class="sa">f</span><span class="s">"B-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>
            <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="n">token_start</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">token_end</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">label2id</span><span class="p">[</span><span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_label</span><span class="p">)</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="n">batch_X</span><span class="p">,</span> <span class="n">batch_y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_X shape:'</span><span class="p">,</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">.</span><span class="n">shape</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch_X</span><span class="p">.</span><span class="n">items</span><span class="p">()})</span>
<span class="k">print</span><span class="p">(</span><span class="s">'batch_y shape:'</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">batch_y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>batch_X shape: {
    'input_ids': torch.Size([4, 65]), 
    'token_type_ids': torch.Size([4, 65]), 
    'attention_mask': torch.Size([4, 65])
}
batch_y shape: torch.Size([4, 65])

{'input_ids': tensor([
        [ 101, 7716, 6645, 1298, 6432, 8024, 1762,  125, 3299, 4638, 3189, 3315,
         6913, 6435, 6612,  677, 8024,  704, 1744, 7339, 6820, 3295, 7566, 1044,
         6814, 5401, 1744, 7339, 8124, 1146,  722, 1914, 8024,  852, 3297, 5303,
         4638, 5310, 2229,  793, 3221, 1927, 1164,  511,  102,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0],
        [ 101, 3341, 5632, 1744, 2157, 4906, 2825,  914, 6822, 1355, 2245,  704,
         2552,  510,  704, 1744, 1093,  689, 1920, 2110,  510,  704, 1744, 2456,
         3332, 4777, 4955, 7368,  510, 1266, 3175,  769, 1920, 5023, 1296,  855,
         4638,  683, 2157, 5440, 2175,  749, 7987, 1366, 4638,  821,  689, 8024,
         2900, 1139,  749, 7987, 1366, 1355, 2245, 2773, 4526,  704, 4638,  679,
         6639,  722, 1905,  511,  102],
        [ 101, 3173, 1814, 2773, 3159,  510,  673, 3983, 2275, 2773, 3159,  510,
         7942, 3817, 4518,  924, 1310, 2773,  510, 4721, 3333, 2773, 3159,  100,
          100, 2218, 3221,  711,  749,  924, 1310, 1157, 1157, 6414, 4495, 1762,
         3031, 5074, 7027, 4638, 7484, 1462, 2048, 1036,  511,  102,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0],
        [ 101, 5401, 2102, 4767, 3779, 1062, 1385, 5307, 6814, 1939, 1213, 2894,
         3011, 8024, 6821, 3613,  793,  855, 2233, 5018, 1061,  511,  102,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0]]), 
 'token_type_ids': tensor(...), 
 'attention_mask': tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}

tensor([[-100,    5,    6,    6,    0,    0,    0,    0,    0,    0,    1,    2,
            0,    0,    0,    0,    0,    3,    4,    4,    0,    0,    0,    0,
            0,    3,    4,    4,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100],
        [-100,    0,    0,    3,    4,    4,    4,    4,    4,    4,    4,    4,
            4,    0,    3,    4,    4,    4,    4,    4,    0,    3,    4,    4,
            4,    4,    4,    4,    0,    3,    4,    4,    4,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    1,    2,    0,    0,    0,    0,
            0,    0,    0,    1,    2,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0, -100],
        [-100,    1,    2,    0,    0,    0,    1,    2,    2,    0,    0,    0,
            1,    2,    2,    0,    0,    0,    0,    1,    2,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100],
        [-100,    3,    4,    4,    4,    4,    4,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
         -100, -100, -100, -100, -100]])
</code></pre></div></div>

<p>可以看到，DataLoader 按照我们设置的 batch size 每次对 4 个样本进行编码，并且将 token 序列填充到了相同的长度。样本标签中实体对应的索引都转换为了实体编号，特殊 token 对应的索引都被设置为 -100。</p>

<blockquote>
  <p><strong>注意：</strong>由于我们在 DataLoader 中设置参数 <code class="language-plaintext highlighter-rouge">shuffle=True</code> 打乱训练集，因此每一次遍历样本的顺序都是随机的。随机遍历训练集会使得每次训练后得到的模型参数都不同，导致实验结果难以复现，因此大部分研究者会采用伪随机序列来进行实验。即通过设置随机种子来生成随机序列，只要种子相同，生成的随机序列就是相同的。</p>

  <p>例如只要你将种子设置为 7，就可以得到与上面完全相同的结果。</p>

  <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</code></pre></div>  </div>

</blockquote>

<h2 id="2-训练模型">2. 训练模型</h2>

<h3 id="构建模型">构建模型</h3>

<p>对于序列标注任务，可以直接使用 Transformers 库封装好的 <code class="language-plaintext highlighter-rouge">AutoModelForTokenClassification</code> 类，只需通过 <code class="language-plaintext highlighter-rouge">num_labels</code> 参数传入分类标签数量即可快速实现一个 token 分类器，或者是传入标签到编号的映射（更推荐），例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForTokenClassification</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_checkpoint</span><span class="p">,</span>
    <span class="n">id2label</span><span class="o">=</span><span class="n">id2label</span><span class="p">,</span>
    <span class="n">label2id</span><span class="o">=</span><span class="n">label2id</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p>考虑到这种方式不够灵活，因此与<a href="/2021/12/17/transformers-note-4.html">《微调预训练模型》</a>中一样，本文采用继承 Transformers 库预训练模型的方式来手工构建模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertPreTrainedModel</span><span class="p">,</span> <span class="n">BertModel</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BertForNER</span><span class="p">(</span><span class="n">BertPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">id2label</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bert_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForNER</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cpu device
BertForNER(
  (bert): BertModel(...)
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=7, bias=True)
)
</code></pre></div></div>

<p>可以看到，我们构建的模型首先运用 BERT 模型将每一个 token 都编码为语义向量，然后将输出序列送入到一个包含 7 个神经元的线性全连接层中对每一个 token 进行分类。</p>

<p>为了测试模型的操作是否符合预期，我们尝试将一个 batch 的数据送入模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([4, 65, 7])
</code></pre></div></div>

<p>对于 batch 内 4 个都被填充到长度为 $65$ 的样本，模型对每个 token 都应该输出一个 $7$ 维的向量（对应 7 种实体标签的预测 logits 值），因此这里模型的输出尺寸 $4\times 65 \times 7$ 完全符合预期。</p>

<h3 id="优化模型参数">优化模型参数</h3>

<p>与之前一样，我们将每一轮 Epoch 分为“训练循环”和“验证/测试循环”，在训练循环中计算损失、优化模型参数，在验证/测试循环中评估模型性能。下面我们首先实现训练循环。</p>

<p>但是，与文本分类任务对于每个样本只输出一个预测向量不同，token 分类任务会输出一个预测向量的序列（因为对每个 token 都进行了一次分类），因此在使用交叉熵计算模型损失时，不能像之前一样直接将模型的预测结果与标签送入到 <code class="language-plaintext highlighter-rouge">CrossEntropyLoss</code> 中进行计算。</p>

<p>对于高维输出（例如 2D 图像需要按像素计算交叉熵），<code class="language-plaintext highlighter-rouge">CrossEntropyLoss</code> 需要将输入维度调整为 $(batch, C, d_1, d_2,…,d_K)$，其中 $C$ 是类别个数，$K$ 是输入的维度。对于 token 分类任务，就是在 token 序列维度上计算交叉熵（Keras 称时间步），因此下面我们先通过 <code class="language-plaintext highlighter-rouge">pred.permute(0, 2, 1)</code> 交换后两维，将模型输出维度从$(batch, seq, 7)$ 调整为 $(batch, 7, seq)$，然后再计算损失。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>
</code></pre></div></div>

<p>验证/测试循环负责评估模型的性能。这里我们借助 <a href="https://github.com/chakki-works/seqeval">seqeval</a> 库进行评估，seqeval 是一个专门用于序列标注评估的 Python 库，支持 IOB、IOB、IOBES 等多种标注格式以及多种评估策略，例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">seqeval.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">seqeval.scheme</span> <span class="kn">import</span> <span class="n">IOB2</span>

<span class="n">y_true</span> <span class="o">=</span> <span class="p">[[</span><span class="s">'O'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">,</span> <span class="s">'B-LOC'</span><span class="p">,</span> <span class="s">'I-LOC'</span><span class="p">,</span> <span class="s">'I-LOC'</span><span class="p">,</span> <span class="s">'B-LOC'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">],</span> <span class="p">[</span><span class="s">'B-PER'</span><span class="p">,</span> <span class="s">'I-PER'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">]]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">[[</span><span class="s">'O'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">,</span> <span class="s">'B-LOC'</span><span class="p">,</span> <span class="s">'I-LOC'</span><span class="p">,</span> <span class="s">'I-LOC'</span><span class="p">,</span> <span class="s">'I-LOC'</span><span class="p">,</span> <span class="s">'B-LOC'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">],</span> <span class="p">[</span><span class="s">'B-PER'</span><span class="p">,</span> <span class="s">'I-PER'</span><span class="p">,</span> <span class="s">'O'</span><span class="p">]]</span>

<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

         LOC       0.50      0.50      0.50         2
         PER       1.00      1.00      1.00         1

   micro avg       0.67      0.67      0.67         3
   macro avg       0.75      0.75      0.75         3
weighted avg       0.67      0.67      0.67         3
</code></pre></div></div>

<p>可以看到，对于第一个地点实体，模型虽然预测正确了其中 2 个 token 的标签，但是仍然判为识别错误，只有当预测的起始和结束位置都正确时才算识别正确。</p>

<p>在验证/测试循环中，我们首先将预测结果和正确标签都先转换为 seqeval 库接受的格式，并且过滤掉标签值为 -100 的特殊 token，然后送入到 seqeval 提供的 <code class="language-plaintext highlighter-rouge">classification_report</code> 函数中计算 P / R / F1 等指标：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">seqeval.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">seqeval.scheme</span> <span class="kn">import</span> <span class="n">IOB2</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">true_labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">label</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
            <span class="n">true_predictions</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">))</span>
</code></pre></div></div>

<p>最后，将“训练循环”和“验证/测试循环”组合成 Epoch 就可以训练和验证模型了。与之前一样，我们使用 AdamW 优化器，并且通过 <code class="language-plaintext highlighter-rouge">get_scheduler()</code> 函数定义学习率调度器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device

Epoch 1/3
-------------------------------
loss: 0.051314: 100%|██████████| 5216/5216 [04:30&lt;00:00, 19.25it/s]
100%|██████████████████████████| 580/580 [00:17&lt;00:00, 33.77it/s]
              precision    recall  f1-score   support

         LOC       0.95      0.95      0.95      1951
         ORG       0.91      0.89      0.90       984
         PER       0.98      0.98      0.98       884

   micro avg       0.95      0.94      0.94      3819
   macro avg       0.95      0.94      0.94      3819
weighted avg       0.95      0.94      0.94      3819

Epoch 2/3
-------------------------------
loss: 0.033487: 100%|██████████| 5216/5216 [04:30&lt;00:00, 19.29it/s]
100%|██████████████████████████| 580/580 [00:17&lt;00:00, 33.89it/s]
              precision    recall  f1-score   support

         LOC       0.97      0.95      0.96      1951
         ORG       0.93      0.92      0.92       984
         PER       0.99      0.98      0.98       884

   micro avg       0.96      0.95      0.96      3819
   macro avg       0.96      0.95      0.96      3819
weighted avg       0.96      0.95      0.96      3819

Epoch 3/3
-------------------------------
loss: 0.024727: 100%|██████████| 5216/5216 [04:31&lt;00:00, 19.23it/s]
100%|██████████████████████████| 580/580 [00:17&lt;00:00, 34.05it/s]
              precision    recall  f1-score   support

         LOC       0.97      0.97      0.97      1951
         ORG       0.93      0.92      0.92       984
         PER       0.99      0.98      0.99       884

   micro avg       0.96      0.96      0.96      3819
   macro avg       0.96      0.96      0.96      3819
weighted avg       0.96      0.96      0.96      3819

Done!
</code></pre></div></div>

<h3 id="保存模型">保存模型</h3>

<p>在实际应用中，我们会根据每一轮模型在验证集上的性能来调整超参数以及选出最好的权重，最后将选出的模型应用于测试集以评估最终的性能。因此，我们首先在上面的验证/测试循环中返回 seqeval 库计算出的指标，然后在每一个 Epoch 中根据 macro-F1/micro-F1 指标保存在验证集上最好的模型：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">true_labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">label</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
            <span class="n">true_predictions</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">classification_report</span><span class="p">(</span>
      <span class="n">true_labels</span><span class="p">,</span> 
      <span class="n">true_predictions</span><span class="p">,</span> 
      <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> 
      <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">,</span> 
      <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_f1</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">valid_macro_f1</span><span class="p">,</span> <span class="n">valid_micro_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'micro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">valid_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">valid_f1</span> <span class="o">&gt;</span> <span class="n">best_f1</span><span class="p">:</span>
        <span class="n">best_f1</span> <span class="o">=</span> <span class="n">valid_f1</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span>
            <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> 
            <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_macrof1_</span><span class="si">{</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">valid_macro_f1</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_microf1_</span><span class="si">{</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">valid_micro_f1</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_weights.bin'</span>
        <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device

Epoch 1/3
-------------------------------
loss: 0.051314: 100%|██████████| 5216/5216 [04:30&lt;00:00, 19.25it/s]
100%|██████████████████████████| 580/580 [00:17&lt;00:00, 33.77it/s]
              precision    recall  f1-score   support

         LOC       0.95      0.95      0.95      1951
         ORG       0.91      0.89      0.90       984
         PER       0.98      0.98      0.98       884

   micro avg       0.95      0.94      0.94      3819
   macro avg       0.95      0.94      0.94      3819
weighted avg       0.95      0.94      0.94      3819

saving new weights...

Epoch 2/3
-------------------------------
loss: 0.033487: 100%|██████████| 5216/5216 [04:30&lt;00:00, 19.29it/s]
100%|██████████████████████████| 580/580 [00:17&lt;00:00, 33.89it/s]
              precision    recall  f1-score   support

         LOC       0.97      0.95      0.96      1951
         ORG       0.93      0.92      0.92       984
         PER       0.99      0.98      0.98       884

   micro avg       0.96      0.95      0.96      3819
   macro avg       0.96      0.95      0.96      3819
weighted avg       0.96      0.95      0.96      3819

saving new weights...

Epoch 3/3
-------------------------------
loss: 0.024727: 100%|██████████| 5216/5216 [04:31&lt;00:00, 19.23it/s]
100%|██████████████████████████| 580/580 [00:17&lt;00:00, 34.05it/s]
              precision    recall  f1-score   support

         LOC       0.97      0.97      0.97      1951
         ORG       0.93      0.92      0.92       984
         PER       0.99      0.98      0.99       884

   micro avg       0.96      0.96      0.96      3819
   macro avg       0.96      0.96      0.96      3819
weighted avg       0.96      0.96      0.96      3819

saving new weights...

Done!
</code></pre></div></div>

<p>可以看到，随着训练的进行，模型在验证集上的 F1 值在不断提升。因此，3 轮 Epoch 结束后，会在目录下保存 3 个模型权重：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch_1_valid_macrof1_94.340_microf1_94.399_weights.bin
epoch_2_valid_macrof1_95.641_microf1_95.728_weights.bin
epoch_3_valid_macrof1_95.878_microf1_96.049_weights.bin
</code></pre></div></div>

<p>至此，我们手工构建的 NER 模型的训练过程就完成了，完整的训练代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">seqeval.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">seqeval.scheme</span> <span class="kn">import</span> <span class="n">IOB2</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BertPreTrainedModel</span><span class="p">,</span> <span class="n">BertModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span><span class="p">,</span> <span class="n">get_scheduler</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">epoch_num</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="s">'PYTHONHASHSEED'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">device</span> <span class="o">=</span> <span class="s">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s">'cpu'</span>
<span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">'Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s"> device'</span><span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"bert-base-chinese"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>

<span class="n">categories</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">PeopleDaily</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">data_file</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_file</span><span class="p">):</span>
        <span class="n">Data</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_file</span><span class="p">,</span> <span class="s">'rt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">f</span><span class="p">.</span><span class="n">read</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n\n</span><span class="s">'</span><span class="p">)):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">line</span><span class="p">:</span>
                    <span class="k">break</span>
                <span class="n">sentence</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="s">''</span><span class="p">,</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)):</span>
                    <span class="n">char</span><span class="p">,</span> <span class="n">tag</span> <span class="o">=</span> <span class="n">item</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
                    <span class="n">sentence</span> <span class="o">+=</span> <span class="n">char</span>
                    <span class="k">if</span> <span class="n">tag</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'B'</span><span class="p">):</span>
                        <span class="n">labels</span><span class="p">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">char</span><span class="p">,</span> <span class="n">tag</span><span class="p">[</span><span class="mi">2</span><span class="p">:]])</span> <span class="c1"># Remove the B- or I-
</span>                        <span class="n">categories</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tag</span><span class="p">[</span><span class="mi">2</span><span class="p">:])</span>
                    <span class="k">elif</span> <span class="n">tag</span><span class="p">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">'I'</span><span class="p">):</span>
                        <span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="n">labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="o">+=</span> <span class="n">char</span>
                <span class="n">Data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s">'sentence'</span><span class="p">:</span> <span class="n">sentence</span><span class="p">,</span> 
                    <span class="s">'labels'</span><span class="p">:</span> <span class="n">labels</span>
                <span class="p">}</span>
        <span class="k">return</span> <span class="n">Data</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">PeopleDaily</span><span class="p">(</span><span class="s">'data/china-people-daily-ner-corpus/example.train'</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">PeopleDaily</span><span class="p">(</span><span class="s">'data/china-people-daily-ner-corpus/example.dev'</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">PeopleDaily</span><span class="p">(</span><span class="s">'data/china-people-daily-ner-corpus/example.test'</span><span class="p">)</span>

<span class="n">id2label</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s">'O'</span><span class="p">}</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">categories</span><span class="p">)):</span>
    <span class="n">id2label</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">id2label</span><span class="p">)]</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"B-</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s">"</span>
    <span class="n">id2label</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">id2label</span><span class="p">)]</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s">"</span>
<span class="n">label2id</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">id2label</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>

<span class="k">def</span> <span class="nf">collote_fn</span><span class="p">(</span><span class="n">batch_samples</span><span class="p">):</span>
    <span class="n">batch_sentence</span><span class="p">,</span> <span class="n">batch_labels</span>  <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">batch_samples</span><span class="p">:</span>
        <span class="n">batch_sentence</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'sentence'</span><span class="p">])</span>
        <span class="n">batch_labels</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="s">'labels'</span><span class="p">])</span>
    <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="n">batch_sentence</span><span class="p">,</span> 
        <span class="n">padding</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span>
    <span class="p">)</span>
    <span class="n">batch_label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_inputs</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s_idx</span><span class="p">,</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_sentence</span><span class="p">):</span>
        <span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">())</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="k">for</span> <span class="n">char_start</span><span class="p">,</span> <span class="n">char_end</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">batch_labels</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]:</span>
            <span class="n">token_start</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">char_start</span><span class="p">)</span>
            <span class="n">token_end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">char_end</span><span class="p">)</span>
            <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="n">token_start</span><span class="p">]</span> <span class="o">=</span> <span class="n">label2id</span><span class="p">[</span><span class="sa">f</span><span class="s">"B-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>
            <span class="n">batch_label</span><span class="p">[</span><span class="n">s_idx</span><span class="p">][</span><span class="n">token_start</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">token_end</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">label2id</span><span class="p">[</span><span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s">"</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">batch_label</span><span class="p">)</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">collote_fn</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BertForNER</span><span class="p">(</span><span class="n">BertPreTrainedModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">BertModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">add_pooling_layer</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">hidden_dropout_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">id2label</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">bert_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">bert</span><span class="p">(</span><span class="o">**</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">bert_output</span><span class="p">.</span><span class="n">last_hidden_state</span>
        <span class="n">sequence_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">sequence_output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BertForNER</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">):</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)))</span>
    <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="mi">0</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
    <span class="n">finish_batch_num</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="p">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>

        <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s">'loss: </span><span class="si">{</span><span class="n">total_loss</span><span class="o">/</span><span class="p">(</span><span class="n">finish_batch_num</span> <span class="o">+</span> <span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">7</span><span class="n">f</span><span class="si">}</span><span class="s">'</span><span class="p">)</span>
        <span class="n">progress_bar</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_loss</span>

<span class="k">def</span> <span class="nf">test_loop</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">true_labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">label</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
            <span class="n">true_predictions</span> <span class="o">+=</span> <span class="p">[</span>
                <span class="p">[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
            <span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">classification_report</span><span class="p">(</span>
      <span class="n">true_labels</span><span class="p">,</span> 
      <span class="n">true_predictions</span><span class="p">,</span> 
      <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> 
      <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">,</span> 
      <span class="n">output_dict</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">get_scheduler</span><span class="p">(</span>
    <span class="s">"linear"</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
    <span class="n">num_warmup_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_training_steps</span><span class="o">=</span><span class="n">epoch_num</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">best_f1</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch_num</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">/</span><span class="si">{</span><span class="n">epoch_num</span><span class="si">}</span><span class="se">\n</span><span class="s">-------------------------------"</span><span class="p">)</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">train_loop</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">test_loop</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    <span class="n">valid_macro_f1</span><span class="p">,</span> <span class="n">valid_micro_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'macro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'micro avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="n">valid_f1</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s">'weighted avg'</span><span class="p">][</span><span class="s">'f1-score'</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">valid_f1</span> <span class="o">&gt;</span> <span class="n">best_f1</span><span class="p">:</span>
        <span class="n">best_f1</span> <span class="o">=</span> <span class="n">valid_f1</span>
        <span class="k">print</span><span class="p">(</span><span class="s">'saving new weights...</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
        <span class="n">torch</span><span class="p">.</span><span class="n">save</span><span class="p">(</span>
            <span class="n">model</span><span class="p">.</span><span class="n">state_dict</span><span class="p">(),</span> 
            <span class="sa">f</span><span class="s">'epoch_</span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s">_valid_macrof1_</span><span class="si">{</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">valid_macro_f1</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_microf1_</span><span class="si">{</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">valid_micro_f1</span><span class="p">)</span><span class="si">:</span><span class="mf">0.3</span><span class="n">f</span><span class="si">}</span><span class="s">_weights.bin'</span>
        <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Done!"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="3-测试模型">3. 测试模型</h2>

<p>训练完成后，我们加载在验证集上性能最优的模型权重，汇报其在测试集上的性能，并且将模型的预测结果保存到文件中。</p>

<h3 id="处理模型输出">处理模型输出</h3>

<p>模型的输出是一个由预测向量组成的列表，每个向量对应一个 token 的预测结果，只需要在输出 logits 值上运用 softmax 函数就可以获得实体类别的预测概率。与<a href="/2022/03/08/transformers-note-5.html">《快速分词器》</a>中类似，我们首先从输出中取出“B-”或“I-”开头的 token，然后将这些 token 组合成实体，最后将实体对应的 token 的平均概率作为实体的概率。</p>

<p>下面我们以处理单个句子为例，加载训练好的 NER 模型来识别句子中的实体：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentence</span> <span class="o">=</span> <span class="s">'日本外务省3月18日发布消息称，日本首相岸田文雄将于19至21日访问印度和柬埔寨。'</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'epoch_3_valid_macrof1_95.878_microf1_96.049_weights.bin'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">,</span> <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">'offset_mapping'</span><span class="p">).</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>

    <span class="n">pred_label</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">id2label</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">label</span> <span class="o">!=</span> <span class="s">"O"</span><span class="p">:</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="c1"># Remove the B- or I-
</span>            <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">all_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">pred</span><span class="p">]]</span>
            <span class="c1"># Grab all the tokens labeled with I-label
</span>            <span class="k">while</span> <span class="p">(</span>
                <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="ow">and</span> 
                <span class="n">id2label</span><span class="p">[</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">==</span> <span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s">"</span>
            <span class="p">):</span>
                <span class="n">all_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_scores</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">start</span><span class="p">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">end</span><span class="p">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
            <span class="n">pred_label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s">"entity_group"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
                    <span class="s">"score"</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                    <span class="s">"word"</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
                    <span class="s">"start"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
                    <span class="s">"end"</span><span class="p">:</span> <span class="n">end</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">print</span><span class="p">(</span><span class="n">pred_label</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[
  {'entity_group': 'ORG', 'score': 0.9994237422943115, 'word': '日本外务省', 'start': 0, 'end': 5}, 
  {'entity_group': 'LOC', 'score': 0.9989436864852905, 'word': '日本', 'start': 16, 'end': 18}, 
  {'entity_group': 'PER', 'score': 0.9996790438890457, 'word': '岸田文雄', 'start': 20, 'end': 24}, 
  {'entity_group': 'LOC', 'score': 0.9996350705623627, 'word': '印度', 'start': 34, 'end': 36}, 
  {'entity_group': 'LOC', 'score': 0.9995178381601969, 'word': '柬埔寨', 'start': 37, 'end': 40}
]
</code></pre></div></div>

<p>可以看到模型成功地将“日本外务省”识别为组织 (ORG)，将“岸田文雄”识别为人物 (PER)，将“日本”、“印度”、“柬埔寨”识别为地点 (LOC)。</p>

<h3 id="保存预测结果">保存预测结果</h3>

<p>最后，我们简单扩展上面的代码以处理整个测试集，不仅像之前“验证/测试循环”中那样评估模型在测试集上的性能，并且将模型的预测结果以 json 格式存储到文件中：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>

<span class="n">model</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'epoch_3_valid_macrof1_95.878_microf1_96.049_weights.bin'</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="s">'cpu'</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'evaluating on test set...'</span><span class="p">)</span>
    <span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">true_labels</span> <span class="o">+=</span> <span class="p">[[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">l</span><span class="p">)]</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">label</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>
        <span class="n">true_predictions</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">id2label</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">p</span><span class="p">)]</span> <span class="k">for</span> <span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="k">if</span> <span class="n">l</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">true_predictions</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'strict'</span><span class="p">,</span> <span class="n">scheme</span><span class="o">=</span><span class="n">IOB2</span><span class="p">))</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'predicting labels...'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">s_idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">))):</span>
        <span class="n">example</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">s_idx</span><span class="p">]</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s">'sentence'</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">pred</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">cpu</span><span class="p">().</span><span class="n">numpy</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>

        <span class="n">pred_label</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">inputs_with_offsets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s">'sentence'</span><span class="p">],</span> <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">.</span><span class="n">tokens</span><span class="p">()</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">[</span><span class="s">"offset_mapping"</span><span class="p">]</span>

        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">id2label</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">label</span> <span class="o">!=</span> <span class="s">"O"</span><span class="p">:</span>
                <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="c1"># Remove the B- or I-
</span>                <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
                <span class="n">all_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">pred</span><span class="p">]]</span>
                <span class="c1"># Grab all the tokens labeled with I-label
</span>                <span class="k">while</span> <span class="p">(</span>
                    <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="ow">and</span> 
                    <span class="n">id2label</span><span class="p">[</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">==</span> <span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s">"</span>
                <span class="p">):</span>
                    <span class="n">all_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_scores</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
                <span class="n">word</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s">'sentence'</span><span class="p">][</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
                <span class="n">pred_label</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s">"entity_group"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
                        <span class="s">"score"</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                        <span class="s">"word"</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
                        <span class="s">"start"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
                        <span class="s">"end"</span><span class="p">:</span> <span class="n">end</span><span class="p">,</span>
                    <span class="p">}</span>
                <span class="p">)</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s">"sentence"</span><span class="p">:</span> <span class="n">example</span><span class="p">[</span><span class="s">'sentence'</span><span class="p">],</span> 
                <span class="s">"pred_label"</span><span class="p">:</span> <span class="n">pred_label</span><span class="p">,</span> 
                <span class="s">"true_label"</span><span class="p">:</span> <span class="n">example</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">'test_data_pred.json'</span><span class="p">,</span> <span class="s">'wt'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">exapmle_result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
            <span class="n">f</span><span class="p">.</span><span class="n">write</span><span class="p">(</span><span class="n">json</span><span class="p">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">exapmle_result</span><span class="p">,</span> <span class="n">ensure_ascii</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using cuda device

evaluating on test set...
100%|████████████| 1159/1159 [00:35&lt;00:00, 32.25it/s]
              precision    recall  f1-score   support

         LOC       0.96      0.96      0.96      3658
         ORG       0.90      0.92      0.91      2185
         PER       0.98      0.98      0.98      1864

   micro avg       0.95      0.95      0.95      7707
   macro avg       0.95      0.95      0.95      7707
weighted avg       0.95      0.95      0.95      7707

predicting labels...
100%|████████████| 4636/4636 [00:34&lt;00:00, 135.78it/s]
</code></pre></div></div>

<p>可以看到，模型最终在测试集上的宏/微 F1 值都达到 95% 左右。考虑到我们只使用了基础版本的 BERT 模型，并且只训练了 3 轮，这已经是一个不错的结果了。</p>

<p>我们打开保存预测结果的 <em>test_data_pred.json</em>，其中每一行对应一个样本，<code class="language-plaintext highlighter-rouge">sentence</code> 对应原文，<code class="language-plaintext highlighter-rouge">pred_label</code> 对应预测出的实体，<code class="language-plaintext highlighter-rouge">true_label</code> 对应标注实体信息。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
 "sentence": "我们变而以书会友，以书结缘，把欧美、港台流行的食品类图谱、画册、工具书汇集一堂。", 
 "pred_label": [
     {"entity_group": "LOC", "score": 0.9954637885093689, "word": "欧", "start": 15, "end": 16}, 
     {"entity_group": "LOC", "score": 0.9948422312736511, "word": "美", "start": 16, "end": 17}, 
     {"entity_group": "LOC", "score": 0.9960285425186157, "word": "港", "start": 18, "end": 19}, 
     {"entity_group": "LOC", "score": 0.9940919280052185, "word": "台", "start": 19, "end": 20}
 ], 
 "true_label": [
     [15, 15, "欧", "LOC"], 
     [16, 16, "美", "LOC"], 
     [18, 18, "港", "LOC"], 
     [19, 19, "台", "LOC"]
 ]
}
...
</code></pre></div></div>

<p>至此，我们运用 Transformers 库进行 NER 任务就全部完成了！</p>

<h2 id="代码">代码</h2>

<p>与之前一样，我们按照功能将代码拆分成模块并且存放在不同的文件中，整理后的代码存储在 Github：<br />
<a href="https://github.com/jsksxs360/How-to-use-Transformers/tree/main/src/sequence_labeling_ner_cpd">How-to-use-Transformers/src/sequence_labeling_ner_cpd/</a></p>

<p>与 Transformers 库类似，我们将模型损失的计算也包含进模型本身，这样在训练循环中我们就可以直接使用模型返回的损失进行反向传播。</p>

<p>为了简化数据处理，这里我们并没有将 <code class="language-plaintext highlighter-rouge">[CLS]</code>、<code class="language-plaintext highlighter-rouge">[SEP]</code>、<code class="language-plaintext highlighter-rouge">[PAD]</code> 等特殊 token 对应的标签设为 -100，而是维持原始的 0 值，然后在计算损失时借助 Attention Mask 来排除填充位置：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">active_loss</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
<span class="n">active_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">num_labels</span><span class="p">)[</span><span class="n">active_loss</span><span class="p">]</span>
<span class="n">active_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">active_loss</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">active_logits</span><span class="p">,</span> <span class="n">active_labels</span><span class="p">)</span>
</code></pre></div></div>

<p>最后通过 <code class="language-plaintext highlighter-rouge">view()</code> 将 batch 中的多个向量序列连接为一个序列，这样就可以直接使用交叉熵函数计算损失，而不必像我们上面那样进行维度调整。</p>

<p>除了本章介绍的纯基于 BERT 的 NER 模型，我们还实现了一个带有 CRF 层的 BERT+CRF 模型，分别通过运行 <em>run_ner_softmax.sh</em> 和 <em>run_ner_crf.sh</em> 脚本进行训练。如果要进行测试或者将预测结果保存到文件，只需把脚本中的 <code class="language-plaintext highlighter-rouge">--do_train</code> 改成 <code class="language-plaintext highlighter-rouge">--do_test</code> 或 <code class="language-plaintext highlighter-rouge">--do_predict</code>。</p>

<blockquote>
  <p>经过 3 轮训练，最终 BERT 模型在测试集上的准确率为 95.10%，BERT+CRF 为 95.37%（Nvidia Tesla V100, batch=4）。</p>
</blockquote>

<h2 id="参考">参考</h2>

<p><a href="https://huggingface.co/course/chapter1/1">[1]</a> HuggingFace 在线教程<br />
<a href="https://pytorch.org/docs/stable/">[2]</a> Pytorch 官方文档<br />
<a href="https://github.com/bojone/bert4keras/blob/master/examples/task_sequence_labeling_ner_crf.py">[3]</a> Bert4Keras 库中文 NER 实现</p>]]></content><author><name>SHENG XU</name></author><category term="NLP" /><summary type="html"><![CDATA[我们的第一个实战任务是序列标注 (Sequence Labeling/Tagging)，其目标是为文本中的每一个 token 分配一个标签，因此 Transformers 库也将其称为 token 分类任务。常见的序列标注任务有命名实体识别 NER (Named Entity Recognition) 和词性标注 POS (Part-Of-Speech tagging)。]]></summary></entry><entry><title type="html">第八章：快速分词器</title><link href="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-08-transformers-note-5.html" rel="alternate" type="text/html" title="第八章：快速分词器" /><published>2022-03-08T00:00:00+08:00</published><updated>2022-03-08T00:00:00+08:00</updated><id>http://localhost:4000/How-to-use-Transformers/nlp/transformers-note-5</id><content type="html" xml:base="http://localhost:4000/How-to-use-Transformers/nlp/2022-03-08-transformers-note-5.html"><![CDATA[<p>通过前面章节的介绍，我们已经对 Transformers 库有了基本的了解，并且上手微调了一个句子对分类模型。从本章开始，我们将通过一系列的实例向大家展示如何使用 Transformers 库来完成目前主流的 NLP 任务。</p>

<p>在开始之前，我们先回顾一下在第五章《模型与分词器》中已经介绍过的分词器 (Tokenizer)，进一步了解分词器的一些高级功能。</p>

<h2 id="1-快速分词器">1. 快速分词器</h2>

<p>前面我们已经介绍过如何使用分词器将文本编码为 token IDs，以及反过来将 token IDs 解码回文本。</p>

<p>实际上，Hugging Face 共提供了两种分分词器：</p>

<ol>
  <li><strong>慢速分词器：</strong>Transformers 库自带，使用 Python 编写；</li>
  <li><strong>快速分词器：</strong>Tokenizers 库提供，使用 Rust 编写。</li>
</ol>

<p>特别地，快速分词器除了能进行编码和解码之外，还能够追踪原文到 token 之间的映射，这对于处理序列标注、自动问答等任务非常重要。</p>

<blockquote>
  <p>快速分词器只有在并行处理大量文本时才能发挥出速度优势，在处理单个句子时甚至可能慢于慢速分词器。</p>
</blockquote>

<p>我们一直推荐使用的 <code class="language-plaintext highlighter-rouge">AutoTokenizer</code> 类除了能根据 checkpoint 自动加载对应分词器以外，默认就会选择快速分词器，因此在大部分情况下都应该使用 <code class="language-plaintext highlighter-rouge">AutoTokenizer</code> 类来加载分词器。</p>

<h3 id="再看分词结果">再看分词结果</h3>

<p>其实，分词器返回的是 <code class="language-plaintext highlighter-rouge">BatchEncoding</code> 对象，它是基于 Python 字典的子类，因此我们之前可以像字典一样来解析分词结果。我们可以通过 <code class="language-plaintext highlighter-rouge">Tokenizer</code> 或 <code class="language-plaintext highlighter-rouge">BatchEncoding</code> 对象的 <code class="language-plaintext highlighter-rouge">is_fast</code> 属性来判断使用的是哪种分词器：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"bert-base-cased"</span><span class="p">)</span>
<span class="n">example</span> <span class="o">=</span> <span class="s">"Hello world!"</span>
<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">encoding</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'tokenizer.is_fast:'</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">is_fast</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'encoding.is_fast:'</span><span class="p">,</span> <span class="n">encoding</span><span class="p">.</span><span class="n">is_fast</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'transformers.tokenization_utils_base.BatchEncoding'&gt;
tokenizer.is_fast: True
encoding.is_fast: True
</code></pre></div></div>

<p>对于快速分词器，<code class="language-plaintext highlighter-rouge">BatchEncoding</code> 对象还提供了一些额外的方法。例如，我们可以直接通过 <code class="language-plaintext highlighter-rouge">tokens()</code> 函数来获取切分出的 token：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">"bert-base-cased"</span><span class="p">)</span>
<span class="n">example</span> <span class="o">=</span> <span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span>
<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['[CLS]', 'My', 'name', 'is', 'S', '##yl', '##va', '##in', 'and', 'I', 'work', 'at', 'Hu', '##gging', 'Face', 'in', 'Brooklyn', '.', '[SEP]']
</code></pre></div></div>

<h3 id="追踪映射">追踪映射</h3>

<p>在上面的例子中，索引为 5 的 token 是“##yl”，它是词语“Sylvain”的一个部分，因此在映射回原文时不应该被单独看待。我们可以通过 <code class="language-plaintext highlighter-rouge">word_ids()</code> 函数来获取每一个 token 对应的词语索引：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">encoding</span><span class="p">.</span><span class="n">word_ids</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[None, 0, 1, 2, 3, 3, 3, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, None]
</code></pre></div></div>

<p>可以看到，特殊 token <code class="language-plaintext highlighter-rouge">[CLS]</code> 和 <code class="language-plaintext highlighter-rouge">[SEP]</code> 被映射到 None，其他 token 都被映射到对应的来源词语。这可以为很多任务提供帮助，例如对于序列标注任务，就可以运用这个映射将词语的标签转换到 token 的标签；对于遮蔽语言建模 (Masked Language Modeling, MLM)，就可以实现全词遮盖 (whole word masking)，将属于同一个词语的 token 全部遮盖掉。</p>

<blockquote>
  <p><strong>注意：</strong>词语索引取决于模型对于 word 的定义，例如“I’ll”到底算是一个词语还是两个词语，与分词器采用的预分词 (pre-tokenization) 操作有关。一些分词器直接采用空格切分，因此”I’ll“会被视为一个词语，还有一些分词器会进一步按照标点符号进行切分，那么 ‘I’ll’ 就会被视为两个词语。</p>
</blockquote>

<p>快速分词器通过偏移量列表追踪文本、词语和 token 之间的映射，因此可以很容易地在这三者之间互相转换：</p>

<ul>
  <li>
    <p><strong>词语/token $\Rightarrow$ 文本</strong>：通过 <code class="language-plaintext highlighter-rouge">word_to_chars()</code>、<code class="language-plaintext highlighter-rouge">token_to_chars()</code> 函数来实现，返回词语/token 在原文中的起始和结束偏移量。</p>

    <p>例如，前面例子中索引为 5 的 token 是 ‘##yl’，它对应的词语索引为 3，因此我们可以方便的从从原文中抽取出对应的 token 片段和词语片段：</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">token_index</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">print</span><span class="p">(</span><span class="s">'the 5th token is:'</span><span class="p">,</span> <span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">()[</span><span class="n">token_index</span><span class="p">])</span>
<span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">token_to_chars</span><span class="p">(</span><span class="n">token_index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'corresponding text span is:'</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
<span class="n">word_index</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">word_ids</span><span class="p">()[</span><span class="n">token_index</span><span class="p">]</span> <span class="c1"># 3
</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">word_to_chars</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'corresponding word span is:'</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
</code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>the 5th token is: ##yl
corresponding text span is: yl
corresponding word span is: Sylvain
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>词语 $\Leftrightarrow$ token：</strong>前面的例子中我们使用 <code class="language-plaintext highlighter-rouge">word_ids()</code> 获取了整个 token 序列对应的词语索引。实际上，词语和 token 之间可以直接通过索引直接映射，分别通过 <code class="language-plaintext highlighter-rouge">token_to_word()</code> 和 <code class="language-plaintext highlighter-rouge">word_to_tokens()</code> 来实现：</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">token_index</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">print</span><span class="p">(</span><span class="s">'the 5th token is:'</span><span class="p">,</span> <span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">()[</span><span class="n">token_index</span><span class="p">])</span>
<span class="n">corresp_word_index</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">token_to_word</span><span class="p">(</span><span class="n">token_index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'corresponding word index is:'</span><span class="p">,</span> <span class="n">corresp_word_index</span><span class="p">)</span>
<span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">word_to_chars</span><span class="p">(</span><span class="n">corresp_word_index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'the word is:'</span><span class="p">,</span> <span class="n">example</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
<span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">encoding</span><span class="p">.</span><span class="n">word_to_tokens</span><span class="p">(</span><span class="n">corresp_word_index</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'corresponding tokens are:'</span><span class="p">,</span> <span class="n">encoding</span><span class="p">.</span><span class="n">tokens</span><span class="p">()[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
</code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>the 5th token is: ##yl
corresponding word index is: 3
the word is: Sylvain
corresponding tokens are: ['S', '##yl', '##va', '##in']
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>文本 $\Rightarrow$ 词语/token：</strong>通过 <code class="language-plaintext highlighter-rouge">char_to_word()</code> 和 <code class="language-plaintext highlighter-rouge">char_to_token()</code> 方法来实现：</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chars</span> <span class="o">=</span> <span class="s">'My name is Sylvain'</span>
<span class="k">print</span><span class="p">(</span><span class="s">'characters of "{}" ars: {}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">chars</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">chars</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'corresponding word index: '</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'"{}": {} '</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_word</span><span class="p">(</span><span class="n">i</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="s">""</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">corresponding token index: '</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chars</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'"{}": {} '</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">encoding</span><span class="p">.</span><span class="n">char_to_token</span><span class="p">(</span><span class="n">i</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="s">""</span><span class="p">)</span>
</code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>characters of "My name is Sylvain" ars: ['M', 'y', ' ', 'n', 'a', 'm', 'e', ' ', 'i', 's', ' ', 'S', 'y', 'l', 'v', 'a', 'i', 'n']
corresponding word index: 
"M": 0 "y": 0 " ": None "n": 1 "a": 1 "m": 1 "e": 1 " ": None "i": 2 "s": 2 " ": None "S": 3 "y": 3 "l": 3 "v": 3 "a": 3 "i": 3 "n": 3 
corresponding token index: 
"M": 1 "y": 1 " ": None "n": 2 "a": 2 "m": 2 "e": 2 " ": None "i": 3 "s": 3 " ": None "S": 4 "y": 5 "l": 5 "v": 6 "a": 6 "i": 7 "n": 7
</code></pre></div>    </div>

    <p>由于空格会被 BERT 的分词器过滤掉，因此对应的词语或 token 索引都为 None。</p>
  </li>
</ul>

<p>下面，我们将以序列标注和问答任务为例，展示如何在实际任务中运用快速分词器。</p>

<h2 id="2-序列标注任务">2. 序列标注任务</h2>

<p>在<a href="/2021/12/08/transformers-note-1.html">《开箱即用的 pipelines》</a>中我们已经介绍过，序列标注任务在 Transformers 库中被称为 token 分类任务，典型的如命名实体识别 (NER)，负责识别出文本中哪些片段是实体。</p>

<h3 id="pipeline-的输出">pipeline 的输出</h3>

<p>前面我们讲过，NER pipeline 模型实际上封装了三个过程：</p>

<ol>
  <li>对文本进行编码；</li>
  <li>将输入送入模型；</li>
  <li>对模型输出进行后处理。</li>
</ol>

<p>前两个步骤在所有 pipeline 模型中都是一样的，只有第三个步骤——对模型输出进行后处理，则是根据任务类型而不同。token 分类 pipeline 模型在默认情况下会加载 <a href="https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english">dbmdz/bert-large-cased-finetuned-conll03-english</a> NER 模型，我们直接打印出它的输出：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">token_classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">"token-classification"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">token_classifier</span><span class="p">(</span><span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'entity': 'I-PER', 'score': 0.99938285, 'index': 4, 'word': 'S', 'start': 11, 'end': 12}, 
 {'entity': 'I-PER', 'score': 0.99815494, 'index': 5, 'word': '##yl', 'start': 12, 'end': 14}, 
 {'entity': 'I-PER', 'score': 0.99590707, 'index': 6, 'word': '##va', 'start': 14, 'end': 16}, 
 {'entity': 'I-PER', 'score': 0.99923277, 'index': 7, 'word': '##in', 'start': 16, 'end': 18}, 
 {'entity': 'I-ORG', 'score': 0.9738931, 'index': 12, 'word': 'Hu', 'start': 33, 'end': 35}, 
 {'entity': 'I-ORG', 'score': 0.976115, 'index': 13, 'word': '##gging', 'start': 35, 'end': 40}, 
 {'entity': 'I-ORG', 'score': 0.9887976, 'index': 14, 'word': 'Face', 'start': 41, 'end': 45}, 
 {'entity': 'I-LOC', 'score': 0.9932106, 'index': 16, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
</code></pre></div></div>

<p>可以看到，模型成功地将“Sylvain”对应的 token 识别为人物，“Hugging Face”对应的 token 识别为机构，以及“Brooklyn”识别为地点。我们还可以通过设置参数 <code class="language-plaintext highlighter-rouge">grouped_entities=True</code> 让模型自动合属于同一个实体的 token：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">token_classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">"token-classification"</span><span class="p">,</span> <span class="n">grouped_entities</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">token_classifier</span><span class="p">(</span><span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'entity_group': 'PER', 'score': 0.9981694, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.9796019, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.9932106, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
</code></pre></div></div>

<p>实际上，NER pipeline 模型提供了多种组合 token 形成实体的策略，可以通过 <code class="language-plaintext highlighter-rouge">aggregation_strategy</code> 参数进行设置：</p>

<ul>
  <li><strong>simple：</strong>默认策略，以实体对应所有 token 的平均分数作为得分，例如“Sylvain”的分数就是“S”、“##yl”、“##va”和“##in”四个 token 分数的平均；</li>
  <li><strong>first：</strong>将第一个 token 的分数作为实体的分数，例如“Sylvain”的分数就是 token “S”的分数；</li>
  <li><strong>max：</strong>将 token 中最大的分数作为整个实体的分数；</li>
  <li><strong>average：</strong>对应词语（注意不是 token）的平均分数作为整个实体的分数，例如“Hugging Face”就是“Hugging”（0.975）和 “Face”（0.98879）的平均值 0.9819，而 simple 策略得分为 0.9796。</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">token_classifier</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">"token-classification"</span><span class="p">,</span> <span class="n">aggregation_strategy</span><span class="o">=</span><span class="s">"max"</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">token_classifier</span><span class="p">(</span><span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'entity_group': 'PER', 'score': 0.99938285, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.9824563, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.9932106, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
</code></pre></div></div>

<h3 id="构造模型输出">构造模型输出</h3>

<p>下面，我们将通过 <code class="language-plaintext highlighter-rouge">AutoModelForTokenClassification</code> 类来构造一个 token 分类模型，并且手工地对模型的输出进行后处理，获得与 pipeline 模型相同的结果。这里我们同样将 checkpoint 设为 dbmdz/bert-large-cased-finetuned-conll03-english：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForTokenClassification</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"dbmdz/bert-large-cased-finetuned-conll03-english"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">example</span> <span class="o">=</span> <span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([1, 19])
torch.Size([1, 19, 9])
</code></pre></div></div>

<p>可以看到，模型的输入是一个长度为 $19$ 的 token 序列，输出尺寸为 $1 \times 19 \times 9$，即模型对每个 token 都会输出一个包含 9 个 logits 值的向量（9 分类）。我们可以通过 <code class="language-plaintext highlighter-rouge">model.config.id2label</code> 属性来查看这 9 个标签：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{0: 'O', 1: 'B-MISC', 2: 'I-MISC', 3: 'B-PER', 4: 'I-PER', 5: 'B-ORG', 6: 'I-ORG', 7: 'B-LOC', 8: 'I-LOC'}
</code></pre></div></div>

<p>这里使用的是 IOB 标签格式，“B-XXX”表示某一种标签的开始，“I-XXX”表示某一种标签的中间，“O”表示非标签。因此，该模型识别的实体类型共有 4 种：miscellaneous、person、organization 和 location。</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-5/iob_versions.png" alt="IOB_versions.png" /></p>

<p>在实际应用中， IOB 标签格式又分为两种：</p>

<ul>
  <li><strong>IOB1：</strong>如上图绿色所示，只有在分隔类别相同的连续 token 时才会使用 B-XXX 标签，例如右图中的“Alice”和“Bob”是连续的两个人物，因此“Bob”的起始 token 标签为“B-PER”，而“Alice”的起始 token 为“I-PER”；</li>
  <li><strong>IOB2：</strong>如上图粉色所示，不管任何情况下，起始 token 的标签都为“B-XXX”，后续 token 的标签都为“I-XXX”，因此右图中“Alice”和“Bob”的起始 token 都为“B-PER”。</li>
</ul>

<p>从 pipeline 的输出结果可以看到，模型采用的是 IOB1 格式，因此“Sylvain”对应的 4 个 token “S”、“##yl”、“##va”和“##in”预测的标签都为“I-PER”。</p>

<p>与文本分类任务一样，我们可以通过 softmax 函数进一步将 logits 值转换为概率值，并且通过 argmax 函数来获取每一个 token 的预测结果：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForTokenClassification</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"dbmdz/bert-large-cased-finetuned-conll03-english"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">example</span> <span class="o">=</span> <span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">tokens</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">label</span> <span class="o">!=</span> <span class="s">"O"</span><span class="p">:</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span><span class="s">"entity"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span> <span class="s">"score"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">pred</span><span class="p">],</span> <span class="s">"word"</span><span class="p">:</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="p">]}</span>
        <span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 6, 6, 6, 0, 8, 0, 0]
[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S'}, 
 {'entity': 'I-PER', 'score': 0.9981549382209778, 'word': '##yl'}, 
 {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va'}, 
 {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in'}, 
 {'entity': 'I-ORG', 'score': 0.9738931059837341, 'word': 'Hu'}, 
 {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging'}, 
 {'entity': 'I-ORG', 'score': 0.9887976050376892, 'word': 'Face'}, 
 {'entity': 'I-LOC', 'score': 0.9932106137275696, 'word': 'Brooklyn'}]
</code></pre></div></div>

<p>可以看到，这样就已经和 pipeline 模型的输出非常相似了，只不过 pipeline 模型还会返回 token 或者组合实体在原文中的起始和结束位置。</p>

<p>前面我们已经介绍过，快速分词器可以追踪从文本到 token 的映射，只需要给分词器传递 <code class="language-plaintext highlighter-rouge">return_offsets_mapping=True</code> 参数，就可以获取从 token 到原文的映射（特殊 token 对应的原文位置为 <code class="language-plaintext highlighter-rouge">(0, 0)</code>。）：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs_with_offsets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">offset_mapping</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">[</span><span class="s">"offset_mapping"</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">offset_mapping</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(0, 0), (0, 2), (3, 7), (8, 10), (11, 12), (12, 14), (14, 16), (16, 18), (19, 22), (23, 24), (25, 29), (30, 32), (33, 35), (35, 40), (41, 45), (46, 48), (49, 57), (57, 58), (0, 0)]
</code></pre></div></div>

<p>借助于这个映射，我们可以进一步完善模型的输出结果：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForTokenClassification</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"dbmdz/bert-large-cased-finetuned-conll03-english"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">example</span> <span class="o">=</span> <span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inputs_with_offsets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">.</span><span class="n">tokens</span><span class="p">()</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">[</span><span class="s">"offset_mapping"</span><span class="p">]</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">label</span> <span class="o">!=</span> <span class="s">"O"</span><span class="p">:</span>
        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s">"entity"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
                <span class="s">"score"</span><span class="p">:</span> <span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">pred</span><span class="p">],</span>
                <span class="s">"word"</span><span class="p">:</span> <span class="n">tokens</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span>
                <span class="s">"start"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
                <span class="s">"end"</span><span class="p">:</span> <span class="n">end</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'entity': 'I-PER', 'score': 0.9993828535079956, 'word': 'S', 'start': 11, 'end': 12}, 
 {'entity': 'I-PER', 'score': 0.9981549382209778, 'word': '##yl', 'start': 12, 'end': 14}, 
 {'entity': 'I-PER', 'score': 0.995907187461853, 'word': '##va', 'start': 14, 'end': 16}, 
 {'entity': 'I-PER', 'score': 0.9992327690124512, 'word': '##in', 'start': 16, 'end': 18}, 
 {'entity': 'I-ORG', 'score': 0.9738931059837341, 'word': 'Hu', 'start': 33, 'end': 35}, 
 {'entity': 'I-ORG', 'score': 0.9761149883270264, 'word': '##gging', 'start': 35, 'end': 40}, 
 {'entity': 'I-ORG', 'score': 0.9887976050376892, 'word': 'Face', 'start': 41, 'end': 45}, 
 {'entity': 'I-LOC', 'score': 0.9932106137275696, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
</code></pre></div></div>

<p>这样我们手工构建的结果就与 pipeline 的输出完全一致了！只需要再实现组合实体功能就完成所有的后处理步骤了。</p>

<h3 id="组合实体">组合实体</h3>

<p>我们以前面介绍的 simple 合并策略为例，将连续的标签为“I-XXX”的多个 token 进行合并（或者以“B-XXX”开头，后面接多个“I-XXX”的 token 序列），直到遇到</p>

<ul>
  <li>“O”：表示该 token 为非实体；</li>
  <li>“B-XXX”或“I-YYY”或“B-YYY”：表示出现了新的实体。</li>
</ul>

<p>然后对组合后 token 的概率值求平均作为实体的分数：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForTokenClassification</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"dbmdz/bert-large-cased-finetuned-conll03-english"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForTokenClassification</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">example</span> <span class="o">=</span> <span class="s">"My name is Sylvain and I work at Hugging Face in Brooklyn."</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">logits</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">inputs_with_offsets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">.</span><span class="n">tokens</span><span class="p">()</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">[</span><span class="s">"offset_mapping"</span><span class="p">]</span>

<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">predictions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">label</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">pred</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">label</span> <span class="o">!=</span> <span class="s">"O"</span><span class="p">:</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="c1"># Remove the B- or I-
</span>        <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">all_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">pred</span><span class="p">]]</span>
        <span class="c1"># Grab all the tokens labeled with I-label
</span>        <span class="k">while</span> <span class="p">(</span>
            <span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
            <span class="ow">and</span> <span class="n">model</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">id2label</span><span class="p">[</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">==</span> <span class="sa">f</span><span class="s">"I-</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s">"</span>
        <span class="p">):</span>
            <span class="n">all_scores</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">probabilities</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">predictions</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]])</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">all_scores</span><span class="p">).</span><span class="n">item</span><span class="p">()</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
        <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s">"entity_group"</span><span class="p">:</span> <span class="n">label</span><span class="p">,</span>
                <span class="s">"score"</span><span class="p">:</span> <span class="n">score</span><span class="p">,</span>
                <span class="s">"word"</span><span class="p">:</span> <span class="n">word</span><span class="p">,</span>
                <span class="s">"start"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
                <span class="s">"end"</span><span class="p">:</span> <span class="n">end</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>
    <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'entity_group': 'PER', 'score': 0.9981694370508194, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.9796018997828165, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.9932106137275696, 'word': 'Brooklyn', 'start': 49, 'end': 57}]
</code></pre></div></div>

<p>这样我们就得到了与 pipeline 模型完全一致的组合实体预测结果。</p>

<h2 id="3-抽取式问答任务">3. 抽取式问答任务</h2>

<p>除了序列标注以外，抽取式问答是另一个需要使用到分词器高级功能的任务。与 NER 任务类似，自动问答需要根据问题从原文中标记（抽取）出答案片段。</p>

<h3 id="pipeline-的输出-1">pipeline 的输出</h3>

<p>同样地，我们首先通过 QA pipeline 模型来完成问答任务：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">question_answerer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">"question-answering"</span><span class="p">)</span>
<span class="n">context</span> <span class="o">=</span> <span class="s">"""
Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.
"""</span>
<span class="n">question</span> <span class="o">=</span> <span class="s">"Which deep learning libraries back Transformers?"</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">question_answerer</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'score': 0.9741130471229553, 'start': 76, 'end': 104, 'answer': 'Jax, PyTorch, and TensorFlow'}
</code></pre></div></div>

<p>可以看到 pipeline 会输出答案片段的概率、文本以及在原文中的位置。下面我们将手工构建 QA 模型，并且通过对输出进行处理获得与 pipeline 一样的结果。</p>

<h3 id="构造模型输出-1">构造模型输出</h3>

<p>我们首先通过 <code class="language-plaintext highlighter-rouge">AutoModelForQuestionAnswering</code> 类来手工构建一个问答模型，并且将 checkpoint 设为  <a href="https://huggingface.co/distilbert-base-cased-distilled-squad">distilbert-base-cased-distilled-squad</a>。按照模型预训练时的输入格式，我们将问题和上下文通过特殊分隔符 <code class="language-plaintext highlighter-rouge">[SEP]</code> 连接成一个整体，如下图所示：</p>

<p><img src="/How-to-use-Transformers/assets/img/transformers-note-5/question_tokens.png" alt="question_tokens.png" /></p>

<p>标准的问答模型会使用两个指针分别预测答案片段的起始 token 和结束 token 的索引（例子中分别是 21 和 24）。因此，模型会返回两个张量，分别对应答案起始 token 和结束 token 的 logits 值：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForQuestionAnswering</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"distilbert-base-cased-distilled-squad"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="s">"""
Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.
"""</span>
<span class="n">question</span> <span class="o">=</span> <span class="s">"Which deep learning libraries back Transformers?"</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>

<span class="n">start_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">start_logits</span>
<span class="n">end_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">end_logits</span>
<span class="k">print</span><span class="p">(</span><span class="n">start_logits</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">end_logits</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([1, 65])
torch.Size([1, 65]) torch.Size([1, 65])
</code></pre></div></div>

<p>在上面的例子中，因为模型的输入包含 $65$ 个 token，所以输出也是两个长度为 $65$ 的张量。同样地，我们也可以通过 softmax 函数将这些 logits 值转换为概率值。</p>

<p><strong>注意！</strong>因为答案是在上下文中抽取，所以在计算前我们需要先排除掉输入中那些不属于上下文的 token 索引。</p>

<p>我们的输入格式为“$\texttt{[CLS]} \text{ question } \texttt{[SEP]} \text{ context } \texttt{[SEP]}$”，所以需要构建 Mask 遮蔽掉问题文本以及 $\texttt{[SEP]}$。</p>

<blockquote>
  <p>考虑到某些模型使用 $\texttt{[CLS]}$ 来标记答案是否在上下文中，这里我们会保留 $\texttt{[CLS]}$。</p>
</blockquote>

<p>下面我们手工构建一个 Mask 张量，将需要遮盖 token 索引的 logits 值替换为一个大的负值（例如 -10000），然后再应用 softmax 函数：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForQuestionAnswering</span>

<span class="n">model_checkpoint</span> <span class="o">=</span> <span class="s">"distilbert-base-cased-distilled-squad"</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForQuestionAnswering</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_checkpoint</span><span class="p">)</span>

<span class="n">context</span> <span class="o">=</span> <span class="s">"""
Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.
"""</span>
<span class="n">question</span> <span class="o">=</span> <span class="s">"Which deep learning libraries back Transformers?"</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s">"pt"</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">start_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">start_logits</span>
<span class="n">end_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">end_logits</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">()</span>
<span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sequence_ids</span><span class="p">]</span>
<span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># Unmask the [CLS] token
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="bp">None</span><span class="p">]</span>

<span class="n">start_logits</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>
<span class="n">end_logits</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>

<span class="n">start_probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">end_probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<p>接下来最简单的做法就是使用 argmax 函数取出 <code class="language-plaintext highlighter-rouge">start_probabilities</code> 和 <code class="language-plaintext highlighter-rouge">end_probabilities</code> 中最大的索引分别作为答案的起始和结束位置。但是这样做起始索引可能会大于结束索引，因此我们换一种方式，计算所有可能的答案片段的概率，然后将概率最高的片段作为答案：</p>

\[P(\text{index}_{start}, \text{index}_{end}), \text{index}_{start} \le \text{index}_{end}\]

<p>具体的，我们假设“答案从 $\text{index}_{start}$ 开始”与“答案以 $\text{index}_{end}$ 结束”为相互独立的事件，因此答案片段从 $\text{index}_{start}$ 开始到 $\text{index}_{end}$ 结束的概率为：</p>

\[P(\text{index}_{start}, \text{index}_{end}) = P_{start}(\text{index}_{start})\times P_{end}(\text{index}_{end})\]

<p>因此，我们首先通过构建矩阵计算所有的概率值，然后将 $\text{index}<em>{start} &gt; \text{index}</em>{end}$ 对应的值赋为 0 来遮蔽掉这些不应该出现的情况，这可以使用 Pytorch 自带的 <code class="language-plaintext highlighter-rouge">torch.triu()</code> 函数来完成，它会返回一个 2 维张量的上三角部分：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">start_probabilities</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">end_probabilities</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">triu</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</code></pre></div></div>

<p>最后，我们只需取出矩阵 <code class="language-plaintext highlighter-rouge">scores</code> 中最大的值对应的索引作为答案。由于 PyTorch 会返回展平张量中的索引，因此我们还需要将索引换算为对应的 $\text{index}_{start}$ 和 $\text{index}_{end}$ （通过整除和求模运算）：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">max_index</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>
<span class="n">start_index</span> <span class="o">=</span> <span class="n">max_index</span> <span class="o">//</span> <span class="n">scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">end_index</span> <span class="o">=</span> <span class="n">max_index</span> <span class="o">%</span> <span class="n">scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">inputs_with_offsets</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">inputs_with_offsets</span><span class="p">[</span><span class="s">"offset_mapping"</span><span class="p">]</span>

<span class="n">start</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">start_index</span><span class="p">]</span>
<span class="n">_</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="n">offsets</span><span class="p">[</span><span class="n">end_index</span><span class="p">]</span>

<span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"answer"</span><span class="p">:</span> <span class="n">context</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">],</span>
    <span class="s">"start"</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
    <span class="s">"end"</span><span class="p">:</span> <span class="n">end</span><span class="p">,</span>
    <span class="s">"score"</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="n">start_index</span><span class="p">,</span> <span class="n">end_index</span><span class="p">]),</span>
<span class="p">}</span>
<span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'answer': 'Jax, PyTorch, and TensorFlow', 'start': 76, 'end': 104, 'score': 0.9741137027740479}
</code></pre></div></div>

<p>这样我们就得到了与 pipeline 模型完全相同的输出结果！</p>

<h3 id="处理长文本">处理长文本</h3>

<p>问答模型可能遇到的另一个问题是：如果上下文非常长，在与问题拼接后就可能会超过模型可接受的最大长度，例如默认 QA pipeline 的最大输入长度只有 384。</p>

<p>最简单粗暴的办法就是直接截去超过最大长度的 token，由于我们只希望对上下文进行剪裁，因此可以使用 <code class="language-plaintext highlighter-rouge">only_second</code> 截断策略：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">long_context</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">)</span>
</code></pre></div></div>

<p>但是万一答案恰好在被截去的部分中，模型就无法预测出最优的结果了。</p>

<p>幸运的是，自动问答 pipeline 采取了一种将超过最大长度的上下文切分为文本块 (chunk) 的方式，即使答案出现在长文末尾也依然能够成功地抽取出来：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="n">question_answerer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s">"question-answering"</span><span class="p">)</span>

<span class="n">long_context</span> <span class="o">=</span> <span class="s">"""
Transformers: State of the Art NLP

Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction, question answering, summarization, translation, text generation and more in over 100 languages. Its aim is to make cutting-edge NLP easier to use for everyone.

Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and can be modified to enable quick research experiments.

Why should I use transformers?

1. Easy-to-use state-of-the-art models:
  - High performance on NLU and NLG tasks.
  - Low barrier to entry for educators and practitioners.
  - Few user-facing abstractions with just three classes to learn.
  - A unified API for using all our pretrained models.
  - Lower compute costs, smaller carbon footprint:

2. Researchers can share trained models instead of always retraining.
  - Practitioners can reduce compute time and production costs.
  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.

3. Choose the right framework for every part of a model's lifetime:
  - Train state-of-the-art models in 3 lines of code.
  - Move a single model between TF2.0/PyTorch frameworks at will.
  - Seamlessly pick the right framework for training, evaluation and production.

4. Easily customize a model or an example to your needs:
  - We provide examples for each architecture to reproduce the results published by its original authors.
  - Model internals are exposed as consistently as possible.
  - Model files can be used independently of the library for quick experiments.

Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration between them. It's straightforward to train your models with one before loading them for inference with the other.
"""</span>
<span class="n">question</span> <span class="o">=</span> <span class="s">"Which deep learning libraries back Transformers?"</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">question_answerer</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="o">=</span><span class="n">long_context</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'score': 0.9697490930557251, 'start': 1884, 'end': 1911, 'answer': 'Jax, PyTorch and TensorFlow'}
</code></pre></div></div>

<p>实际上，无论快速或慢速分词器都提供了按 chunk 切分文本的功能，只需要在截断文本时再添加额外的参数 <code class="language-plaintext highlighter-rouge">return_overflowing_tokens=True</code>。考虑到如果截断的位置不合理，也可能无法抽取出正确的答案，因此还可以通过设置步长参数 <code class="language-plaintext highlighter-rouge">stride</code> 控制文本块重叠部分的长度。例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentence</span> <span class="o">=</span> <span class="s">"This sentence is not too long but we are going to split it anyway."</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">ids</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">decode</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[CLS] This sentence is not [SEP]
[CLS] is not too long [SEP]
[CLS] too long but we [SEP]
[CLS] but we are going [SEP]
[CLS] are going to split [SEP]
[CLS] to split it anyway [SEP]
[CLS] it anyway. [SEP]
</code></pre></div></div>

<p>可以看到在 <code class="language-plaintext highlighter-rouge">max_length=6, stride=2</code> 设置下，切分出的文本块最多只能包含 6 个 token，并且文本块之间有 2 个 token 重叠。如果我们进一步打印编码结果就会发现，除了常规的 token ID 和注意力 Mask 以外，还有一个 <code class="language-plaintext highlighter-rouge">overflow_to_sample_mapping</code> 项，它负责记录每一个文本块对应原文中的句子索引，例如：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sentence</span> <span class="o">=</span> <span class="s">"This sentence is not too long but we are going to split it anyway."</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">sentence</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"overflow_to_sample_mapping"</span><span class="p">])</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s">"This sentence is not too long but we are going to split it anyway."</span><span class="p">,</span>
    <span class="s">"This sentence is shorter but will still get split."</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">sentences</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span>
<span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"overflow_to_sample_mapping"</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])
[0, 0, 0, 0, 0, 0, 0]
[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]
</code></pre></div></div>

<p>对单个句子进行切分时，因为所有的 chunk 都来源于同一个句子，因此 mapping 中对应的句子索引都为 0；而如果同时对多个句子进行切分时，可以看到其中第一个句子对应的句子索引为 0，第二个句子为 1。</p>

<p>QA pipeline 默认会按照预训练时的设置将最大输入长度设为 384，将步长设为 128，我们也可以在调用 pipeline 时通过参数 <code class="language-plaintext highlighter-rouge">max_seq_len</code> 和 <code class="language-plaintext highlighter-rouge">stride</code> 进行调整。</p>

<p>下面我们采用相同的设置对前面示例中的长文本进行分词，考虑到编码结果中除了模型需要的 token IDs 和注意力 Mask 以外，还会包含文本到 token 的映射以及 <code class="language-plaintext highlighter-rouge">overflow_to_sample_mapping</code> 项，这里我们只有一个句子，因此就不保留这个 map 了：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">question</span><span class="p">,</span>
    <span class="n">long_context</span><span class="p">,</span>
    <span class="n">stride</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">384</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="s">"longest"</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="s">"only_second"</span><span class="p">,</span>
    <span class="n">return_overflowing_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">return_offsets_mapping</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">"overflow_to_sample_mapping"</span><span class="p">)</span>
<span class="n">offsets</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s">"offset_mapping"</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">convert_to_tensors</span><span class="p">(</span><span class="s">"pt"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"input_ids"</span><span class="p">].</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([2, 384])
</code></pre></div></div>

<p>可以看到，长文本被切分成了 2 个文本块，因此模型对应的输出也会是 2 组起始和结束 logits 值的集合：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">start_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">start_logits</span>
<span class="n">end_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">.</span><span class="n">end_logits</span>
<span class="k">print</span><span class="p">(</span><span class="n">start_logits</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">end_logits</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>torch.Size([2, 384]) torch.Size([2, 384])
</code></pre></div></div>

<p>继续按照之前做的那样，在运用 softmax 转换为概率之前，我们先将非上下文的部分以及填充的 padding token 都通过 Mask 遮掩掉：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sequence_ids</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">sequence_ids</span><span class="p">()</span>
<span class="c1"># Mask everything apart from the tokens of the context
</span><span class="n">mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sequence_ids</span><span class="p">]</span>
<span class="c1"># Unmask the [CLS] token
</span><span class="n">mask</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
<span class="c1"># Mask all the [PAD] tokens
</span><span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mask</span><span class="p">)[</span><span class="bp">None</span><span class="p">],</span> <span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s">"attention_mask"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

<span class="n">start_logits</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>
<span class="n">end_logits</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">10000</span>

<span class="n">start_probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">start_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">end_probabilities</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">functional</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">end_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p><strong>注意：</strong>上面的代码中，<code class="language-plaintext highlighter-rouge">logical_or</code> 函数首先通过广播机制将 mask 向量从 $(1, 384)$ 扩展成了 $(2, 384)$，然后再与 <code class="language-plaintext highlighter-rouge">attention_mask</code> 张量进行计算。这是因为两个 chunk 中非上下文的部分的一致的，如果不一致就必须针对每一个文本块单独构建 mask。</p>
</blockquote>

<p>同样地，对于每一个 chunk，我们对 chunk 中所有可能的文本片段都计算其为答案的概率，再从中取出概率最大的文本片段，最后将 token 索引映射回原文本作为输出：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">candidates</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">start_probs</span><span class="p">,</span> <span class="n">end_probs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">start_probabilities</span><span class="p">,</span> <span class="n">end_probabilities</span><span class="p">):</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">start_probs</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">end_probs</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">triu</span><span class="p">(</span><span class="n">scores</span><span class="p">).</span><span class="n">argmax</span><span class="p">().</span><span class="n">item</span><span class="p">()</span>

    <span class="n">start_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">//</span> <span class="n">scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">end_idx</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">%</span> <span class="n">scores</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">].</span><span class="n">item</span><span class="p">()</span>
    <span class="n">candidates</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">start_idx</span><span class="p">,</span> <span class="n">end_idx</span><span class="p">,</span> <span class="n">score</span><span class="p">))</span>

<span class="k">for</span> <span class="n">candidate</span><span class="p">,</span> <span class="n">offset</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">candidates</span><span class="p">,</span> <span class="n">offsets</span><span class="p">):</span>
    <span class="n">start_token</span><span class="p">,</span> <span class="n">end_token</span><span class="p">,</span> <span class="n">score</span> <span class="o">=</span> <span class="n">candidate</span>
    <span class="n">start_char</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">offset</span><span class="p">[</span><span class="n">start_token</span><span class="p">]</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">end_char</span> <span class="o">=</span> <span class="n">offset</span><span class="p">[</span><span class="n">end_token</span><span class="p">]</span>
    <span class="n">answer</span> <span class="o">=</span> <span class="n">long_context</span><span class="p">[</span><span class="n">start_char</span><span class="p">:</span><span class="n">end_char</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s">"answer"</span><span class="p">:</span> <span class="n">answer</span><span class="p">,</span> <span class="s">"start"</span><span class="p">:</span> <span class="n">start_char</span><span class="p">,</span> <span class="s">"end"</span><span class="p">:</span> <span class="n">end_char</span><span class="p">,</span> <span class="s">"score"</span><span class="p">:</span> <span class="n">score</span><span class="p">}</span>
    <span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'answer': '', 'start': 0, 'end': 0, 'score': 0.6493748426437378}
{'answer': 'Jax, PyTorch and TensorFlow', 'start': 1884, 'end': 1911, 'score': 0.9697459936141968}
</code></pre></div></div>

<p>可以看到最终的输出与前面 pipeline 模型的输出是一致的，这也验证了我们对模型输出的处理是正确的。</p>

<h2 id="参考">参考</h2>

<p><a href="https://huggingface.co/docs/tokenizers/python/latest/">[1]</a> Tokenizers 官方文档<br />
<a href="https://huggingface.co/course/chapter1/1">[2]</a> HuggingFace 在线教程</p>]]></content><author><name>SHENG XU</name></author><category term="NLP" /><summary type="html"><![CDATA[通过前面章节的介绍，我们已经对 Transformers 库有了基本的了解，并且上手微调了一个句子对分类模型。从本章开始，我们将通过一系列的实例向大家展示如何使用 Transformers 库来完成目前主流的 NLP 任务。]]></summary></entry></feed>